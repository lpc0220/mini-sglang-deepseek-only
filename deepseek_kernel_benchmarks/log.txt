Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 317, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 313, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 278, in run_benchmarks
    result = bench_trtllm_fp4_block_scale_moe(flashinfer, B, 1, H, E, K, I, "decode")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 95, in bench_trtllm_fp4_block_scale_moe
    torch.manual_seed(42)
  File "/usr/local/lib/python3.12/dist-packages/torch/random.py", line 46, in manual_seed
    torch.cuda.manual_seed_all(seed)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 131, in manual_seed_all
    _lazy_call(cb, seed_all=True)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 341, in _lazy_call
    callable()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 129, in cb
    default_generator.manual_seed(seed)
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


======================================================================
DeepSeek-R1-NVFP4-v2 Kernel Benchmarks
======================================================================
Kernels to run: 23
Batch sizes: 1,2,4,8,16,32,64,128
Sequence lengths: 128,256,512,1024,2048
Output directory: ../results/

NOTE: Each kernel runs in a separate subprocess for isolation.
      CUDA crashes in one kernel will NOT affect other kernels.
======================================================================

======================================================================
Running: rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: rmsnorm (Kernel #1)
============================================================

=== Decode Phase ===
  B=1: 0.0020 ms, 14.4 GB/s, 0.2% peak
  B=2: 0.0020 ms, 28.6 GB/s, 0.4% peak
  B=4: 0.0020 ms, 57.3 GB/s, 0.7% peak
  B=8: 0.0020 ms, 114.7 GB/s, 1.4% peak
  B=16: 0.0020 ms, 229.2 GB/s, 2.9% peak
  B=32: 0.0020 ms, 456.1 GB/s, 5.7% peak
  B=64: 0.0020 ms, 902.2 GB/s, 11.3% peak
  B=128: 0.0021 ms, 1760.7 GB/s, 22.0% peak

=== Prefill Phase ===
  B=1, S=128: 0.0021 ms, 1760.5 GB/s, 22.0% peak
  B=1, S=256: 0.0027 ms, 2691.9 GB/s, 33.6% peak
  B=1, S=512: 0.0046 ms, 3206.0 GB/s, 40.1% peak
  B=1, S=1024: 0.0082 ms, 3565.5 GB/s, 44.6% peak
  B=1, S=2048: 0.0152 ms, 3860.2 GB/s, 48.3% peak
  B=2, S=128: 0.0027 ms, 2689.8 GB/s, 33.6% peak
  B=2, S=256: 0.0046 ms, 3196.0 GB/s, 39.9% peak
  B=2, S=512: 0.0082 ms, 3566.9 GB/s, 44.6% peak
  B=2, S=1024: 0.0152 ms, 3873.0 GB/s, 48.4% peak
  B=2, S=2048: 0.0360 ms, 3263.2 GB/s, 40.8% peak
  B=4, S=128: 0.0046 ms, 3198.0 GB/s, 40.0% peak
  B=4, S=256: 0.0082 ms, 3567.3 GB/s, 44.6% peak
  B=4, S=512: 0.0152 ms, 3873.8 GB/s, 48.4% peak
  B=4, S=1024: 0.0366 ms, 3212.7 GB/s, 40.2% peak
  B=4, S=2048: 0.0701 ms, 3349.9 GB/s, 41.9% peak
  B=8, S=128: 0.0081 ms, 3627.3 GB/s, 45.3% peak
  B=8, S=256: 0.0151 ms, 3896.4 GB/s, 48.7% peak
  B=8, S=512: 0.0364 ms, 3229.6 GB/s, 40.4% peak
  B=8, S=1024: 0.0699 ms, 3359.9 GB/s, 42.0% peak
  B=8, S=2048: 0.1364 ms, 3443.3 GB/s, 43.0% peak
Saved ../results/rmsnorm.csv

[OK] rmsnorm completed successfully

======================================================================
Running: fused_add_rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: fused_add_rmsnorm (Kernel #2)
============================================================

=== Decode Phase ===
  B=1: 0.0025 ms, 23.4 GB/s, 0.3% peak
  B=2: 0.0025 ms, 46.7 GB/s, 0.6% peak
  B=4: 0.0024 ms, 93.8 GB/s, 1.2% peak
  B=8: 0.0025 ms, 183.4 GB/s, 2.3% peak
  B=16: 0.0025 ms, 367.3 GB/s, 4.6% peak
  B=32: 0.0025 ms, 724.8 GB/s, 9.1% peak
  B=64: 0.0025 ms, 1468.8 GB/s, 18.4% peak
  B=128: 0.0026 ms, 2860.4 GB/s, 35.8% peak

=== Prefill Phase ===
  B=1, S=128: 0.0026 ms, 2859.3 GB/s, 35.7% peak
  B=1, S=256: 0.0045 ms, 3274.4 GB/s, 40.9% peak
  B=1, S=512: 0.0080 ms, 3661.4 GB/s, 45.8% peak
  B=1, S=1024: 0.0144 ms, 4078.0 GB/s, 51.0% peak
  B=1, S=2048: 0.0266 ms, 4412.0 GB/s, 55.1% peak
  B=2, S=128: 0.0045 ms, 3279.9 GB/s, 41.0% peak
  B=2, S=256: 0.0080 ms, 3656.3 GB/s, 45.7% peak
  B=2, S=512: 0.0143 ms, 4115.8 GB/s, 51.4% peak
  B=2, S=1024: 0.0267 ms, 4402.8 GB/s, 55.0% peak
  B=2, S=2048: 0.0672 ms, 3494.7 GB/s, 43.7% peak
  B=4, S=128: 0.0080 ms, 3656.6 GB/s, 45.7% peak
  B=4, S=256: 0.0144 ms, 4087.5 GB/s, 51.1% peak
  B=4, S=512: 0.0266 ms, 4407.5 GB/s, 55.1% peak
  B=4, S=1024: 0.0675 ms, 3478.3 GB/s, 43.5% peak
  B=4, S=2048: 0.1312 ms, 3580.9 GB/s, 44.8% peak
  B=8, S=128: 0.0143 ms, 4103.1 GB/s, 51.3% peak
  B=8, S=256: 0.0267 ms, 4404.5 GB/s, 55.1% peak
  B=8, S=512: 0.0676 ms, 3474.3 GB/s, 43.4% peak
  B=8, S=1024: 0.1318 ms, 3564.1 GB/s, 44.6% peak
  B=8, S=2048: 0.2578 ms, 3644.8 GB/s, 45.6% peak
Saved ../results/fused_add_rmsnorm.csv

[OK] fused_add_rmsnorm completed successfully

======================================================================
Running: cutlass_scaled_fp4_mm (GEMM, Compute)
======================================================================
============================================================
Benchmark: cutlass_scaled_fp4_mm (Kernel #3)
============================================================

=== Decode Phase ===
  q_b_proj B=1: 0.0064 ms, 11815.2 GFLOPS, 0.13% peak
  kv_b_proj B=1: 0.0051 ms, 6589.1 GFLOPS, 0.07% peak
  o_proj B=1: 0.0234 ms, 10043.0 GFLOPS, 0.11% peak
  q_b_proj B=2: 0.0064 ms, 23567.3 GFLOPS, 0.26% peak
  kv_b_proj B=2: 0.0050 ms, 13303.5 GFLOPS, 0.15% peak
  o_proj B=2: 0.0234 ms, 20078.1 GFLOPS, 0.22% peak
  q_b_proj B=4: 0.0063 ms, 47695.1 GFLOPS, 0.53% peak
  kv_b_proj B=4: 0.0051 ms, 26310.7 GFLOPS, 0.29% peak
  o_proj B=4: 0.0233 ms, 40328.7 GFLOPS, 0.45% peak
  q_b_proj B=8: 0.0064 ms, 94632.5 GFLOPS, 1.05% peak
  kv_b_proj B=8: 0.0050 ms, 53628.7 GFLOPS, 0.60% peak
  o_proj B=8: 0.0233 ms, 80657.2 GFLOPS, 0.90% peak
  q_b_proj B=16: 0.0063 ms, 190755.8 GFLOPS, 2.12% peak
  kv_b_proj B=16: 0.0050 ms, 106661.2 GFLOPS, 1.19% peak
  o_proj B=16: 0.0233 ms, 161416.6 GFLOPS, 1.79% peak
  q_b_proj B=32: 0.0063 ms, 381133.2 GFLOPS, 4.23% peak
  kv_b_proj B=32: 0.0050 ms, 215701.1 GFLOPS, 2.40% peak
  o_proj B=32: 0.0234 ms, 321117.2 GFLOPS, 3.57% peak
  q_b_proj B=64: 0.0064 ms, 753809.2 GFLOPS, 8.38% peak
  kv_b_proj B=64: 0.0050 ms, 426644.2 GFLOPS, 4.74% peak
  o_proj B=64: 0.0234 ms, 641321.1 GFLOPS, 7.13% peak
  q_b_proj B=128: 0.0069 ms, 1407622.2 GFLOPS, 15.64% peak
  kv_b_proj B=128: 0.0054 ms, 797251.0 GFLOPS, 8.86% peak
  o_proj B=128: 0.0240 ms, 1250699.1 GFLOPS, 13.90% peak

=== Prefill Phase ===
  q_b_proj B=1, S=128: 0.0069 ms, 1407735.6 GFLOPS, 15.64% peak
  kv_b_proj B=1, S=128: 0.0054 ms, 798021.8 GFLOPS, 8.87% peak
  o_proj B=1, S=128: 0.0240 ms, 1250570.7 GFLOPS, 13.90% peak
  q_b_proj B=1, S=256: 0.0090 ms, 2137424.2 GFLOPS, 23.75% peak
  kv_b_proj B=1, S=256: 0.0070 ms, 1226671.2 GFLOPS, 13.63% peak
  o_proj B=1, S=256: 0.0221 ms, 2716239.8 GFLOPS, 30.18% peak
  q_b_proj B=1, S=512: 0.0123 ms, 3142575.6 GFLOPS, 34.92% peak
  kv_b_proj B=1, S=512: 0.0102 ms, 1690961.8 GFLOPS, 18.79% peak
  o_proj B=1, S=512: 0.0237 ms, 5078463.9 GFLOPS, 56.43% peak
  q_b_proj B=1, S=1024: 0.0200 ms, 3871926.8 GFLOPS, 43.02% peak
  kv_b_proj B=1, S=1024: 0.0152 ms, 2259882.8 GFLOPS, 25.11% peak
  o_proj B=1, S=1024: 0.0517 ms, 4650911.2 GFLOPS, 51.68% peak
  q_b_proj B=1, S=2048: 0.0399 ms, 3870582.6 GFLOPS, 43.01% peak
  kv_b_proj B=1, S=2048: 0.0285 ms, 2414372.4 GFLOPS, 26.83% peak
  o_proj B=1, S=2048: 0.1013 ms, 4747721.8 GFLOPS, 52.75% peak
  q_b_proj B=2, S=128: 0.0090 ms, 2152093.1 GFLOPS, 23.91% peak
  kv_b_proj B=2, S=128: 0.0070 ms, 1224571.1 GFLOPS, 13.61% peak
  o_proj B=2, S=128: 0.0225 ms, 2672938.5 GFLOPS, 29.70% peak
  q_b_proj B=2, S=256: 0.0123 ms, 3142752.4 GFLOPS, 34.92% peak
  kv_b_proj B=2, S=256: 0.0102 ms, 1687072.8 GFLOPS, 18.75% peak
  o_proj B=2, S=256: 0.0242 ms, 4971400.3 GFLOPS, 55.24% peak
  q_b_proj B=2, S=512: 0.0197 ms, 3918528.5 GFLOPS, 43.54% peak
  kv_b_proj B=2, S=512: 0.0153 ms, 2241686.4 GFLOPS, 24.91% peak
  o_proj B=2, S=512: 0.0515 ms, 4665806.4 GFLOPS, 51.84% peak
  q_b_proj B=2, S=1024: 0.0400 ms, 3869096.5 GFLOPS, 42.99% peak
  kv_b_proj B=2, S=1024: 0.0285 ms, 2409274.0 GFLOPS, 26.77% peak
  o_proj B=2, S=1024: 0.1020 ms, 4717963.8 GFLOPS, 52.42% peak
  q_b_proj B=2, S=2048: 0.0714 ms, 4330131.6 GFLOPS, 48.11% peak
  kv_b_proj B=2, S=2048: 0.0517 ms, 2657990.3 GFLOPS, 29.53% peak
  o_proj B=2, S=2048: 0.1809 ms, 5319041.9 GFLOPS, 59.10% peak
  q_b_proj B=4, S=128: 0.0127 ms, 3036218.1 GFLOPS, 33.74% peak
  kv_b_proj B=4, S=128: 0.0102 ms, 1689788.1 GFLOPS, 18.78% peak
  o_proj B=4, S=128: 0.0241 ms, 4984049.7 GFLOPS, 55.38% peak
  q_b_proj B=4, S=256: 0.0199 ms, 3880238.9 GFLOPS, 43.11% peak
  kv_b_proj B=4, S=256: 0.0154 ms, 2231270.5 GFLOPS, 24.79% peak
  o_proj B=4, S=256: 0.0520 ms, 4627697.3 GFLOPS, 51.42% peak
  q_b_proj B=4, S=512: 0.0399 ms, 3878896.7 GFLOPS, 43.10% peak
  kv_b_proj B=4, S=512: 0.0283 ms, 2432004.3 GFLOPS, 27.02% peak
  o_proj B=4, S=512: 0.1012 ms, 4754631.2 GFLOPS, 52.83% peak
  q_b_proj B=4, S=1024: 0.0726 ms, 4261139.0 GFLOPS, 47.35% peak
  kv_b_proj B=4, S=1024: 0.0528 ms, 2602749.2 GFLOPS, 28.92% peak
  o_proj B=4, S=1024: 0.1781 ms, 5403210.0 GFLOPS, 60.04% peak
  q_b_proj B=4, S=2048: 0.1459 ms, 4237664.3 GFLOPS, 47.09% peak
  kv_b_proj B=4, S=2048: 0.1000 ms, 2748326.3 GFLOPS, 30.54% peak
  o_proj B=4, S=2048: 0.3514 ms, 5476290.1 GFLOPS, 60.85% peak
  q_b_proj B=8, S=128: 0.0198 ms, 3914393.8 GFLOPS, 43.49% peak
  kv_b_proj B=8, S=128: 0.0151 ms, 2275145.3 GFLOPS, 25.28% peak
  o_proj B=8, S=128: 0.0517 ms, 4656505.9 GFLOPS, 51.74% peak
  q_b_proj B=8, S=256: 0.0400 ms, 3868447.8 GFLOPS, 42.98% peak
  kv_b_proj B=8, S=256: 0.0283 ms, 2426278.5 GFLOPS, 26.96% peak
  o_proj B=8, S=256: 0.1014 ms, 4745427.7 GFLOPS, 52.73% peak
  q_b_proj B=8, S=512: 0.0732 ms, 4226302.5 GFLOPS, 46.96% peak
  kv_b_proj B=8, S=512: 0.0528 ms, 2600632.0 GFLOPS, 28.90% peak
  o_proj B=8, S=512: 0.1783 ms, 5396800.7 GFLOPS, 59.96% peak
  q_b_proj B=8, S=1024: 0.1442 ms, 4288381.3 GFLOPS, 47.65% peak
  kv_b_proj B=8, S=1024: 0.0997 ms, 2758064.0 GFLOPS, 30.65% peak
  o_proj B=8, S=1024: 0.3505 ms, 5489752.4 GFLOPS, 61.00% peak
  q_b_proj B=8, S=2048: 0.2879 ms, 4297020.4 GFLOPS, 47.74% peak
  kv_b_proj B=8, S=2048: 0.1953 ms, 2815040.0 GFLOPS, 31.28% peak
  o_proj B=8, S=2048: 0.7093 ms, 5425589.0 GFLOPS, 60.28% peak
Saved ../results/cutlass_scaled_fp4_mm.csv

[OK] cutlass_scaled_fp4_mm completed successfully

======================================================================
Running: dsv3_fused_a_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_fused_a_gemm (Kernel #4)
============================================================

=== Decode Phase (B<=16, low-latency path) ===
  B=1: 0.0051 ms, 5899.6 GFLOPS, 0.26% peak
  B=2: 0.0051 ms, 11812.6 GFLOPS, 0.53% peak
  B=4: 0.0052 ms, 23508.6 GFLOPS, 1.04% peak
  B=8: 0.0052 ms, 46464.0 GFLOPS, 2.07% peak
  B=16: 0.0058 ms, 83070.2 GFLOPS, 3.69% peak
Saved ../results/dsv3_fused_a_gemm.csv

[OK] dsv3_fused_a_gemm completed successfully

======================================================================
Running: dsv3_router_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_router_gemm (Kernel #5)
============================================================

=== Decode Phase ===
  B=1: 0.0021 ms, 1790.0 GFLOPS, 0.08% peak
  B=2: 0.0022 ms, 3271.5 GFLOPS, 0.15% peak
  B=4: 0.0027 ms, 5386.2 GFLOPS, 0.24% peak
  B=8: 0.0036 ms, 8237.3 GFLOPS, 0.37% peak
  B=16: 0.0072 ms, 8173.3 GFLOPS, 0.36% peak
  Skipping B=32: kernel limited to num_tokens <= 16
  Skipping B=64: kernel limited to num_tokens <= 16
  Skipping B=128: kernel limited to num_tokens <= 16

=== Prefill Phase (skipped - kernel limited to 16 tokens) ===
Saved ../results/dsv3_router_gemm.csv

[OK] dsv3_router_gemm completed successfully

======================================================================
Running: bmm_fp8 (BMM, Compute)
======================================================================
============================================================
Benchmark: bmm_fp8 (Kernel #6)
============================================================

=== Decode Phase: q_nope * w_kc ===
  B=1: 0.0055 ms, 3061.3 GFLOPS, 0.07% peak
  B=2: 0.0055 ms, 6113.1 GFLOPS, 0.14% peak
  B=4: 0.0055 ms, 12242.1 GFLOPS, 0.27% peak
  B=8: 0.0055 ms, 24439.6 GFLOPS, 0.54% peak
  B=16: 0.0056 ms, 47718.9 GFLOPS, 1.06% peak
  B=32: 0.0057 ms, 93629.7 GFLOPS, 2.08% peak
  B=64: 0.0061 ms, 175813.7 GFLOPS, 3.91% peak
  B=128: 0.0069 ms, 309615.8 GFLOPS, 6.88% peak

=== Decode Phase: attn * w_vc ===
  B=1: 0.0028 ms, 6089.3 GFLOPS, 0.14% peak
  B=2: 0.0028 ms, 12187.7 GFLOPS, 0.27% peak
  B=4: 0.0027 ms, 24418.3 GFLOPS, 0.54% peak
  B=8: 0.0028 ms, 48660.5 GFLOPS, 1.08% peak
  B=16: 0.0031 ms, 85863.7 GFLOPS, 1.91% peak
  B=32: 0.0032 ms, 169051.8 GFLOPS, 3.76% peak
  B=64: 0.0033 ms, 321346.7 GFLOPS, 7.14% peak
  B=128: 0.0038 ms, 572034.8 GFLOPS, 12.71% peak
Saved ../results/bmm_fp8.csv

[OK] bmm_fp8 completed successfully

======================================================================
Running: cutlass_mla_decode (Attention, Mixed)
======================================================================
============================================================
Benchmark: cutlass_mla_decode (Kernel #7)
============================================================

=== Decode Phase (MLA Attention) ===
  B=1, seq_len=128: 0.0182 ms, 16.2 GB/s, memory
  B=1, seq_len=256: 0.0296 ms, 14.9 GB/s, memory
  B=1, seq_len=512: 0.0308 ms, 23.9 GB/s, memory
  B=1, seq_len=1024: 0.0301 ms, 44.1 GB/s, memory
  Skipping B=1, seq_len=2048: B*seq_len=2048 > 1024 (crash risk)
  B=2, seq_len=128: 0.0181 ms, 32.6 GB/s, memory
  B=2, seq_len=256: 0.0296 ms, 29.9 GB/s, memory
  B=2, seq_len=512: 0.0292 ms, 50.4 GB/s, memory
  Skipping B=2, seq_len=1024: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=2, seq_len=2048: B*seq_len=4096 > 1024 (crash risk)
  B=4, seq_len=128: 0.0181 ms, 65.1 GB/s, memory
  B=4, seq_len=256: 0.0296 ms, 59.8 GB/s, memory
  Skipping B=4, seq_len=512: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=4, seq_len=1024: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=4, seq_len=2048: B*seq_len=8192 > 1024 (crash risk)
  B=8, seq_len=128: 0.0182 ms, 129.9 GB/s, memory
  Skipping B=8, seq_len=256: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=8, seq_len=512: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=8, seq_len=1024: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=8, seq_len=2048: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=128: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=16, seq_len=256: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=16, seq_len=512: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=16, seq_len=1024: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=2048: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=128: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=32, seq_len=256: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=32, seq_len=512: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=32, seq_len=1024: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=2048: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=128: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=64, seq_len=256: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=64, seq_len=512: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=64, seq_len=1024: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=2048: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=128: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=128, seq_len=256: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=128, seq_len=512: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=128, seq_len=1024: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=2048: B*seq_len=262144 > 1024 (crash risk)
Saved ../results/cutlass_mla_decode.csv

[OK] cutlass_mla_decode completed successfully

======================================================================
Running: trtllm_batch_decode_with_kv_cache_mla (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_batch_decode_with_kv_cache_mla (Kernel #8)
============================================================

=== Decode Phase (TRT-LLM MLA Attention) ===

  Page size: 32
    B=1, seq_len=128: 0.0054 ms, 54.5 GB/s, memory
    B=1, seq_len=256: 0.0054 ms, 82.0 GB/s, memory
    B=1, seq_len=512: 0.0074 ms, 100.0 GB/s, memory
    B=1, seq_len=1024: 0.0098 ms, 135.4 GB/s, memory
    B=1, seq_len=2048: 0.0112 ms, 223.1 GB/s, memory
    B=2, seq_len=128: 0.0061 ms, 96.2 GB/s, memory
    B=2, seq_len=256: 0.0060 ms, 148.1 GB/s, memory
    B=2, seq_len=512: 0.0080 ms, 183.8 GB/s, memory
    B=2, seq_len=1024: 0.0102 ms, 259.0 GB/s, memory
    B=2, seq_len=2048: 0.0126 ms, 397.2 GB/s, memory
    B=4, seq_len=128: 0.0069 ms, 171.1 GB/s, memory
    B=4, seq_len=256: 0.0069 ms, 257.6 GB/s, memory
    B=4, seq_len=512: 0.0091 ms, 324.5 GB/s, memory
    B=4, seq_len=1024: 0.0115 ms, 459.9 GB/s, memory
    B=4, seq_len=2048: 0.0164 ms, 613.0 GB/s, memory
    B=8, seq_len=128: 0.0077 ms, 307.1 GB/s, memory
    B=8, seq_len=256: 0.0077 ms, 462.2 GB/s, memory
    B=8, seq_len=512: 0.0106 ms, 558.9 GB/s, memory
    B=8, seq_len=1024: 0.0156 ms, 682.2 GB/s, memory
    B=8, seq_len=2048: 0.0234 ms, 856.6 GB/s, memory
    B=16, seq_len=128: 0.0094 ms, 503.5 GB/s, memory
    B=16, seq_len=256: 0.0093 ms, 758.9 GB/s, memory
    B=16, seq_len=512: 0.0132 ms, 892.5 GB/s, memory
    B=16, seq_len=1024: 0.0203 ms, 1048.0 GB/s, memory
    B=16, seq_len=2048: 0.0160 ms, 2501.0 GB/s, memory
    B=32, seq_len=128: 0.0075 ms, 1261.5 GB/s, memory
    B=32, seq_len=256: 0.0088 ms, 1608.6 GB/s, memory
    B=32, seq_len=512: 0.0143 ms, 1652.6 GB/s, memory
    B=32, seq_len=1024: 0.0172 ms, 2467.9 GB/s, memory
    B=32, seq_len=2048: 0.0236 ms, 3394.0 GB/s, memory
    B=64, seq_len=128: 0.0081 ms, 2329.0 GB/s, memory
    B=64, seq_len=256: 0.0100 ms, 2837.1 GB/s, memory
    B=64, seq_len=512: 0.0130 ms, 3629.8 GB/s, memory
    B=64, seq_len=1024: 0.0195 ms, 4363.7 GB/s, memory
    B=64, seq_len=2048: 0.0413 ms, 3888.9 GB/s, memory
    B=128, seq_len=128: 0.0127 ms, 2976.1 GB/s, memory
    B=128, seq_len=256: 0.0174 ms, 3259.3 GB/s, memory
    B=128, seq_len=512: 0.0250 ms, 3768.0 GB/s, memory
    B=128, seq_len=1024: 0.0471 ms, 3605.7 GB/s, memory
    B=128, seq_len=2048: 0.0862 ms, 3720.8 GB/s, memory

  Page size: 64
    B=1, seq_len=128: 0.0059 ms, 49.9 GB/s, memory
    B=1, seq_len=256: 0.0055 ms, 81.0 GB/s, memory
    B=1, seq_len=512: 0.0074 ms, 99.1 GB/s, memory
    B=1, seq_len=1024: 0.0099 ms, 134.7 GB/s, memory
    B=1, seq_len=2048: 0.0111 ms, 225.7 GB/s, memory
    B=2, seq_len=128: 0.0057 ms, 104.2 GB/s, memory
    B=2, seq_len=256: 0.0056 ms, 156.8 GB/s, memory
    B=2, seq_len=512: 0.0076 ms, 193.6 GB/s, memory
    B=2, seq_len=1024: 0.0097 ms, 272.8 GB/s, memory
    B=2, seq_len=2048: 0.0114 ms, 441.6 GB/s, memory
    B=4, seq_len=128: 0.0064 ms, 185.4 GB/s, memory
    B=4, seq_len=256: 0.0064 ms, 275.4 GB/s, memory
    B=4, seq_len=512: 0.0083 ms, 353.5 GB/s, memory
    B=4, seq_len=1024: 0.0109 ms, 487.6 GB/s, memory
    B=4, seq_len=2048: 0.0143 ms, 701.9 GB/s, memory
    B=8, seq_len=128: 0.0070 ms, 339.3 GB/s, memory
    B=8, seq_len=256: 0.0069 ms, 513.2 GB/s, memory
    B=8, seq_len=512: 0.0095 ms, 623.4 GB/s, memory
    B=8, seq_len=1024: 0.0136 ms, 783.0 GB/s, memory
    B=8, seq_len=2048: 0.0203 ms, 987.6 GB/s, memory
    B=16, seq_len=128: 0.0082 ms, 578.3 GB/s, memory
    B=16, seq_len=256: 0.0081 ms, 868.9 GB/s, memory
    B=16, seq_len=512: 0.0116 ms, 1013.4 GB/s, memory
    B=16, seq_len=1024: 0.0184 ms, 1151.3 GB/s, memory
    B=16, seq_len=2048: 0.0155 ms, 2588.2 GB/s, memory
    B=32, seq_len=128: 0.0072 ms, 1309.3 GB/s, memory
    B=32, seq_len=256: 0.0084 ms, 1675.8 GB/s, memory
    B=32, seq_len=512: 0.0140 ms, 1682.8 GB/s, memory
    B=32, seq_len=1024: 0.0170 ms, 2492.9 GB/s, memory
    B=32, seq_len=2048: 0.0233 ms, 3439.0 GB/s, memory
    B=64, seq_len=128: 0.0081 ms, 2330.9 GB/s, memory
    B=64, seq_len=256: 0.0098 ms, 2877.2 GB/s, memory
    B=64, seq_len=512: 0.0127 ms, 3716.0 GB/s, memory
    B=64, seq_len=1024: 0.0189 ms, 4489.2 GB/s, memory
    B=64, seq_len=2048: 0.0422 ms, 3802.7 GB/s, memory
    B=128, seq_len=128: 0.0124 ms, 3034.5 GB/s, memory
    B=128, seq_len=256: 0.0168 ms, 3362.7 GB/s, memory
    B=128, seq_len=512: 0.0238 ms, 3959.2 GB/s, memory
    B=128, seq_len=1024: 0.0472 ms, 3596.5 GB/s, memory
    B=128, seq_len=2048: 0.0852 ms, 3764.4 GB/s, memory
Saved ../results/trtllm_batch_decode_with_kv_cache_mla.csv

[OK] trtllm_batch_decode_with_kv_cache_mla completed successfully

======================================================================
Running: trtllm_ragged_attention_deepseek (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_ragged_attention_deepseek (Kernel #9)
============================================================

=== Prefill Phase (TRT-LLM Ragged Attention) ===
  B=1, S=128: 0.0072 ms, 739.2 GFLOPS, memory
  B=1, S=256: 0.0104 ms, 3287.9 GFLOPS, memory
  B=1, S=512: 0.0186 ms, 4755.7 GFLOPS, memory
  B=1, S=1024: 0.0356 ms, 7647.3 GFLOPS, memory
  B=1, S=2048: 0.0836 ms, 11257.3 GFLOPS, memory
  B=2, S=128: 0.0117 ms, 1163.0 GFLOPS, memory
  B=2, S=256: 0.0176 ms, 4300.4 GFLOPS, memory
  B=2, S=512: 0.0356 ms, 5278.2 GFLOPS, memory
  B=2, S=1024: 0.0903 ms, 9159.6 GFLOPS, memory
  B=2, S=2048: 0.2511 ms, 13797.8 GFLOPS, memory
  B=4, S=128: 0.0196 ms, 1601.9 GFLOPS, memory
  B=4, S=256: 0.0341 ms, 3499.4 GFLOPS, memory
  B=4, S=512: 0.0741 ms, 6271.6 GFLOPS, memory
  B=4, S=1024: 0.1568 ms, 9847.1 GFLOPS, memory
  B=4, S=2048: 0.4797 ms, 13971.2 GFLOPS, memory
  B=8, S=128: 0.0351 ms, 1813.3 GFLOPS, memory
  B=8, S=256: 0.0593 ms, 3732.9 GFLOPS, memory
  B=8, S=512: 0.1347 ms, 6100.2 GFLOPS, memory
  B=8, S=1024: 0.3353 ms, 9439.1 GFLOPS, memory
  B=8, S=2048: 0.9745 ms, 13917.5 GFLOPS, memory
  B=16, S=128: 0.0651 ms, 1765.5 GFLOPS, memory
  B=16, S=256: 0.1132 ms, 3865.9 GFLOPS, memory
  B=16, S=512: 0.2739 ms, 6231.4 GFLOPS, memory
  B=16, S=1024: 0.7101 ms, 9907.8 GFLOPS, memory
  B=16, S=2048: 2.0186 ms, 14151.2 GFLOPS, memory
  B=32, S=128: 0.1268 ms, 1730.2 GFLOPS, memory
  B=32, S=256: 0.2248 ms, 3966.7 GFLOPS, memory
  B=32, S=512: 0.5594 ms, 6561.2 GFLOPS, memory
  B=32, S=1024: 1.4343 ms, 10171.4 GFLOPS, memory
  B=32, S=2048: 4.1037 ms, 14770.5 GFLOPS, memory
  B=64, S=128: 0.2470 ms, 1754.3 GFLOPS, memory
  B=64, S=256: 0.4480 ms, 3750.8 GFLOPS, memory
  B=64, S=512: 1.1146 ms, 6465.1 GFLOPS, memory
  B=64, S=1024: 2.8861 ms, 10226.1 GFLOPS, memory
  B=64, S=2048: 7.8170 ms, 14813.3 GFLOPS, memory
  B=128, S=128: 0.4912 ms, 1825.6 GFLOPS, memory
  B=128, S=256: 0.8824 ms, 3875.2 GFLOPS, memory
  B=128, S=512: 2.2557 ms, 6210.6 GFLOPS, memory
  B=128, S=1024: 5.5675 ms, 10078.4 GFLOPS, memory
Warning: Kernel failed for B=128, S=2048: Error in function 'aligned_alloc' at /usr/local/lib/python3.12/dist-packages/flashinfer/data/include/flashinfer/allocator.h:49: Buffer overflow when allocating memory for trtllm_gen_softmax_workspace with size 200737792 and alignment 16, but only 125829120 bytes available in AlignedAllocator. Increase the workspace buffer size.
Saved ../results/trtllm_ragged_attention_deepseek.csv

[OK] trtllm_ragged_attention_deepseek completed successfully

======================================================================
Running: mla_rope_quantize_fp8 (Attention, Memory)
======================================================================
============================================================
Benchmark: rope_quantize_fp8 (MLA config) (Kernel #10)
MLA: 128 Q heads, 1 K head, 64 rope_dim + 512 no_rope_dim
============================================================

=== MLA RoPE + FP8 Quantization ===
  tokens=128: 0.0064 ms, 4638.1 GB/s, 58.0% peak
  tokens=256: 0.0114 ms, 5097.4 GB/s, 63.7% peak
  tokens=512: 0.0237 ms, 4856.8 GB/s, 60.7% peak
  tokens=1024: 0.0465 ms, 4932.5 GB/s, 61.7% peak
  tokens=2048: 0.0917 ms, 4992.4 GB/s, 62.4% peak
  tokens=4096: 0.1833 ms, 4986.1 GB/s, 62.3% peak
  tokens=8192: 0.3674 ms, 4976.4 GB/s, 62.2% peak
  tokens=16384: 0.7536 ms, 4851.8 GB/s, 60.6% peak
  tokens=32768: 1.5394 ms, 4750.4 GB/s, 59.4% peak
  tokens=65536: 3.0659 ms, 4770.5 GB/s, 59.6% peak
  tokens=131072: 6.1875 ms, 4727.4 GB/s, 59.1% peak
  tokens=262144: 13.9208 ms, 4202.5 GB/s, 52.5% peak
Saved ../results/mla_rope_quantize_fp8.csv

[OK] mla_rope_quantize_fp8 completed successfully

======================================================================
Running: apply_rope_with_cos_sin_cache_inplace (RoPE, Memory)
======================================================================
============================================================
Benchmark: apply_rope_with_cos_sin_cache_inplace (Kernel #11)
============================================================

=== Decode Phase ===
  B=1: 0.0017 ms, 347.8 GB/s, 4.3% peak
  B=2: 0.0017 ms, 379.0 GB/s, 4.7% peak
  B=4: 0.0017 ms, 455.2 GB/s, 5.7% peak
  B=8: 0.0018 ms, 595.7 GB/s, 7.4% peak
  B=16: 0.0018 ms, 882.7 GB/s, 11.0% peak
  B=32: 0.0019 ms, 1359.9 GB/s, 17.0% peak
  B=64: 0.0022 ms, 2161.8 GB/s, 27.0% peak
  B=128: 0.0033 ms, 2705.9 GB/s, 33.8% peak

=== Prefill Phase ===
  B=1, S=128: 0.0033 ms, 2685.6 GB/s, 33.6% peak
  B=1, S=256: 0.0046 ms, 3729.5 GB/s, 46.6% peak
  B=1, S=512: 0.0073 ms, 4654.0 GB/s, 58.2% peak
  B=1, S=1024: 0.0128 ms, 5288.8 GB/s, 66.1% peak
  B=1, S=2048: 0.0240 ms, 5605.0 GB/s, 70.1% peak
  B=2, S=128: 0.0047 ms, 3719.3 GB/s, 46.5% peak
  B=2, S=256: 0.0073 ms, 4655.5 GB/s, 58.2% peak
  B=2, S=512: 0.0128 ms, 5294.0 GB/s, 66.2% peak
  B=2, S=1024: 0.0244 ms, 5527.5 GB/s, 69.1% peak
  B=2, S=2048: 0.0679 ms, 3963.9 GB/s, 49.5% peak
  B=4, S=128: 0.0073 ms, 4655.6 GB/s, 58.2% peak
  B=4, S=256: 0.0127 ms, 5343.8 GB/s, 66.8% peak
  B=4, S=512: 0.0239 ms, 5650.0 GB/s, 70.6% peak
  B=4, S=1024: 0.0671 ms, 4011.4 GB/s, 50.1% peak
  B=4, S=2048: 0.1384 ms, 3883.7 GB/s, 48.5% peak
  B=8, S=128: 0.0126 ms, 5352.5 GB/s, 66.9% peak
  B=8, S=256: 0.0247 ms, 5451.0 GB/s, 68.1% peak
  B=8, S=512: 0.0669 ms, 4018.6 GB/s, 50.2% peak
  B=8, S=1024: 0.1385 ms, 3880.3 GB/s, 48.5% peak
  B=8, S=2048: 0.2832 ms, 3793.5 GB/s, 47.4% peak
Saved ../results/apply_rope_with_cos_sin_cache_inplace.csv

[OK] apply_rope_with_cos_sin_cache_inplace completed successfully

======================================================================
Running: concat_mla_k (Concat, Memory)
======================================================================
============================================================
Benchmark: concat_mla_k (Kernel #12)
============================================================

=== Decode Phase ===
  B=1: 0.0022 ms, 37.3 GB/s, 0.5% peak
  B=2: 0.0031 ms, 53.3 GB/s, 0.7% peak
  B=4: 0.0049 ms, 66.9 GB/s, 0.8% peak
  B=8: 0.0049 ms, 132.9 GB/s, 1.7% peak
  B=16: 0.0049 ms, 266.3 GB/s, 3.3% peak
  B=32: 0.0049 ms, 532.8 GB/s, 6.7% peak
  B=64: 0.0049 ms, 1065.4 GB/s, 13.3% peak
  B=128: 0.0049 ms, 2130.8 GB/s, 26.6% peak

=== Prefill Phase ===
  B=1, S=128: 0.0049 ms, 2131.0 GB/s, 26.6% peak
  B=1, S=256: 0.0050 ms, 4223.5 GB/s, 52.8% peak
  B=1, S=512: 0.0053 ms, 7902.4 GB/s, 98.8% peak
  B=1, S=1024: 0.0106 ms, 7918.4 GB/s, 99.0% peak
  B=1, S=2048: 0.0273 ms, 6147.0 GB/s, 76.8% peak
  B=2, S=128: 0.0050 ms, 4213.3 GB/s, 52.7% peak
  B=2, S=256: 0.0052 ms, 8106.4 GB/s, 101.3% peak
  B=2, S=512: 0.0097 ms, 8660.6 GB/s, 108.3% peak
  B=2, S=1024: 0.0272 ms, 6185.9 GB/s, 77.3% peak
  B=2, S=2048: 0.0523 ms, 6422.0 GB/s, 80.3% peak
  B=4, S=128: 0.0052 ms, 8139.5 GB/s, 101.7% peak
  B=4, S=256: 0.0094 ms, 8925.4 GB/s, 111.6% peak
  B=4, S=512: 0.0272 ms, 6170.0 GB/s, 77.1% peak
  B=4, S=1024: 0.0523 ms, 6424.9 GB/s, 80.3% peak
  B=4, S=2048: 0.1013 ms, 6634.9 GB/s, 82.9% peak
  B=8, S=128: 0.0095 ms, 8880.6 GB/s, 111.0% peak
  B=8, S=256: 0.0275 ms, 6111.1 GB/s, 76.4% peak
  B=8, S=512: 0.0528 ms, 6364.0 GB/s, 79.6% peak
  B=8, S=1024: 0.1014 ms, 6629.5 GB/s, 82.9% peak
  B=8, S=2048: 0.1988 ms, 6762.8 GB/s, 84.5% peak
Saved ../results/concat_mla_k.csv

[OK] concat_mla_k completed successfully

======================================================================
Running: silu_and_mul (Activation, Memory)
======================================================================
============================================================
Benchmark: silu_and_mul (Kernel #13)
============================================================

=== Decode Phase ===
  B=1: 0.0019 ms, 6.4 GB/s, 0.1% peak
  B=2: 0.0019 ms, 12.8 GB/s, 0.2% peak
  B=4: 0.0019 ms, 25.6 GB/s, 0.3% peak
  B=8: 0.0019 ms, 51.4 GB/s, 0.6% peak
  B=16: 0.0019 ms, 104.1 GB/s, 1.3% peak
  B=32: 0.0019 ms, 207.8 GB/s, 2.6% peak
  B=64: 0.0019 ms, 409.6 GB/s, 5.1% peak
  B=128: 0.0019 ms, 810.0 GB/s, 10.1% peak

=== Prefill Phase ===
  B=1, S=128: 0.0020 ms, 774.3 GB/s, 9.7% peak
  B=1, S=256: 0.0021 ms, 1472.5 GB/s, 18.4% peak
  B=1, S=512: 0.0028 ms, 2222.7 GB/s, 27.8% peak
  B=1, S=1024: 0.0038 ms, 3313.5 GB/s, 41.4% peak
  B=1, S=2048: 0.0058 ms, 4356.5 GB/s, 54.5% peak
  B=2, S=128: 0.0021 ms, 1468.8 GB/s, 18.4% peak
  B=2, S=256: 0.0028 ms, 2229.3 GB/s, 27.9% peak
  B=2, S=512: 0.0038 ms, 3315.0 GB/s, 41.4% peak
  B=2, S=1024: 0.0058 ms, 4355.2 GB/s, 54.4% peak
  B=2, S=2048: 0.0099 ms, 5084.6 GB/s, 63.6% peak
  B=4, S=128: 0.0028 ms, 2229.5 GB/s, 27.9% peak
  B=4, S=256: 0.0038 ms, 3314.4 GB/s, 41.4% peak
  B=4, S=512: 0.0058 ms, 4353.0 GB/s, 54.4% peak
  B=4, S=1024: 0.0099 ms, 5083.7 GB/s, 63.5% peak
  B=4, S=2048: 0.0197 ms, 5109.2 GB/s, 63.9% peak
  B=8, S=128: 0.0038 ms, 3275.4 GB/s, 40.9% peak
  B=8, S=256: 0.0058 ms, 4333.4 GB/s, 54.2% peak
  B=8, S=512: 0.0099 ms, 5083.3 GB/s, 63.5% peak
  B=8, S=1024: 0.0196 ms, 5124.9 GB/s, 64.1% peak
  B=8, S=2048: 0.0399 ms, 5049.4 GB/s, 63.1% peak
Saved ../results/silu_and_mul.csv

[OK] silu_and_mul completed successfully

======================================================================
Running: topk_softmax (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_softmax (Kernel #14)
============================================================

=== Decode Phase ===
  B=1: 0.0035 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0035 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0035 ms, 1.2 GB/s, 0.0% peak
  B=8: 0.0036 ms, 2.4 GB/s, 0.0% peak
  B=16: 0.0036 ms, 4.9 GB/s, 0.1% peak
  B=32: 0.0035 ms, 9.8 GB/s, 0.1% peak
  B=64: 0.0035 ms, 19.6 GB/s, 0.2% peak
  B=128: 0.0036 ms, 39.2 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0035 ms, 39.2 GB/s, 0.5% peak
  B=1, S=256: 0.0036 ms, 78.4 GB/s, 1.0% peak
  B=1, S=512: 0.0036 ms, 154.9 GB/s, 1.9% peak
  B=1, S=1024: 0.0039 ms, 283.4 GB/s, 3.5% peak
  B=1, S=2048: 0.0053 ms, 418.6 GB/s, 5.2% peak
  B=2, S=128: 0.0036 ms, 78.4 GB/s, 1.0% peak
  B=2, S=256: 0.0036 ms, 155.0 GB/s, 1.9% peak
  B=2, S=512: 0.0039 ms, 283.8 GB/s, 3.5% peak
  B=2, S=1024: 0.0053 ms, 418.6 GB/s, 5.2% peak
  B=2, S=2048: 0.0079 ms, 567.1 GB/s, 7.1% peak
  B=4, S=128: 0.0036 ms, 155.0 GB/s, 1.9% peak
  B=4, S=256: 0.0039 ms, 283.8 GB/s, 3.5% peak
  B=4, S=512: 0.0053 ms, 418.3 GB/s, 5.2% peak
  B=4, S=1024: 0.0079 ms, 567.0 GB/s, 7.1% peak
  B=4, S=2048: 0.0134 ms, 663.8 GB/s, 8.3% peak
  B=8, S=128: 0.0039 ms, 283.8 GB/s, 3.5% peak
  B=8, S=256: 0.0053 ms, 418.8 GB/s, 5.2% peak
  B=8, S=512: 0.0079 ms, 567.2 GB/s, 7.1% peak
  B=8, S=1024: 0.0134 ms, 663.9 GB/s, 8.3% peak
  B=8, S=2048: 0.0240 ms, 743.5 GB/s, 9.3% peak
Saved ../results/topk_softmax.csv

[OK] topk_softmax completed successfully

======================================================================
Running: topk_sigmoid (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_sigmoid (Kernel #15)
============================================================

=== Decode Phase ===
  B=1: 0.0038 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0038 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0038 ms, 1.1 GB/s, 0.0% peak
  B=8: 0.0038 ms, 2.3 GB/s, 0.0% peak
  B=16: 0.0038 ms, 4.6 GB/s, 0.1% peak
  B=32: 0.0038 ms, 9.1 GB/s, 0.1% peak
  B=64: 0.0038 ms, 18.2 GB/s, 0.2% peak
  B=128: 0.0038 ms, 36.5 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0038 ms, 36.5 GB/s, 0.5% peak
  B=1, S=256: 0.0038 ms, 72.9 GB/s, 0.9% peak
  B=1, S=512: 0.0039 ms, 144.5 GB/s, 1.8% peak
  B=1, S=1024: 0.0041 ms, 268.9 GB/s, 3.4% peak
  B=1, S=2048: 0.0054 ms, 411.9 GB/s, 5.1% peak
  B=2, S=128: 0.0038 ms, 72.9 GB/s, 0.9% peak
  B=2, S=256: 0.0039 ms, 144.5 GB/s, 1.8% peak
  B=2, S=512: 0.0041 ms, 268.8 GB/s, 3.4% peak
  B=2, S=1024: 0.0054 ms, 412.1 GB/s, 5.2% peak
  B=2, S=2048: 0.0078 ms, 571.5 GB/s, 7.1% peak
  B=4, S=128: 0.0039 ms, 144.5 GB/s, 1.8% peak
  B=4, S=256: 0.0041 ms, 268.9 GB/s, 3.4% peak
  B=4, S=512: 0.0054 ms, 412.0 GB/s, 5.2% peak
  B=4, S=1024: 0.0078 ms, 571.8 GB/s, 7.1% peak
  B=4, S=2048: 0.0131 ms, 680.0 GB/s, 8.5% peak
  B=8, S=128: 0.0041 ms, 269.2 GB/s, 3.4% peak
  B=8, S=256: 0.0054 ms, 412.1 GB/s, 5.2% peak
  B=8, S=512: 0.0078 ms, 571.7 GB/s, 7.1% peak
  B=8, S=1024: 0.0131 ms, 679.6 GB/s, 8.5% peak
  B=8, S=2048: 0.0231 ms, 771.3 GB/s, 9.6% peak
Saved ../results/topk_sigmoid.csv

[OK] topk_sigmoid completed successfully

======================================================================
Running: moe_fused_gate (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: moe_fused_gate (Kernel #16)
============================================================

=== Decode Phase ===
  B=1: 0.0111 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0113 ms, 0.3 GB/s, 0.0% peak
  B=4: 0.0115 ms, 0.5 GB/s, 0.0% peak
  B=8: 0.0122 ms, 0.8 GB/s, 0.0% peak
  B=16: 0.0139 ms, 1.3 GB/s, 0.0% peak
  B=32: 0.0160 ms, 2.2 GB/s, 0.0% peak
  B=64: 0.0158 ms, 4.5 GB/s, 0.1% peak
  B=128: 0.0161 ms, 8.7 GB/s, 0.1% peak

=== Prefill Phase ===
  B=1, S=128: 0.0161 ms, 8.7 GB/s, 0.1% peak
  B=1, S=256: 0.0160 ms, 17.5 GB/s, 0.2% peak
  B=1, S=512: 0.0161 ms, 34.6 GB/s, 0.4% peak
  B=1, S=1024: 0.0161 ms, 69.4 GB/s, 0.9% peak
  B=1, S=2048: 0.0160 ms, 139.5 GB/s, 1.7% peak
  B=2, S=128: 0.0159 ms, 17.6 GB/s, 0.2% peak
  B=2, S=256: 0.0160 ms, 34.9 GB/s, 0.4% peak
  B=2, S=512: 0.0160 ms, 69.8 GB/s, 0.9% peak
  B=2, S=1024: 0.0162 ms, 137.8 GB/s, 1.7% peak
  B=2, S=2048: 0.0222 ms, 200.6 GB/s, 2.5% peak
  B=4, S=128: 0.0160 ms, 34.8 GB/s, 0.4% peak
  B=4, S=256: 0.0159 ms, 70.0 GB/s, 0.9% peak
  B=4, S=512: 0.0161 ms, 138.6 GB/s, 1.7% peak
  B=4, S=1024: 0.0219 ms, 203.1 GB/s, 2.5% peak
  B=4, S=2048: 0.0292 ms, 305.6 GB/s, 3.8% peak
  B=8, S=128: 0.0160 ms, 69.8 GB/s, 0.9% peak
  B=8, S=256: 0.0160 ms, 139.0 GB/s, 1.7% peak
  B=8, S=512: 0.0219 ms, 203.5 GB/s, 2.5% peak
  B=8, S=1024: 0.0289 ms, 308.2 GB/s, 3.9% peak
  B=8, S=2048: 0.0456 ms, 391.3 GB/s, 4.9% peak
Saved ../results/moe_fused_gate.csv

[OK] moe_fused_gate completed successfully

======================================================================
Running: prepare_moe_input (MoE, Memory)
======================================================================
============================================================
Benchmark: prepare_moe_input (Kernel #17)
============================================================

=== Decode Phase ===
  B=1: 0.0157 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0158 ms, 0.2 GB/s, 0.0% peak
  B=4: 0.0157 ms, 0.2 GB/s, 0.0% peak
  B=8: 0.0159 ms, 0.2 GB/s, 0.0% peak
  B=16: 0.0160 ms, 0.3 GB/s, 0.0% peak
  B=32: 0.0151 ms, 0.4 GB/s, 0.0% peak
  B=64: 0.0145 ms, 0.6 GB/s, 0.0% peak
  B=128: 0.0148 ms, 1.0 GB/s, 0.0% peak

=== Prefill Phase ===
  B=1, S=128: 0.0149 ms, 1.0 GB/s, 0.0% peak
  B=1, S=256: 0.0169 ms, 1.6 GB/s, 0.0% peak
  B=1, S=512: 0.0186 ms, 2.8 GB/s, 0.0% peak
  B=1, S=1024: 0.0223 ms, 4.5 GB/s, 0.1% peak
  B=1, S=2048: 0.0326 ms, 6.1 GB/s, 0.1% peak
  B=2, S=128: 0.0166 ms, 1.7 GB/s, 0.0% peak
  B=2, S=256: 0.0185 ms, 2.8 GB/s, 0.0% peak
  B=2, S=512: 0.0218 ms, 4.6 GB/s, 0.1% peak
  B=2, S=1024: 0.0329 ms, 6.1 GB/s, 0.1% peak
  B=2, S=2048: 0.0445 ms, 8.9 GB/s, 0.1% peak
  B=4, S=128: 0.0182 ms, 2.9 GB/s, 0.0% peak
  B=4, S=256: 0.0220 ms, 4.6 GB/s, 0.1% peak
  B=4, S=512: 0.0329 ms, 6.1 GB/s, 0.1% peak
  B=4, S=1024: 0.0448 ms, 8.8 GB/s, 0.1% peak
  B=4, S=2048: 0.0736 ms, 10.7 GB/s, 0.1% peak
  B=8, S=128: 0.0230 ms, 4.4 GB/s, 0.1% peak
  B=8, S=256: 0.0327 ms, 6.1 GB/s, 0.1% peak
  B=8, S=512: 0.0463 ms, 8.6 GB/s, 0.1% peak
  B=8, S=1024: 0.0725 ms, 10.9 GB/s, 0.1% peak
  B=8, S=2048: 0.1287 ms, 12.2 GB/s, 0.2% peak
Saved ../results/prepare_moe_input.csv

[OK] prepare_moe_input completed successfully

======================================================================
Running: scaled_fp4_experts_quant (MoE, Memory)
======================================================================
============================================================
Benchmark: scaled_fp4_experts_quant (Kernel #18)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=2, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=4, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=8, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=16, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=32, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=64, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=128, S=1: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=1, S=256: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=1, S=512: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=1, S=1024: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=1, S=2048: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=2, S=128: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=2, S=256: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=2, S=512: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=2, S=1024: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=2, S=2048: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=4, S=128: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=4, S=256: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=4, S=512: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=4, S=1024: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=4, S=2048: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=8, S=128: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=8, S=256: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=8, S=512: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=8, S=1024: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Warning: Kernel failed for B=8, S=2048: Expected input_global_scale.dim() == 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)

No results - kernel not available

[FAILED] scaled_fp4_experts_quant: No CSV output (kernel not available or all runs failed)

======================================================================
Running: cutlass_fp4_group_mm (MoE, Compute)
======================================================================
============================================================
Benchmark: cutlass_fp4_group_mm (Kernel #19)
============================================================

=== Decode Phase: gate_up ===
Warning: Kernel failed for B=1, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=16, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=32, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=64, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=128, S=1, op=gate_up: Number of experts in problem_sizes must match expert_offsets

=== Decode Phase: down ===
Warning: Kernel failed for B=1, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=16, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=32, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=64, S=1, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=128, S=1, op=down: Number of experts in problem_sizes must match expert_offsets

=== Prefill Phase: gate_up ===
Warning: Kernel failed for B=1, S=128, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=256, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=512, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=1024, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=2048, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=128, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=256, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=512, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=1024, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=2048, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=128, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=256, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=512, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=1024, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=2048, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=128, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=256, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=512, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=1024, op=gate_up: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=2048, op=gate_up: Number of experts in problem_sizes must match expert_offsets

=== Prefill Phase: down ===
Warning: Kernel failed for B=1, S=128, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=256, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=512, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=1024, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=1, S=2048, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=128, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=256, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=512, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=1024, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=2, S=2048, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=128, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=256, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=512, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=1024, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=4, S=2048, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=128, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=256, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=512, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=1024, op=down: Number of experts in problem_sizes must match expert_offsets
Warning: Kernel failed for B=8, S=2048, op=down: Number of experts in problem_sizes must match expert_offsets

No results - kernel not available

[FAILED] cutlass_fp4_group_mm: No CSV output (kernel not available or all runs failed)

======================================================================
Running: apply_shuffle_mul_sum (MoE, Memory)
======================================================================
============================================================
Benchmark: apply_shuffle_mul_sum (Kernel #20)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: Factors must match output dtype
Warning: Kernel failed for B=2, S=1: Factors must match output dtype
Warning: Kernel failed for B=4, S=1: Factors must match output dtype
Warning: Kernel failed for B=8, S=1: Factors must match output dtype
Warning: Kernel failed for B=16, S=1: Factors must match output dtype
Warning: Kernel failed for B=32, S=1: Factors must match output dtype
Warning: Kernel failed for B=64, S=1: Factors must match output dtype
Warning: Kernel failed for B=128, S=1: Factors must match output dtype

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: Factors must match output dtype
Warning: Kernel failed for B=1, S=256: Factors must match output dtype
Warning: Kernel failed for B=1, S=512: Factors must match output dtype
Warning: Kernel failed for B=1, S=1024: Factors must match output dtype
Warning: Kernel failed for B=1, S=2048: Factors must match output dtype
Warning: Kernel failed for B=2, S=128: Factors must match output dtype
Warning: Kernel failed for B=2, S=256: Factors must match output dtype
Warning: Kernel failed for B=2, S=512: Factors must match output dtype
Warning: Kernel failed for B=2, S=1024: Factors must match output dtype
Warning: Kernel failed for B=2, S=2048: Factors must match output dtype
Warning: Kernel failed for B=4, S=128: Factors must match output dtype
Warning: Kernel failed for B=4, S=256: Factors must match output dtype
Warning: Kernel failed for B=4, S=512: Factors must match output dtype
Warning: Kernel failed for B=4, S=1024: Factors must match output dtype
Warning: Kernel failed for B=4, S=2048: Factors must match output dtype
Warning: Kernel failed for B=8, S=128: Factors must match output dtype
Warning: Kernel failed for B=8, S=256: Factors must match output dtype
Warning: Kernel failed for B=8, S=512: Factors must match output dtype
Warning: Kernel failed for B=8, S=1024: Factors must match output dtype
Warning: Kernel failed for B=8, S=2048: Factors must match output dtype

No results - kernel not available

[FAILED] apply_shuffle_mul_sum: No CSV output (kernel not available or all runs failed)

======================================================================
Running: moe_align_block_size (MoE, Memory)
======================================================================
============================================================
Benchmark: moe_align_block_size (Kernel #21)
============================================================

=== Decode Phase ===
  B=1: 0.0045 ms, 15.1 GB/s, 0.2% peak
  B=2: 0.0045 ms, 15.0 GB/s, 0.2% peak
  B=4: 0.0045 ms, 15.0 GB/s, 0.2% peak
  B=8: 0.0045 ms, 15.0 GB/s, 0.2% peak
  B=16: 0.0046 ms, 15.0 GB/s, 0.2% peak
  B=32: 0.0045 ms, 15.6 GB/s, 0.2% peak
  B=64: 0.0045 ms, 16.0 GB/s, 0.2% peak
  B=128: 0.0045 ms, 16.7 GB/s, 0.2% peak

=== Prefill Phase ===
  B=1, S=128: 0.0045 ms, 16.8 GB/s, 0.2% peak
  B=1, S=256: 0.0049 ms, 17.1 GB/s, 0.2% peak
  B=1, S=512: 0.0058 ms, 17.4 GB/s, 0.2% peak
  B=1, S=1024: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=1, S=2048: 0.0088 ms, 22.8 GB/s, 0.3% peak
  B=2, S=128: 0.0049 ms, 17.1 GB/s, 0.2% peak
  B=2, S=256: 0.0058 ms, 17.4 GB/s, 0.2% peak
  B=2, S=512: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=2, S=1024: 0.0087 ms, 22.9 GB/s, 0.3% peak
  B=2, S=2048: 0.0135 ms, 24.6 GB/s, 0.3% peak
  B=4, S=128: 0.0058 ms, 17.4 GB/s, 0.2% peak
  B=4, S=256: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=4, S=512: 0.0088 ms, 22.8 GB/s, 0.3% peak
  B=4, S=1024: 0.0135 ms, 24.6 GB/s, 0.3% peak
  B=4, S=2048: 0.0231 ms, 25.8 GB/s, 0.3% peak
  B=8, S=128: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=8, S=256: 0.0087 ms, 22.9 GB/s, 0.3% peak
  B=8, S=512: 0.0136 ms, 24.4 GB/s, 0.3% peak
  B=8, S=1024: 0.0231 ms, 25.8 GB/s, 0.3% peak
  B=8, S=2048: 0.0418 ms, 26.9 GB/s, 0.3% peak
Saved ../results/moe_align_block_size.csv

[OK] moe_align_block_size completed successfully

======================================================================
Running: trtllm_fp4_block_scale_moe (MoE, Mixed)
======================================================================
============================================================
Benchmark: trtllm_fp4_block_scale_moe (Kernel #22)
============================================================

=== Decode Phase ===
  B=1: Skipped (minimum batch size for FP4 MoE is 2)
Warning: Kernel failed for B=2, S=1: Error in function 'run' at /usr/local/lib/python3.12/dist-packages/flashinfer/data/csrc/trtllm_batched_gemm_runner.cu:258: Error occurred when running GEMM! (numBatches:  256 , GemmMNK:  2   4096   7168 , Kernel:  bmm_E2m1_E2m1E2m1_Fp32_t128x8x512u2_s5_et128x8_m128x8x64_cga1x1x1_16dp256b_rM_TN_transOut_schedP2x1x2x3_bN_ldgsts_tmaOpt_clmp_swiGlu_dynBatch_sm100f )

[FAILED] trtllm_fp4_block_scale_moe: Exit code 1

======================================================================
Running: fused_moe_kernel (MoE, Mixed)
======================================================================
============================================================
Benchmark: fused_moe_kernel (Kernel #23)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: 'module' object is not callable
Warning: Kernel failed for B=2, S=1: 'module' object is not callable
Warning: Kernel failed for B=4, S=1: 'module' object is not callable
Warning: Kernel failed for B=8, S=1: 'module' object is not callable
Warning: Kernel failed for B=16, S=1: 'module' object is not callable
Warning: Kernel failed for B=32, S=1: 'module' object is not callable
Warning: Kernel failed for B=64, S=1: 'module' object is not callable
Warning: Kernel failed for B=128, S=1: 'module' object is not callable

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: 'module' object is not callable
Warning: Kernel failed for B=1, S=256: 'module' object is not callable
Warning: Kernel failed for B=1, S=512: 'module' object is not callable
Warning: Kernel failed for B=1, S=1024: 'module' object is not callable
Warning: Kernel failed for B=1, S=2048: 'module' object is not callable
Warning: Kernel failed for B=2, S=128: 'module' object is not callable
Warning: Kernel failed for B=2, S=256: 'module' object is not callable
Warning: Kernel failed for B=2, S=512: 'module' object is not callable
Warning: Kernel failed for B=2, S=1024: 'module' object is not callable
Warning: Kernel failed for B=2, S=2048: 'module' object is not callable
Warning: Kernel failed for B=4, S=128: 'module' object is not callable
Warning: Kernel failed for B=4, S=256: 'module' object is not callable
Warning: Kernel failed for B=4, S=512: 'module' object is not callable
Warning: Kernel failed for B=4, S=1024: 'module' object is not callable
Warning: Kernel failed for B=4, S=2048: 'module' object is not callable
Warning: Kernel failed for B=8, S=128: 'module' object is not callable
Warning: Kernel failed for B=8, S=256: 'module' object is not callable
Warning: Kernel failed for B=8, S=512: 'module' object is not callable
Warning: Kernel failed for B=8, S=1024: 'module' object is not callable
Warning: Kernel failed for B=8, S=2048: 'module' object is not callable

No results - kernel not available

[FAILED] fused_moe_kernel: No CSV output (kernel not available or all runs failed)

Aggregated results saved to ../results/all_kernels.csv
Total benchmark results: 531

Summary saved to ../results/benchmark_summary.md

======================================================================
Benchmark Complete!
Successful: 18/23
Failed kernels:
  - scaled_fp4_experts_quant: No CSV output (kernel not available or all runs failed)
  - cutlass_fp4_group_mm: No CSV output (kernel not available or all runs failed)
  - apply_shuffle_mul_sum: No CSV output (kernel not available or all runs failed)
  - trtllm_fp4_block_scale_moe: Exit code 1
  - fused_moe_kernel: No CSV output (kernel not available or all runs failed)
======================================================================
