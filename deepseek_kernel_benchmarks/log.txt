======================================================================
DeepSeek-R1-NVFP4-v2 Kernel Benchmarks
======================================================================
Kernels to run: 23
Batch sizes: 1,2,4,8,16,32,64,128
Sequence lengths: 128,256,512,1024,2048
Output directory: ../results/

NOTE: Each kernel runs in a separate subprocess for isolation.
      CUDA crashes in one kernel will NOT affect other kernels.
======================================================================

======================================================================
Running: rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: rmsnorm (Kernel #1)
============================================================

=== Decode Phase ===
  B=1: 0.0019 ms, 15.1 GB/s, 0.2% peak
  B=2: 0.0019 ms, 30.0 GB/s, 0.4% peak
  B=4: 0.0019 ms, 59.4 GB/s, 0.7% peak
  B=8: 0.0019 ms, 119.6 GB/s, 1.5% peak
  B=16: 0.0020 ms, 232.8 GB/s, 2.9% peak
  B=32: 0.0020 ms, 467.2 GB/s, 5.8% peak
  B=64: 0.0020 ms, 920.1 GB/s, 11.5% peak
  B=128: 0.0021 ms, 1781.5 GB/s, 22.3% peak

=== Prefill Phase ===
  B=1, S=128: 0.0021 ms, 1781.6 GB/s, 22.3% peak
  B=1, S=256: 0.0027 ms, 2766.9 GB/s, 34.6% peak
  B=1, S=512: 0.0046 ms, 3175.0 GB/s, 39.7% peak
  B=1, S=1024: 0.0081 ms, 3625.6 GB/s, 45.3% peak
  B=1, S=2048: 0.0149 ms, 3930.6 GB/s, 49.1% peak
  B=2, S=128: 0.0027 ms, 2768.0 GB/s, 34.6% peak
  B=2, S=256: 0.0046 ms, 3175.4 GB/s, 39.7% peak
  B=2, S=512: 0.0081 ms, 3625.4 GB/s, 45.3% peak
  B=2, S=1024: 0.0150 ms, 3918.7 GB/s, 49.0% peak
  B=2, S=2048: 0.0360 ms, 3258.6 GB/s, 40.7% peak
  B=4, S=128: 0.0046 ms, 3160.3 GB/s, 39.5% peak
  B=4, S=256: 0.0081 ms, 3623.3 GB/s, 45.3% peak
  B=4, S=512: 0.0150 ms, 3919.9 GB/s, 49.0% peak
  B=4, S=1024: 0.0364 ms, 3222.4 GB/s, 40.3% peak
  B=4, S=2048: 0.0704 ms, 3335.6 GB/s, 41.7% peak
  B=8, S=128: 0.0081 ms, 3622.6 GB/s, 45.3% peak
  B=8, S=256: 0.0151 ms, 3892.4 GB/s, 48.7% peak
  B=8, S=512: 0.0366 ms, 3210.0 GB/s, 40.1% peak
  B=8, S=1024: 0.0704 ms, 3336.3 GB/s, 41.7% peak
  B=8, S=2048: 0.1375 ms, 3415.7 GB/s, 42.7% peak
Saved ../results/rmsnorm.csv

[OK] rmsnorm completed successfully

======================================================================
Running: fused_add_rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: fused_add_rmsnorm (Kernel #2)
============================================================

=== Decode Phase ===
  B=1: 0.0024 ms, 24.4 GB/s, 0.3% peak
  B=2: 0.0024 ms, 48.4 GB/s, 0.6% peak
  B=4: 0.0024 ms, 96.7 GB/s, 1.2% peak
  B=8: 0.0025 ms, 186.8 GB/s, 2.3% peak
  B=16: 0.0025 ms, 371.2 GB/s, 4.6% peak
  B=32: 0.0024 ms, 755.5 GB/s, 9.4% peak
  B=64: 0.0024 ms, 1507.8 GB/s, 18.8% peak
  B=128: 0.0026 ms, 2872.0 GB/s, 35.9% peak

=== Prefill Phase ===
  B=1, S=128: 0.0026 ms, 2872.9 GB/s, 35.9% peak
  B=1, S=256: 0.0045 ms, 3262.5 GB/s, 40.8% peak
  B=1, S=512: 0.0081 ms, 3633.3 GB/s, 45.4% peak
  B=1, S=1024: 0.0143 ms, 4094.5 GB/s, 51.2% peak
  B=1, S=2048: 0.0273 ms, 4307.2 GB/s, 53.8% peak
  B=2, S=128: 0.0045 ms, 3263.6 GB/s, 40.8% peak
  B=2, S=256: 0.0081 ms, 3634.2 GB/s, 45.4% peak
  B=2, S=512: 0.0142 ms, 4140.9 GB/s, 51.8% peak
  B=2, S=1024: 0.0272 ms, 4315.3 GB/s, 53.9% peak
  B=2, S=2048: 0.0674 ms, 3487.0 GB/s, 43.6% peak
  B=4, S=128: 0.0081 ms, 3637.1 GB/s, 45.5% peak
  B=4, S=256: 0.0143 ms, 4115.5 GB/s, 51.4% peak
  B=4, S=512: 0.0273 ms, 4302.5 GB/s, 53.8% peak
  B=4, S=1024: 0.0672 ms, 3497.2 GB/s, 43.7% peak
  B=4, S=2048: 0.1314 ms, 3575.9 GB/s, 44.7% peak
  B=8, S=128: 0.0142 ms, 4125.1 GB/s, 51.6% peak
  B=8, S=256: 0.0273 ms, 4295.1 GB/s, 53.7% peak
  B=8, S=512: 0.0676 ms, 3472.8 GB/s, 43.4% peak
  B=8, S=1024: 0.1316 ms, 3569.7 GB/s, 44.6% peak
  B=8, S=2048: 0.2604 ms, 3608.5 GB/s, 45.1% peak
Saved ../results/fused_add_rmsnorm.csv

[OK] fused_add_rmsnorm completed successfully

======================================================================
Running: cutlass_scaled_fp4_mm (GEMM, Compute)
======================================================================
============================================================
Benchmark: cutlass_scaled_fp4_mm (Kernel #3)
============================================================

=== Decode Phase ===
  q_b_proj B=1: 0.0063 ms, 11926.1 GFLOPS, 0.13% peak
  kv_b_proj B=1: 0.0050 ms, 6688.6 GFLOPS, 0.07% peak
  o_proj B=1: 0.0233 ms, 10092.8 GFLOPS, 0.11% peak
  q_b_proj B=2: 0.0064 ms, 23715.5 GFLOPS, 0.26% peak
  kv_b_proj B=2: 0.0051 ms, 13273.9 GFLOPS, 0.15% peak
  o_proj B=2: 0.0233 ms, 20130.3 GFLOPS, 0.22% peak
  q_b_proj B=4: 0.0063 ms, 48151.1 GFLOPS, 0.54% peak
  kv_b_proj B=4: 0.0050 ms, 26655.1 GFLOPS, 0.30% peak
  o_proj B=4: 0.0232 ms, 40420.7 GFLOPS, 0.45% peak
  q_b_proj B=8: 0.0064 ms, 94666.5 GFLOPS, 1.05% peak
  kv_b_proj B=8: 0.0051 ms, 52925.5 GFLOPS, 0.59% peak
  o_proj B=8: 0.0232 ms, 80868.2 GFLOPS, 0.90% peak
  q_b_proj B=16: 0.0063 ms, 192275.1 GFLOPS, 2.14% peak
  kv_b_proj B=16: 0.0050 ms, 107548.1 GFLOPS, 1.19% peak
  o_proj B=16: 0.0233 ms, 161546.1 GFLOPS, 1.79% peak
  q_b_proj B=32: 0.0063 ms, 382768.6 GFLOPS, 4.25% peak
  kv_b_proj B=32: 0.0050 ms, 214429.8 GFLOPS, 2.38% peak
  o_proj B=32: 0.0233 ms, 323007.7 GFLOPS, 3.59% peak
  q_b_proj B=64: 0.0064 ms, 760026.6 GFLOPS, 8.44% peak
  kv_b_proj B=64: 0.0050 ms, 427299.0 GFLOPS, 4.75% peak
  o_proj B=64: 0.0234 ms, 642706.1 GFLOPS, 7.14% peak
  q_b_proj B=128: 0.0068 ms, 1430069.9 GFLOPS, 15.89% peak
  kv_b_proj B=128: 0.0054 ms, 798412.6 GFLOPS, 8.87% peak
  o_proj B=128: 0.0239 ms, 1256413.6 GFLOPS, 13.96% peak

=== Prefill Phase ===
  q_b_proj B=1, S=128: 0.0068 ms, 1421853.0 GFLOPS, 15.80% peak
  kv_b_proj B=1, S=128: 0.0054 ms, 798303.0 GFLOPS, 8.87% peak
  o_proj B=1, S=128: 0.0239 ms, 1256434.1 GFLOPS, 13.96% peak
  q_b_proj B=1, S=256: 0.0091 ms, 2120750.4 GFLOPS, 23.56% peak
  kv_b_proj B=1, S=256: 0.0070 ms, 1226381.9 GFLOPS, 13.63% peak
  o_proj B=1, S=256: 0.0225 ms, 2676246.7 GFLOPS, 29.74% peak
  q_b_proj B=1, S=512: 0.0125 ms, 3082228.2 GFLOPS, 34.25% peak
  kv_b_proj B=1, S=512: 0.0102 ms, 1685656.1 GFLOPS, 18.73% peak
  o_proj B=1, S=512: 0.0240 ms, 5013689.7 GFLOPS, 55.71% peak
  q_b_proj B=1, S=1024: 0.0200 ms, 3869495.3 GFLOPS, 42.99% peak
  kv_b_proj B=1, S=1024: 0.0155 ms, 2210389.6 GFLOPS, 24.56% peak
  o_proj B=1, S=1024: 0.0508 ms, 4739046.0 GFLOPS, 52.66% peak
  q_b_proj B=1, S=2048: 0.0400 ms, 3866577.4 GFLOPS, 42.96% peak
  kv_b_proj B=1, S=2048: 0.0286 ms, 2404395.4 GFLOPS, 26.72% peak
  o_proj B=1, S=2048: 0.0910 ms, 5286292.0 GFLOPS, 58.74% peak
  q_b_proj B=2, S=128: 0.0092 ms, 2107944.1 GFLOPS, 23.42% peak
  kv_b_proj B=2, S=128: 0.0070 ms, 1225446.2 GFLOPS, 13.62% peak
  o_proj B=2, S=128: 0.0221 ms, 2717900.9 GFLOPS, 30.20% peak
  q_b_proj B=2, S=256: 0.0125 ms, 3093442.9 GFLOPS, 34.37% peak
  kv_b_proj B=2, S=256: 0.0102 ms, 1689855.7 GFLOPS, 18.78% peak
  o_proj B=2, S=256: 0.0257 ms, 4674995.6 GFLOPS, 51.94% peak
  q_b_proj B=2, S=512: 0.0204 ms, 3790053.8 GFLOPS, 42.11% peak
  kv_b_proj B=2, S=512: 0.0152 ms, 2257737.0 GFLOPS, 25.09% peak
  o_proj B=2, S=512: 0.0497 ms, 4834724.3 GFLOPS, 53.72% peak
  q_b_proj B=2, S=1024: 0.0400 ms, 3861089.1 GFLOPS, 42.90% peak
  kv_b_proj B=2, S=1024: 0.0284 ms, 2417925.4 GFLOPS, 26.87% peak
  o_proj B=2, S=1024: 0.0958 ms, 5023792.1 GFLOPS, 55.82% peak
  q_b_proj B=2, S=2048: 0.0751 ms, 4118591.7 GFLOPS, 45.76% peak
  kv_b_proj B=2, S=2048: 0.0524 ms, 2620393.7 GFLOPS, 29.12% peak
  o_proj B=2, S=2048: 0.1837 ms, 5236118.2 GFLOPS, 58.18% peak
  q_b_proj B=4, S=128: 0.0125 ms, 3086609.5 GFLOPS, 34.30% peak
  kv_b_proj B=4, S=128: 0.0102 ms, 1687294.8 GFLOPS, 18.75% peak
  o_proj B=4, S=128: 0.0236 ms, 5093795.9 GFLOPS, 56.60% peak
  q_b_proj B=4, S=256: 0.0200 ms, 3869550.2 GFLOPS, 43.00% peak
  kv_b_proj B=4, S=256: 0.0154 ms, 2231836.0 GFLOPS, 24.80% peak
  o_proj B=4, S=256: 0.0508 ms, 4737868.3 GFLOPS, 52.64% peak
  q_b_proj B=4, S=512: 0.0403 ms, 3841229.4 GFLOPS, 42.68% peak
  kv_b_proj B=4, S=512: 0.0287 ms, 2396495.4 GFLOPS, 26.63% peak
  o_proj B=4, S=512: 0.0925 ms, 5202961.5 GFLOPS, 57.81% peak
  q_b_proj B=4, S=1024: 0.0759 ms, 4076133.7 GFLOPS, 45.29% peak
  kv_b_proj B=4, S=1024: 0.0536 ms, 2565540.5 GFLOPS, 28.51% peak
  o_proj B=4, S=1024: 0.1827 ms, 5265212.8 GFLOPS, 58.50% peak
  q_b_proj B=4, S=2048: 0.1464 ms, 4223499.5 GFLOPS, 46.93% peak
  kv_b_proj B=4, S=2048: 0.1014 ms, 2709576.8 GFLOPS, 30.11% peak
  o_proj B=4, S=2048: 0.3609 ms, 5331034.3 GFLOPS, 59.23% peak
  q_b_proj B=8, S=128: 0.0206 ms, 3751570.6 GFLOPS, 41.68% peak
  kv_b_proj B=8, S=128: 0.0154 ms, 2225893.4 GFLOPS, 24.73% peak
  o_proj B=8, S=128: 0.0502 ms, 4790230.3 GFLOPS, 53.22% peak
  q_b_proj B=8, S=256: 0.0401 ms, 3858030.6 GFLOPS, 42.87% peak
  kv_b_proj B=8, S=256: 0.0286 ms, 2403250.7 GFLOPS, 26.70% peak
  o_proj B=8, S=256: 0.0935 ms, 5143418.6 GFLOPS, 57.15% peak
  q_b_proj B=8, S=512: 0.0758 ms, 4082161.1 GFLOPS, 45.36% peak
  kv_b_proj B=8, S=512: 0.0525 ms, 2616387.9 GFLOPS, 29.07% peak
  o_proj B=8, S=512: 0.1830 ms, 5256262.0 GFLOPS, 58.40% peak
  q_b_proj B=8, S=1024: 0.1462 ms, 4231462.7 GFLOPS, 47.02% peak
  kv_b_proj B=8, S=1024: 0.1029 ms, 2671089.8 GFLOPS, 29.68% peak
  o_proj B=8, S=1024: 0.3603 ms, 5340917.2 GFLOPS, 59.34% peak
  q_b_proj B=8, S=2048: 0.2944 ms, 4201687.4 GFLOPS, 46.69% peak
  kv_b_proj B=8, S=2048: 0.2049 ms, 2683530.8 GFLOPS, 29.82% peak
  o_proj B=8, S=2048: 0.7172 ms, 5365809.9 GFLOPS, 59.62% peak
Saved ../results/cutlass_scaled_fp4_mm.csv

[OK] cutlass_scaled_fp4_mm completed successfully

======================================================================
Running: dsv3_fused_a_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_fused_a_gemm (Kernel #4)
============================================================

=== Decode Phase (B<=16, low-latency path) ===
  B=1: 0.0051 ms, 5941.3 GFLOPS, 0.26% peak
  B=2: 0.0051 ms, 11894.3 GFLOPS, 0.53% peak
  B=4: 0.0051 ms, 23693.1 GFLOPS, 1.05% peak
  B=8: 0.0052 ms, 46644.1 GFLOPS, 2.07% peak
  B=16: 0.0058 ms, 83783.6 GFLOPS, 3.72% peak
Saved ../results/dsv3_fused_a_gemm.csv

[OK] dsv3_fused_a_gemm completed successfully

======================================================================
Running: dsv3_router_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_router_gemm (Kernel #5)
============================================================

=== Decode Phase ===
  B=1: 0.0020 ms, 1856.5 GFLOPS, 0.08% peak
  B=2: 0.0022 ms, 3285.3 GFLOPS, 0.15% peak
  B=4: 0.0027 ms, 5417.9 GFLOPS, 0.24% peak
  B=8: 0.0036 ms, 8218.7 GFLOPS, 0.37% peak
  B=16: 0.0071 ms, 8255.4 GFLOPS, 0.37% peak
  Skipping B=32: kernel limited to num_tokens <= 16
  Skipping B=64: kernel limited to num_tokens <= 16
  Skipping B=128: kernel limited to num_tokens <= 16

=== Prefill Phase (skipped - kernel limited to 16 tokens) ===
Saved ../results/dsv3_router_gemm.csv

[OK] dsv3_router_gemm completed successfully

======================================================================
Running: bmm_fp8 (BMM, Compute)
======================================================================
============================================================
Benchmark: bmm_fp8 (Kernel #6)
============================================================

=== Decode Phase: q_nope * w_kc ===
  B=1: 0.0055 ms, 3060.7 GFLOPS, 0.07% peak
  B=2: 0.0055 ms, 6102.1 GFLOPS, 0.14% peak
  B=4: 0.0055 ms, 12225.1 GFLOPS, 0.27% peak
  B=8: 0.0055 ms, 24388.5 GFLOPS, 0.54% peak
  B=16: 0.0056 ms, 47673.0 GFLOPS, 1.06% peak
  B=32: 0.0057 ms, 93482.1 GFLOPS, 2.08% peak
  B=64: 0.0061 ms, 175895.4 GFLOPS, 3.91% peak
  B=128: 0.0069 ms, 309245.5 GFLOPS, 6.87% peak

=== Decode Phase: attn * w_vc ===
  B=1: 0.0027 ms, 6138.3 GFLOPS, 0.14% peak
  B=2: 0.0027 ms, 12272.7 GFLOPS, 0.27% peak
  B=4: 0.0027 ms, 24525.5 GFLOPS, 0.55% peak
  B=8: 0.0027 ms, 48869.7 GFLOPS, 1.09% peak
  B=16: 0.0031 ms, 85736.4 GFLOPS, 1.91% peak
  B=32: 0.0032 ms, 168587.2 GFLOPS, 3.75% peak
  B=64: 0.0034 ms, 320275.6 GFLOPS, 7.12% peak
  B=128: 0.0037 ms, 574785.9 GFLOPS, 12.77% peak
Saved ../results/bmm_fp8.csv

[OK] bmm_fp8 completed successfully

======================================================================
Running: cutlass_mla_decode (Attention, Mixed)
======================================================================
============================================================
Benchmark: cutlass_mla_decode (Kernel #7)
============================================================

=== Decode Phase (MLA Attention) ===
  B=1, seq_len=128: 0.0184 ms, 16.1 GB/s, memory
  B=1, seq_len=256: 0.0302 ms, 14.7 GB/s, memory
  B=1, seq_len=512: 0.0306 ms, 24.1 GB/s, memory
  B=1, seq_len=1024: 0.0321 ms, 41.3 GB/s, memory
  Skipping B=1, seq_len=2048: B*seq_len=2048 > 1024 (crash risk)
  B=2, seq_len=128: 0.0193 ms, 30.5 GB/s, memory
  B=2, seq_len=256: 0.0311 ms, 28.5 GB/s, memory
  B=2, seq_len=512: 0.0307 ms, 48.0 GB/s, memory
  Skipping B=2, seq_len=1024: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=2, seq_len=2048: B*seq_len=4096 > 1024 (crash risk)
  B=4, seq_len=128: 0.0194 ms, 60.9 GB/s, memory
  B=4, seq_len=256: 0.0298 ms, 59.4 GB/s, memory
  Skipping B=4, seq_len=512: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=4, seq_len=1024: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=4, seq_len=2048: B*seq_len=8192 > 1024 (crash risk)
  B=8, seq_len=128: 0.0194 ms, 121.9 GB/s, memory
  Skipping B=8, seq_len=256: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=8, seq_len=512: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=8, seq_len=1024: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=8, seq_len=2048: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=128: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=16, seq_len=256: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=16, seq_len=512: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=16, seq_len=1024: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=2048: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=128: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=32, seq_len=256: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=32, seq_len=512: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=32, seq_len=1024: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=2048: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=128: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=64, seq_len=256: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=64, seq_len=512: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=64, seq_len=1024: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=2048: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=128: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=128, seq_len=256: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=128, seq_len=512: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=128, seq_len=1024: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=2048: B*seq_len=262144 > 1024 (crash risk)
Saved ../results/cutlass_mla_decode.csv

[OK] cutlass_mla_decode completed successfully

======================================================================
Running: trtllm_batch_decode_with_kv_cache_mla (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_batch_decode_with_kv_cache_mla (Kernel #8)
============================================================

=== Decode Phase (TRT-LLM MLA Attention) ===

  Page size: 32
    B=1, seq_len=128: 0.0057 ms, 51.4 GB/s, memory
    B=1, seq_len=256: 0.0057 ms, 77.3 GB/s, memory
    B=1, seq_len=512: 0.0078 ms, 94.9 GB/s, memory
    B=1, seq_len=1024: 0.0091 ms, 145.2 GB/s, memory
    B=1, seq_len=2048: 0.0114 ms, 219.3 GB/s, memory
    B=2, seq_len=128: 0.0061 ms, 96.6 GB/s, memory
    B=2, seq_len=256: 0.0062 ms, 142.2 GB/s, memory
    B=2, seq_len=512: 0.0078 ms, 188.1 GB/s, memory
    B=2, seq_len=1024: 0.0096 ms, 275.7 GB/s, memory
    B=2, seq_len=2048: 0.0117 ms, 427.5 GB/s, memory
    B=4, seq_len=128: 0.0070 ms, 168.8 GB/s, memory
    B=4, seq_len=256: 0.0070 ms, 254.2 GB/s, memory
    B=4, seq_len=512: 0.0089 ms, 330.1 GB/s, memory
    B=4, seq_len=1024: 0.0116 ms, 457.9 GB/s, memory
    B=4, seq_len=2048: 0.0163 ms, 616.9 GB/s, memory
    B=8, seq_len=128: 0.0076 ms, 308.4 GB/s, memory
    B=8, seq_len=256: 0.0076 ms, 465.5 GB/s, memory
    B=8, seq_len=512: 0.0110 ms, 535.5 GB/s, memory
    B=8, seq_len=1024: 0.0158 ms, 671.6 GB/s, memory
    B=8, seq_len=2048: 0.0237 ms, 844.4 GB/s, memory
    B=16, seq_len=128: 0.0095 ms, 498.0 GB/s, memory
    B=16, seq_len=256: 0.0094 ms, 754.4 GB/s, memory
    B=16, seq_len=512: 0.0133 ms, 890.1 GB/s, memory
    B=16, seq_len=1024: 0.0202 ms, 1052.3 GB/s, memory
    B=16, seq_len=2048: 0.0157 ms, 2550.1 GB/s, memory
    B=32, seq_len=128: 0.0078 ms, 1202.3 GB/s, memory
    B=32, seq_len=256: 0.0121 ms, 1173.3 GB/s, memory
    B=32, seq_len=512: 0.0141 ms, 1676.1 GB/s, memory
    B=32, seq_len=1024: 0.0169 ms, 2506.7 GB/s, memory
    B=32, seq_len=2048: 0.0241 ms, 3326.7 GB/s, memory
    B=64, seq_len=128: 0.0085 ms, 2213.3 GB/s, memory
    B=64, seq_len=256: 0.0104 ms, 2729.3 GB/s, memory
    B=64, seq_len=512: 0.0130 ms, 3623.0 GB/s, memory
    B=64, seq_len=1024: 0.0199 ms, 4264.8 GB/s, memory
    B=64, seq_len=2048: 0.0443 ms, 3623.9 GB/s, memory
    B=128, seq_len=128: 0.0134 ms, 2824.6 GB/s, memory
    B=128, seq_len=256: 0.0181 ms, 3119.8 GB/s, memory
    B=128, seq_len=512: 0.0264 ms, 3578.1 GB/s, memory
    B=128, seq_len=1024: 0.0481 ms, 3534.7 GB/s, memory
    B=128, seq_len=2048: 0.0861 ms, 3727.8 GB/s, memory

  Page size: 64
    B=1, seq_len=128: 0.0056 ms, 52.6 GB/s, memory
    B=1, seq_len=256: 0.0056 ms, 79.3 GB/s, memory
Warning: Kernel failed for B=1, seq_len=512: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_mla.py", line 194, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_mla.py", line 190, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_mla.py", line 166, in run_benchmarks
    result = bench_trtllm_mla(flashinfer, B, seq_len, page_size)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_mla.py", line 49, in bench_trtllm_mla
    torch.manual_seed(42)
  File "/usr/local/lib/python3.12/dist-packages/torch/random.py", line 46, in manual_seed
    torch.cuda.manual_seed_all(seed)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 131, in manual_seed_all
    _lazy_call(cb, seed_all=True)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 341, in _lazy_call
    callable()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 129, in cb
    default_generator.manual_seed(seed)
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[FAILED] trtllm_batch_decode_with_kv_cache_mla: Exit code 1

======================================================================
Running: trtllm_ragged_attention_deepseek (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_ragged_attention_deepseek (Kernel #9)
============================================================

=== Prefill Phase (TRT-LLM Ragged Attention) ===
  B=1, S=128: 0.0073 ms, 720.4 GFLOPS, memory
  B=1, S=256: 0.0111 ms, 3080.3 GFLOPS, memory
  B=1, S=512: 0.0195 ms, 4533.2 GFLOPS, memory
  B=1, S=1024: 0.0369 ms, 7361.1 GFLOPS, memory
  B=1, S=2048: 0.0848 ms, 11092.0 GFLOPS, memory
  B=2, S=128: 0.0124 ms, 1093.7 GFLOPS, memory
  B=2, S=256: 0.0188 ms, 4034.0 GFLOPS, memory
  B=2, S=512: 0.0381 ms, 4938.3 GFLOPS, memory
  B=2, S=1024: 0.0914 ms, 9055.8 GFLOPS, memory
  B=2, S=2048: 0.2573 ms, 13468.2 GFLOPS, memory
  B=4, S=128: 0.0208 ms, 1507.3 GFLOPS, memory
  B=4, S=256: 0.0359 ms, 3321.3 GFLOPS, memory
  B=4, S=512: 0.0768 ms, 6052.7 GFLOPS, memory
  B=4, S=1024: 0.1630 ms, 9472.1 GFLOPS, memory
  B=4, S=2048: 0.5021 ms, 13348.2 GFLOPS, memory
  B=8, S=128: 0.0377 ms, 1686.2 GFLOPS, memory
  B=8, S=256: 0.0619 ms, 3575.6 GFLOPS, memory
  B=8, S=512: 0.1399 ms, 5874.4 GFLOPS, memory
  B=8, S=1024: 0.3513 ms, 9010.8 GFLOPS, memory
  B=8, S=2048: 1.0203 ms, 13292.9 GFLOPS, memory
  B=16, S=128: 0.0677 ms, 1695.9 GFLOPS, memory
  B=16, S=256: 0.1190 ms, 3675.1 GFLOPS, memory
  B=16, S=512: 0.2889 ms, 5906.9 GFLOPS, memory
  B=16, S=1024: 0.7468 ms, 9421.2 GFLOPS, memory
  B=16, S=2048: 2.0544 ms, 13904.8 GFLOPS, memory
  B=32, S=128: 0.1314 ms, 1668.7 GFLOPS, memory
  B=32, S=256: 0.2370 ms, 3761.6 GFLOPS, memory
  B=32, S=512: 0.5882 ms, 6240.9 GFLOPS, memory
  B=32, S=1024: 1.4951 ms, 9758.0 GFLOPS, memory
  B=32, S=2048: 4.3540 ms, 13921.3 GFLOPS, memory
  B=64, S=128: 0.2652 ms, 1633.6 GFLOPS, memory
  B=64, S=256: 0.4697 ms, 3577.3 GFLOPS, memory
  B=64, S=512: 1.1648 ms, 6186.7 GFLOPS, memory
  B=64, S=1024: 3.0159 ms, 9785.9 GFLOPS, memory
Warning: Kernel failed for B=64, S=2048: Error in function 'buildNdTmaDescriptor' at /workspace/include/flashinfer/trtllm/fmha/kernelParams.h:536: Check failed: false
  B=128, S=128: 0.5109 ms, 1755.3 GFLOPS, memory
  B=128, S=256: 0.9277 ms, 3686.2 GFLOPS, memory
  B=128, S=512: 2.3417 ms, 5982.7 GFLOPS, memory
Warning: Kernel failed for B=128, S=1024: Error in function 'buildNdTmaDescriptor' at /workspace/include/flashinfer/trtllm/fmha/kernelParams.h:536: Check failed: false
Warning: Kernel failed for B=128, S=2048: Error in function 'aligned_alloc' at /workspace/include/flashinfer/allocator.h:49: Buffer overflow when allocating memory for trtllm_gen_softmax_workspace with size 200737792 and alignment 16, but only 125829120 bytes available in AlignedAllocator. Increase the workspace buffer size.
Saved ../results/trtllm_ragged_attention_deepseek.csv

Error: Failed to initialize the TMA descriptor due to invalid argument
tmaFormat: 9 dim: 4 gmem: 0xfff5c0000000
Shape: 192 98233 128 1 48
Stride: 49152 384 2305843005452107776 177
tileShapes: 64 128 1 1 49152
tileStrides: 1 1 1 1 8820
swizzleType: 3
Error: Failed to initialize the TMA descriptor due to invalid argument
tmaFormat: 9 dim: 4 gmem: 0xfff740000000
Shape: 192 96705 128 1 48
Stride: 49152 384 2305843005377003520 209
tileShapes: 64 128 1 1 49152
tileStrides: 1 1 1 1 8820
swizzleType: 3

[OK] trtllm_ragged_attention_deepseek completed successfully

======================================================================
Running: mla_rope_quantize_fp8 (Attention, Memory)
======================================================================
============================================================
Benchmark: rope_quantize_fp8 (MLA config) (Kernel #10)
MLA: 128 Q heads, 1 K head, 64 rope_dim + 512 no_rope_dim
============================================================

=== MLA RoPE + FP8 Quantization ===
  tokens=128: 0.0063 ms, 4680.3 GB/s, 58.5% peak
  tokens=256: 0.0115 ms, 5064.6 GB/s, 63.3% peak
  tokens=512: 0.0234 ms, 4916.6 GB/s, 61.5% peak
  tokens=1024: 0.0455 ms, 5041.5 GB/s, 63.0% peak
  tokens=2048: 0.0894 ms, 5118.4 GB/s, 64.0% peak
  tokens=4096: 0.1784 ms, 5125.1 GB/s, 64.1% peak
  tokens=8192: 0.3580 ms, 5107.1 GB/s, 63.8% peak
  tokens=16384: 0.7262 ms, 5034.6 GB/s, 62.9% peak
  tokens=32768: 1.5079 ms, 4849.6 GB/s, 60.6% peak
  tokens=65536: 3.0132 ms, 4853.8 GB/s, 60.7% peak
  tokens=131072: 6.0692 ms, 4819.6 GB/s, 60.2% peak
  tokens=262144: 13.6985 ms, 4270.7 GB/s, 53.4% peak
Saved ../results/mla_rope_quantize_fp8.csv

[OK] mla_rope_quantize_fp8 completed successfully

======================================================================
Running: apply_rope_with_cos_sin_cache_inplace (RoPE, Memory)
======================================================================
============================================================
Benchmark: apply_rope_with_cos_sin_cache_inplace (Kernel #11)
============================================================

=== Decode Phase ===
  B=1: 0.0017 ms, 349.6 GB/s, 4.4% peak
  B=2: 0.0017 ms, 386.4 GB/s, 4.8% peak
  B=4: 0.0017 ms, 460.7 GB/s, 5.8% peak
  B=8: 0.0018 ms, 599.0 GB/s, 7.5% peak
  B=16: 0.0018 ms, 886.5 GB/s, 11.1% peak
  B=32: 0.0019 ms, 1405.3 GB/s, 17.6% peak
  B=64: 0.0022 ms, 2185.0 GB/s, 27.3% peak
  B=128: 0.0033 ms, 2714.2 GB/s, 33.9% peak

=== Prefill Phase ===
  B=1, S=128: 0.0033 ms, 2737.9 GB/s, 34.2% peak
  B=1, S=256: 0.0046 ms, 3764.0 GB/s, 47.0% peak
  B=1, S=512: 0.0073 ms, 4660.9 GB/s, 58.3% peak
  B=1, S=1024: 0.0128 ms, 5286.7 GB/s, 66.1% peak
  B=1, S=2048: 0.0242 ms, 5558.6 GB/s, 69.5% peak
  B=2, S=128: 0.0046 ms, 3745.9 GB/s, 46.8% peak
  B=2, S=256: 0.0073 ms, 4653.5 GB/s, 58.2% peak
  B=2, S=512: 0.0128 ms, 5283.1 GB/s, 66.0% peak
  B=2, S=1024: 0.0243 ms, 5552.6 GB/s, 69.4% peak
  B=2, S=2048: 0.0681 ms, 3948.1 GB/s, 49.4% peak
  B=4, S=128: 0.0073 ms, 4656.6 GB/s, 58.2% peak
  B=4, S=256: 0.0127 ms, 5318.2 GB/s, 66.5% peak
  B=4, S=512: 0.0243 ms, 5550.0 GB/s, 69.4% peak
  B=4, S=1024: 0.0677 ms, 3973.1 GB/s, 49.7% peak
  B=4, S=2048: 0.1385 ms, 3881.1 GB/s, 48.5% peak
  B=8, S=128: 0.0127 ms, 5327.4 GB/s, 66.6% peak
  B=8, S=256: 0.0240 ms, 5622.4 GB/s, 70.3% peak
  B=8, S=512: 0.0669 ms, 4018.6 GB/s, 50.2% peak
  B=8, S=1024: 0.1383 ms, 3886.8 GB/s, 48.6% peak
  B=8, S=2048: 0.2851 ms, 3769.1 GB/s, 47.1% peak
Saved ../results/apply_rope_with_cos_sin_cache_inplace.csv

[OK] apply_rope_with_cos_sin_cache_inplace completed successfully

======================================================================
Running: concat_mla_k (Concat, Memory)
======================================================================
============================================================
Benchmark: concat_mla_k (Kernel #12)
============================================================

=== Decode Phase ===
  B=1: 0.0021 ms, 39.0 GB/s, 0.5% peak
  B=2: 0.0030 ms, 54.6 GB/s, 0.7% peak
  B=4: 0.0048 ms, 68.3 GB/s, 0.9% peak
  B=8: 0.0048 ms, 135.7 GB/s, 1.7% peak
  B=16: 0.0048 ms, 272.5 GB/s, 3.4% peak
  B=32: 0.0049 ms, 540.8 GB/s, 6.8% peak
  B=64: 0.0049 ms, 1076.2 GB/s, 13.5% peak
  B=128: 0.0049 ms, 2143.6 GB/s, 26.8% peak

=== Prefill Phase ===
  B=1, S=128: 0.0049 ms, 2143.8 GB/s, 26.8% peak
  B=1, S=256: 0.0050 ms, 4227.7 GB/s, 52.8% peak
  B=1, S=512: 0.0055 ms, 7692.3 GB/s, 96.2% peak
  B=1, S=1024: 0.0106 ms, 7924.1 GB/s, 99.1% peak
  B=1, S=2048: 0.0273 ms, 6164.4 GB/s, 77.1% peak
  B=2, S=128: 0.0050 ms, 4159.7 GB/s, 52.0% peak
  B=2, S=256: 0.0051 ms, 8302.7 GB/s, 103.8% peak
  B=2, S=512: 0.0095 ms, 8815.6 GB/s, 110.2% peak
  B=2, S=1024: 0.0273 ms, 6155.1 GB/s, 76.9% peak
  B=2, S=2048: 0.0521 ms, 6455.1 GB/s, 80.7% peak
  B=4, S=128: 0.0051 ms, 8281.6 GB/s, 103.5% peak
  B=4, S=256: 0.0095 ms, 8863.7 GB/s, 110.8% peak
  B=4, S=512: 0.0267 ms, 6299.1 GB/s, 78.7% peak
  B=4, S=1024: 0.0521 ms, 6455.7 GB/s, 80.7% peak
  B=4, S=2048: 0.1010 ms, 6656.8 GB/s, 83.2% peak
  B=8, S=128: 0.0095 ms, 8808.0 GB/s, 110.1% peak
  B=8, S=256: 0.0270 ms, 6214.1 GB/s, 77.7% peak
  B=8, S=512: 0.0526 ms, 6388.0 GB/s, 79.8% peak
  B=8, S=1024: 0.1011 ms, 6651.2 GB/s, 83.1% peak
  B=8, S=2048: 0.1985 ms, 6770.5 GB/s, 84.6% peak
Saved ../results/concat_mla_k.csv

[OK] concat_mla_k completed successfully

======================================================================
Running: silu_and_mul (Activation, Memory)
======================================================================
============================================================
Benchmark: silu_and_mul (Kernel #13)
============================================================

=== Decode Phase ===
  B=1: 0.0018 ms, 6.8 GB/s, 0.1% peak
  B=2: 0.0018 ms, 13.5 GB/s, 0.2% peak
  B=4: 0.0018 ms, 27.0 GB/s, 0.3% peak
  B=8: 0.0018 ms, 54.0 GB/s, 0.7% peak
  B=16: 0.0019 ms, 105.3 GB/s, 1.3% peak
  B=32: 0.0019 ms, 211.0 GB/s, 2.6% peak
  B=64: 0.0019 ms, 416.4 GB/s, 5.2% peak
  B=128: 0.0019 ms, 815.8 GB/s, 10.2% peak

=== Prefill Phase ===
  B=1, S=128: 0.0019 ms, 815.3 GB/s, 10.2% peak
  B=1, S=256: 0.0021 ms, 1483.7 GB/s, 18.5% peak
  B=1, S=512: 0.0028 ms, 2257.1 GB/s, 28.2% peak
  B=1, S=1024: 0.0038 ms, 3300.3 GB/s, 41.3% peak
  B=1, S=2048: 0.0058 ms, 4359.8 GB/s, 54.5% peak
  B=2, S=128: 0.0021 ms, 1481.8 GB/s, 18.5% peak
  B=2, S=256: 0.0028 ms, 2255.0 GB/s, 28.2% peak
  B=2, S=512: 0.0038 ms, 3301.3 GB/s, 41.3% peak
  B=2, S=1024: 0.0058 ms, 4362.7 GB/s, 54.5% peak
  B=2, S=2048: 0.0098 ms, 5119.2 GB/s, 64.0% peak
  B=4, S=128: 0.0028 ms, 2208.1 GB/s, 27.6% peak
  B=4, S=256: 0.0038 ms, 3306.7 GB/s, 41.3% peak
  B=4, S=512: 0.0058 ms, 4359.2 GB/s, 54.5% peak
  B=4, S=1024: 0.0099 ms, 5106.8 GB/s, 63.8% peak
  B=4, S=2048: 0.0198 ms, 5076.8 GB/s, 63.5% peak
  B=8, S=128: 0.0038 ms, 3290.1 GB/s, 41.1% peak
  B=8, S=256: 0.0058 ms, 4348.9 GB/s, 54.4% peak
  B=8, S=512: 0.0099 ms, 5105.5 GB/s, 63.8% peak
  B=8, S=1024: 0.0200 ms, 5034.4 GB/s, 62.9% peak
  B=8, S=2048: 0.0399 ms, 5041.3 GB/s, 63.0% peak
Saved ../results/silu_and_mul.csv

[OK] silu_and_mul completed successfully

======================================================================
Running: topk_softmax (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_softmax (Kernel #14)
============================================================

=== Decode Phase ===
  B=1: 0.0034 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0034 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0034 ms, 1.3 GB/s, 0.0% peak
  B=8: 0.0035 ms, 2.5 GB/s, 0.0% peak
  B=16: 0.0035 ms, 5.0 GB/s, 0.1% peak
  B=32: 0.0035 ms, 10.1 GB/s, 0.1% peak
  B=64: 0.0035 ms, 19.9 GB/s, 0.2% peak
  B=128: 0.0035 ms, 39.9 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0035 ms, 39.9 GB/s, 0.5% peak
  B=1, S=256: 0.0035 ms, 79.1 GB/s, 1.0% peak
  B=1, S=512: 0.0036 ms, 156.6 GB/s, 2.0% peak
  B=1, S=1024: 0.0039 ms, 286.3 GB/s, 3.6% peak
  B=1, S=2048: 0.0053 ms, 424.2 GB/s, 5.3% peak
  B=2, S=128: 0.0035 ms, 79.1 GB/s, 1.0% peak
  B=2, S=256: 0.0036 ms, 156.6 GB/s, 2.0% peak
  B=2, S=512: 0.0039 ms, 286.4 GB/s, 3.6% peak
  B=2, S=1024: 0.0053 ms, 423.9 GB/s, 5.3% peak
  B=2, S=2048: 0.0078 ms, 574.5 GB/s, 7.2% peak
  B=4, S=128: 0.0036 ms, 156.6 GB/s, 2.0% peak
  B=4, S=256: 0.0039 ms, 286.3 GB/s, 3.6% peak
  B=4, S=512: 0.0053 ms, 423.9 GB/s, 5.3% peak
  B=4, S=1024: 0.0078 ms, 574.5 GB/s, 7.2% peak
  B=4, S=2048: 0.0132 ms, 672.9 GB/s, 8.4% peak
  B=8, S=128: 0.0039 ms, 286.3 GB/s, 3.6% peak
  B=8, S=256: 0.0053 ms, 423.9 GB/s, 5.3% peak
  B=8, S=512: 0.0078 ms, 574.7 GB/s, 7.2% peak
  B=8, S=1024: 0.0132 ms, 673.1 GB/s, 8.4% peak
  B=8, S=2048: 0.0237 ms, 753.0 GB/s, 9.4% peak
Saved ../results/topk_softmax.csv

[OK] topk_softmax completed successfully

======================================================================
Running: topk_sigmoid (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_sigmoid (Kernel #15)
============================================================

=== Decode Phase ===
  B=1: 0.0036 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0037 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0037 ms, 1.2 GB/s, 0.0% peak
  B=8: 0.0037 ms, 2.3 GB/s, 0.0% peak
  B=16: 0.0037 ms, 4.7 GB/s, 0.1% peak
  B=32: 0.0037 ms, 9.4 GB/s, 0.1% peak
  B=64: 0.0038 ms, 18.5 GB/s, 0.2% peak
  B=128: 0.0038 ms, 37.1 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0038 ms, 37.1 GB/s, 0.5% peak
  B=1, S=256: 0.0038 ms, 73.6 GB/s, 0.9% peak
  B=1, S=512: 0.0038 ms, 146.0 GB/s, 1.8% peak
  B=1, S=1024: 0.0041 ms, 271.9 GB/s, 3.4% peak
  B=1, S=2048: 0.0053 ms, 417.8 GB/s, 5.2% peak
  B=2, S=128: 0.0038 ms, 73.6 GB/s, 0.9% peak
  B=2, S=256: 0.0038 ms, 146.0 GB/s, 1.8% peak
  B=2, S=512: 0.0041 ms, 272.0 GB/s, 3.4% peak
  B=2, S=1024: 0.0053 ms, 417.7 GB/s, 5.2% peak
  B=2, S=2048: 0.0077 ms, 578.7 GB/s, 7.2% peak
  B=4, S=128: 0.0038 ms, 146.0 GB/s, 1.8% peak
  B=4, S=256: 0.0041 ms, 272.0 GB/s, 3.4% peak
  B=4, S=512: 0.0053 ms, 417.6 GB/s, 5.2% peak
  B=4, S=1024: 0.0077 ms, 578.7 GB/s, 7.2% peak
  B=4, S=2048: 0.0129 ms, 688.7 GB/s, 8.6% peak
  B=8, S=128: 0.0041 ms, 271.9 GB/s, 3.4% peak
  B=8, S=256: 0.0053 ms, 417.6 GB/s, 5.2% peak
  B=8, S=512: 0.0077 ms, 578.7 GB/s, 7.2% peak
  B=8, S=1024: 0.0129 ms, 688.8 GB/s, 8.6% peak
  B=8, S=2048: 0.0228 ms, 780.5 GB/s, 9.8% peak
Saved ../results/topk_sigmoid.csv

[OK] topk_sigmoid completed successfully

======================================================================
Running: moe_fused_gate (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: moe_fused_gate (Kernel #16)
============================================================

=== Decode Phase ===
  B=1: 0.0109 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0112 ms, 0.3 GB/s, 0.0% peak
  B=4: 0.0115 ms, 0.5 GB/s, 0.0% peak
  B=8: 0.0122 ms, 0.8 GB/s, 0.0% peak
  B=16: 0.0136 ms, 1.4 GB/s, 0.0% peak
  B=32: 0.0156 ms, 2.3 GB/s, 0.0% peak
  B=64: 0.0158 ms, 4.5 GB/s, 0.1% peak
  B=128: 0.0156 ms, 9.0 GB/s, 0.1% peak

=== Prefill Phase ===
  B=1, S=128: 0.0158 ms, 8.9 GB/s, 0.1% peak
  B=1, S=256: 0.0156 ms, 17.9 GB/s, 0.2% peak
  B=1, S=512: 0.0158 ms, 35.4 GB/s, 0.4% peak
  B=1, S=1024: 0.0158 ms, 70.5 GB/s, 0.9% peak
  B=1, S=2048: 0.0158 ms, 140.8 GB/s, 1.8% peak
  B=2, S=128: 0.0158 ms, 17.7 GB/s, 0.2% peak
  B=2, S=256: 0.0158 ms, 35.4 GB/s, 0.4% peak
  B=2, S=512: 0.0158 ms, 70.6 GB/s, 0.9% peak
  B=2, S=1024: 0.0158 ms, 141.1 GB/s, 1.8% peak
  B=2, S=2048: 0.0218 ms, 204.3 GB/s, 2.6% peak
  B=4, S=128: 0.0158 ms, 35.4 GB/s, 0.4% peak
  B=4, S=256: 0.0159 ms, 70.3 GB/s, 0.9% peak
  B=4, S=512: 0.0159 ms, 140.1 GB/s, 1.8% peak
  B=4, S=1024: 0.0217 ms, 205.4 GB/s, 2.6% peak
  B=4, S=2048: 0.0288 ms, 309.5 GB/s, 3.9% peak
  B=8, S=128: 0.0159 ms, 70.2 GB/s, 0.9% peak
  B=8, S=256: 0.0158 ms, 140.8 GB/s, 1.8% peak
  B=8, S=512: 0.0216 ms, 206.0 GB/s, 2.6% peak
  B=8, S=1024: 0.0286 ms, 312.1 GB/s, 3.9% peak
  B=8, S=2048: 0.0452 ms, 394.4 GB/s, 4.9% peak
Saved ../results/moe_fused_gate.csv

[OK] moe_fused_gate completed successfully

======================================================================
Running: prepare_moe_input (MoE, Memory)
======================================================================
============================================================
Benchmark: prepare_moe_input (Kernel #17)
============================================================

=== Decode Phase ===
  B=1: 0.0162 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0162 ms, 0.2 GB/s, 0.0% peak
  B=4: 0.0163 ms, 0.2 GB/s, 0.0% peak
  B=8: 0.0164 ms, 0.2 GB/s, 0.0% peak
  B=16: 0.0166 ms, 0.3 GB/s, 0.0% peak
  B=32: 0.0162 ms, 0.4 GB/s, 0.0% peak
  B=64: 0.0153 ms, 0.6 GB/s, 0.0% peak
  B=128: 0.0150 ms, 1.0 GB/s, 0.0% peak

=== Prefill Phase ===
  B=1, S=128: 0.0150 ms, 1.0 GB/s, 0.0% peak
  B=1, S=256: 0.0171 ms, 1.6 GB/s, 0.0% peak
  B=1, S=512: 0.0186 ms, 2.8 GB/s, 0.0% peak
  B=1, S=1024: 0.0235 ms, 4.3 GB/s, 0.1% peak
  B=1, S=2048: 0.0332 ms, 6.0 GB/s, 0.1% peak
  B=2, S=128: 0.0171 ms, 1.6 GB/s, 0.0% peak
  B=2, S=256: 0.0185 ms, 2.8 GB/s, 0.0% peak
  B=2, S=512: 0.0232 ms, 4.4 GB/s, 0.1% peak
  B=2, S=1024: 0.0330 ms, 6.1 GB/s, 0.1% peak
  B=2, S=2048: 0.0450 ms, 8.8 GB/s, 0.1% peak
  B=4, S=128: 0.0184 ms, 2.8 GB/s, 0.0% peak
  B=4, S=256: 0.0233 ms, 4.4 GB/s, 0.1% peak
  B=4, S=512: 0.0337 ms, 5.9 GB/s, 0.1% peak
  B=4, S=1024: 0.0469 ms, 8.4 GB/s, 0.1% peak
  B=4, S=2048: 0.0722 ms, 10.9 GB/s, 0.1% peak
  B=8, S=128: 0.0231 ms, 4.4 GB/s, 0.1% peak
  B=8, S=256: 0.0335 ms, 6.0 GB/s, 0.1% peak
  B=8, S=512: 0.0449 ms, 8.8 GB/s, 0.1% peak
  B=8, S=1024: 0.0724 ms, 10.9 GB/s, 0.1% peak
  B=8, S=2048: 0.1292 ms, 12.2 GB/s, 0.2% peak
Saved ../results/prepare_moe_input.csv

[OK] prepare_moe_input completed successfully

======================================================================
Running: scaled_fp4_experts_quant (MoE, Memory)
======================================================================
============================================================
Benchmark: scaled_fp4_experts_quant (Kernel #18)
============================================================

=== Decode Phase ===
  B=1: 0.0074 ms, 19.9 GB/s, 0.2% peak
  B=2: 0.0074 ms, 39.7 GB/s, 0.5% peak
  B=4: 0.0075 ms, 77.9 GB/s, 1.0% peak
  B=8: 0.0079 ms, 149.0 GB/s, 1.9% peak
  B=16: 0.0092 ms, 255.4 GB/s, 3.2% peak
  B=32: 0.0122 ms, 384.5 GB/s, 4.8% peak
  B=64: 0.0067 ms, 1396.1 GB/s, 17.5% peak
  B=128: 0.0108 ms, 1738.3 GB/s, 21.7% peak

=== Prefill Phase ===
  B=1, S=128: 0.0108 ms, 1738.7 GB/s, 21.7% peak
Warning: Kernel failed for B=1, S=256: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 169, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 165, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 139, in run_benchmarks
    result = bench_scaled_fp4_experts_quant(sgl_kernel, B, S, H, E, K, "prefill")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 48, in bench_scaled_fp4_experts_quant
    expert_inputs = torch.randn(total_expert_tokens, hidden_size, dtype=torch.bfloat16, device=device)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[FAILED] scaled_fp4_experts_quant: Exit code 1

======================================================================
Running: cutlass_fp4_group_mm (MoE, Compute)
======================================================================
============================================================
Benchmark: cutlass_fp4_group_mm (Kernel #19)
============================================================

=== Decode Phase: gate_up ===
  B=1: 0.0511 ms, 9193.3 GFLOPS, 0.10% peak
  B=2: 0.0484 ms, 19406.4 GFLOPS, 0.22% peak
  B=4: 0.0513 ms, 36654.5 GFLOPS, 0.41% peak
  B=8: 0.0489 ms, 76929.3 GFLOPS, 0.85% peak
  B=16: 0.0493 ms, 152416.3 GFLOPS, 1.69% peak
Warning: Kernel failed for B=32, S=1, op=gate_up: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 229, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 225, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 175, in run_benchmarks
    result = bench_cutlass_fp4_group_mm(sgl_kernel, B, 1, E, K, H, I, "gate_up", "decode")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 62, in bench_cutlass_fp4_group_mm
    a = torch.randn((M, K_dim), dtype=torch.bfloat16, device=device)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[FAILED] cutlass_fp4_group_mm: Exit code 1

======================================================================
Running: apply_shuffle_mul_sum (MoE, Memory)
======================================================================
============================================================
Benchmark: apply_shuffle_mul_sum (Kernel #20)
============================================================

=== Decode Phase ===
  B=1: 0.0030 ms, 43.5 GB/s, 0.5% peak
  B=2: 0.0030 ms, 86.9 GB/s, 1.1% peak
  B=4: 0.0030 ms, 173.6 GB/s, 2.2% peak
  B=8: 0.0030 ms, 345.2 GB/s, 4.3% peak
  B=16: 0.0030 ms, 689.9 GB/s, 8.6% peak
  B=32: 0.0030 ms, 1369.7 GB/s, 17.1% peak
  B=64: 0.0030 ms, 2733.1 GB/s, 34.2% peak
  B=128: 0.0031 ms, 5345.8 GB/s, 66.8% peak

=== Prefill Phase ===
  B=1, S=128: 0.0031 ms, 5345.2 GB/s, 66.8% peak
  B=1, S=256: 0.0041 ms, 7988.0 GB/s, 99.9% peak
  B=1, S=512: 0.0066 ms, 9987.5 GB/s, 124.8% peak
  B=1, S=1024: 0.0105 ms, 12629.1 GB/s, 157.9% peak
  B=1, S=2048: 0.0191 ms, 13822.3 GB/s, 172.8% peak
  B=2, S=128: 0.0041 ms, 7995.7 GB/s, 99.9% peak
  B=2, S=256: 0.0066 ms, 9981.4 GB/s, 124.8% peak
  B=2, S=512: 0.0105 ms, 12595.6 GB/s, 157.4% peak
  B=2, S=1024: 0.0190 ms, 13908.9 GB/s, 173.9% peak
  B=2, S=2048: 0.0382 ms, 13824.8 GB/s, 172.8% peak
  B=4, S=128: 0.0066 ms, 9968.1 GB/s, 124.6% peak
  B=4, S=256: 0.0105 ms, 12604.5 GB/s, 157.6% peak
  B=4, S=512: 0.0191 ms, 13865.1 GB/s, 173.3% peak
  B=4, S=1024: 0.0382 ms, 13843.0 GB/s, 173.0% peak
  B=4, S=2048: 0.0735 ms, 14382.6 GB/s, 179.8% peak
  B=8, S=128: 0.0105 ms, 12582.6 GB/s, 157.3% peak
  B=8, S=256: 0.0191 ms, 13867.6 GB/s, 173.3% peak
  B=8, S=512: 0.0380 ms, 13904.6 GB/s, 173.8% peak
  B=8, S=1024: 0.0735 ms, 14386.9 GB/s, 179.8% peak
  B=8, S=2048: 0.1434 ms, 14746.4 GB/s, 184.3% peak
Saved ../results/apply_shuffle_mul_sum.csv

[OK] apply_shuffle_mul_sum completed successfully

======================================================================
Running: moe_align_block_size (MoE, Memory)
======================================================================
============================================================
Benchmark: moe_align_block_size (Kernel #21)
============================================================

=== Decode Phase ===
  B=1: 0.0042 ms, 15.9 GB/s, 0.2% peak
  B=2: 0.0043 ms, 15.9 GB/s, 0.2% peak
  B=4: 0.0043 ms, 15.8 GB/s, 0.2% peak
  B=8: 0.0043 ms, 15.7 GB/s, 0.2% peak
  B=16: 0.0044 ms, 15.7 GB/s, 0.2% peak
  B=32: 0.0043 ms, 16.3 GB/s, 0.2% peak
  B=64: 0.0043 ms, 16.7 GB/s, 0.2% peak
  B=128: 0.0044 ms, 17.4 GB/s, 0.2% peak

=== Prefill Phase ===
  B=1, S=128: 0.0044 ms, 17.4 GB/s, 0.2% peak
  B=1, S=256: 0.0048 ms, 17.7 GB/s, 0.2% peak
  B=1, S=512: 0.0056 ms, 18.1 GB/s, 0.2% peak
  B=1, S=1024: 0.0072 ms, 18.5 GB/s, 0.2% peak
  B=1, S=2048: 0.0087 ms, 23.1 GB/s, 0.3% peak
  B=2, S=128: 0.0048 ms, 17.6 GB/s, 0.2% peak
  B=2, S=256: 0.0055 ms, 18.2 GB/s, 0.2% peak
  B=2, S=512: 0.0072 ms, 18.5 GB/s, 0.2% peak
  B=2, S=1024: 0.0086 ms, 23.1 GB/s, 0.3% peak
  B=2, S=2048: 0.0135 ms, 24.5 GB/s, 0.3% peak
  B=4, S=128: 0.0056 ms, 18.1 GB/s, 0.2% peak
  B=4, S=256: 0.0072 ms, 18.6 GB/s, 0.2% peak
  B=4, S=512: 0.0086 ms, 23.1 GB/s, 0.3% peak
  B=4, S=1024: 0.0136 ms, 24.3 GB/s, 0.3% peak
  B=4, S=2048: 0.0233 ms, 25.6 GB/s, 0.3% peak
  B=8, S=128: 0.0072 ms, 18.5 GB/s, 0.2% peak
  B=8, S=256: 0.0087 ms, 23.1 GB/s, 0.3% peak
  B=8, S=512: 0.0136 ms, 24.4 GB/s, 0.3% peak
  B=8, S=1024: 0.0233 ms, 25.6 GB/s, 0.3% peak
  B=8, S=2048: 0.0423 ms, 26.6 GB/s, 0.3% peak
Saved ../results/moe_align_block_size.csv

[OK] moe_align_block_size completed successfully

======================================================================
Running: trtllm_fp4_block_scale_moe (MoE, Mixed)
======================================================================
============================================================
Benchmark: trtllm_fp4_block_scale_moe (Kernel #22)
============================================================

=== Decode Phase ===
  B=1: Skipped (minimum batch size for FP4 MoE is 32)
  B=2: Skipped (minimum batch size for FP4 MoE is 32)
  B=4: Skipped (minimum batch size for FP4 MoE is 32)
  B=8: Skipped (minimum batch size for FP4 MoE is 32)
  B=16: Skipped (minimum batch size for FP4 MoE is 32)
Warning: Kernel failed for B=32, S=1: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=64, S=1: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=128, S=1: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=1, S=256: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=1, S=512: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=1, S=1024: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=1, S=2048: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=2, S=128: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=2, S=256: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=2, S=512: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=2, S=1024: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=2, S=2048: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=4, S=128: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=4, S=256: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=4, S=512: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=4, S=1024: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=4, S=2048: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=8, S=128: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=8, S=256: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=8, S=512: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=8, S=1024: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'
Warning: Kernel failed for B=8, S=2048: trtllm_fp4_block_scale_moe() missing 1 required positional argument: 'tile_tokens_dim'

No results - kernel not available

[FAILED] trtllm_fp4_block_scale_moe: No CSV output (kernel not available or all runs failed)

======================================================================
Running: fused_moe_kernel (MoE, Mixed)
======================================================================
============================================================
Benchmark: fused_moe_kernel (Kernel #23)
============================================================

=== Decode Phase ===
  B=1: 0.1335 ms, 5277.7 GFLOPS, 2111.09% peak (memory)
  B=2: 0.2826 ms, 4986.1 GFLOPS, 997.22% peak (memory)
  B=4: 0.4505 ms, 6255.9 GFLOPS, 625.59% peak (memory)
  B=8: 0.8481 ms, 6646.7 GFLOPS, 332.34% peak (memory)
  B=16: 1.4434 ms, 7811.1 GFLOPS, 195.28% peak (memory)
  B=32: 2.2484 ms, 10028.9 GFLOPS, 125.37% peak (memory)
  B=64: 3.0044 ms, 15010.1 GFLOPS, 93.82% peak (memory)
  B=128: 3.4197 ms, 26374.6 GFLOPS, 82.43% peak (memory)

=== Prefill Phase ===
  B=1, S=128: 3.4500 ms, 26143.5 GFLOPS, 81.71% peak (memory)
  B=1, S=256: 3.5129 ms, 51350.3 GFLOPS, 80.26% peak (memory)
  B=1, S=512: 3.8977 ms, 92562.4 GFLOPS, 72.36% peak (memory)
  B=1, S=1024: 4.0726 ms, 177174.9 GFLOPS, 69.30% peak (memory)
  B=1, S=2048: 5.4383 ms, 265362.5 GFLOPS, 51.96% peak (memory)
  B=2, S=128: 3.5285 ms, 51123.0 GFLOPS, 79.91% peak (memory)
  B=2, S=256: 3.8956 ms, 92612.3 GFLOPS, 72.40% peak (memory)
  B=2, S=512: 4.0711 ms, 177239.1 GFLOPS, 69.32% peak (memory)
  B=2, S=1024: 5.2730 ms, 273679.6 GFLOPS, 53.59% peak (memory)
  B=2, S=2048: 8.3867 ms, 344141.1 GFLOPS, 33.78% peak (memory)
  B=4, S=128: 3.9002 ms, 92501.3 GFLOPS, 72.31% peak (memory)
  B=4, S=256: 4.0681 ms, 177368.4 GFLOPS, 69.37% peak (memory)
  B=4, S=512: 5.3544 ms, 269520.5 GFLOPS, 52.78% peak (memory)
  B=4, S=1024: 8.3653 ms, 345020.8 GFLOPS, 33.87% peak (memory)
  B=4, S=2048: 13.9090 ms, 415014.2 GFLOPS, 20.48% peak (memory)
  B=8, S=128: 4.0731 ms, 177150.8 GFLOPS, 69.29% peak (memory)
  B=8, S=256: 5.3414 ms, 270175.8 GFLOPS, 52.91% peak (memory)
  B=8, S=512: 8.2448 ms, 350065.9 GFLOPS, 34.36% peak (memory)
  B=8, S=1024: 14.0286 ms, 411475.1 GFLOPS, 20.30% peak (memory)
  B=8, S=2048: 32.4843 ms, 355398.3 GFLOPS, 15.80% peak (compute)
Saved ../results/fused_moe_kernel.csv

[2026-01-27 20:19:42] WARNING fused_moe_triton_config.py:127: Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_5_1/E=256,N=2048,device_name=NVIDIA_GB200.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2026-01-27 20:19:42] WARNING fused_moe_triton_config.py:119: Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_5_1/E=256,N=2048,device_name=NVIDIA_GB200_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton

[OK] fused_moe_kernel completed successfully

Aggregated results saved to ../results/all_kernels.csv
Total benchmark results: 585

Summary saved to ../results/benchmark_summary.md

======================================================================
Benchmark Complete!
Successful: 19/23
Failed kernels:
  - trtllm_batch_decode_with_kv_cache_mla: Exit code 1
  - scaled_fp4_experts_quant: Exit code 1
  - cutlass_fp4_group_mm: Exit code 1
  - trtllm_fp4_block_scale_moe: No CSV output (kernel not available or all runs failed)
======================================================================
