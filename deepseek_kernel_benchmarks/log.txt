Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 310, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 306, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 271, in run_benchmarks
    result = bench_trtllm_fp4_block_scale_moe(flashinfer, B, 1, H, E, K, I, "decode")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 95, in bench_trtllm_fp4_block_scale_moe
    torch.manual_seed(42)
  File "/usr/local/lib/python3.12/dist-packages/torch/random.py", line 46, in manual_seed
    torch.cuda.manual_seed_all(seed)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 131, in manual_seed_all
    _lazy_call(cb, seed_all=True)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 341, in _lazy_call
    callable()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 129, in cb
    default_generator.manual_seed(seed)
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


======================================================================
DeepSeek-R1-NVFP4-v2 Kernel Benchmarks
======================================================================
Kernels to run: 23
Batch sizes: 1,2,4,8,16,32,64,128
Sequence lengths: 128,256,512,1024,2048
Output directory: ../results/

NOTE: Each kernel runs in a separate subprocess for isolation.
      CUDA crashes in one kernel will NOT affect other kernels.
======================================================================

======================================================================
Running: rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: rmsnorm (Kernel #1)
============================================================

=== Decode Phase ===
  B=1: 0.0019 ms, 15.4 GB/s, 0.2% peak
  B=2: 0.0019 ms, 30.6 GB/s, 0.4% peak
  B=4: 0.0019 ms, 61.5 GB/s, 0.8% peak
  B=8: 0.0019 ms, 121.8 GB/s, 1.5% peak
  B=16: 0.0020 ms, 233.3 GB/s, 2.9% peak
  B=32: 0.0020 ms, 463.0 GB/s, 5.8% peak
  B=64: 0.0020 ms, 918.9 GB/s, 11.5% peak
  B=128: 0.0021 ms, 1778.1 GB/s, 22.2% peak

=== Prefill Phase ===
  B=1, S=128: 0.0021 ms, 1778.3 GB/s, 22.2% peak
  B=1, S=256: 0.0027 ms, 2761.9 GB/s, 34.5% peak
  B=1, S=512: 0.0046 ms, 3178.5 GB/s, 39.7% peak
  B=1, S=1024: 0.0081 ms, 3618.5 GB/s, 45.2% peak
  B=1, S=2048: 0.0150 ms, 3917.4 GB/s, 49.0% peak
  B=2, S=128: 0.0027 ms, 2759.8 GB/s, 34.5% peak
  B=2, S=256: 0.0046 ms, 3179.7 GB/s, 39.7% peak
  B=2, S=512: 0.0081 ms, 3618.8 GB/s, 45.2% peak
  B=2, S=1024: 0.0150 ms, 3904.5 GB/s, 48.8% peak
  B=2, S=2048: 0.0364 ms, 3228.4 GB/s, 40.4% peak
  B=4, S=128: 0.0046 ms, 3177.8 GB/s, 39.7% peak
  B=4, S=256: 0.0081 ms, 3616.1 GB/s, 45.2% peak
  B=4, S=512: 0.0150 ms, 3918.1 GB/s, 49.0% peak
  B=4, S=1024: 0.0366 ms, 3211.3 GB/s, 40.1% peak
  B=4, S=2048: 0.0703 ms, 3340.2 GB/s, 41.8% peak
  B=8, S=128: 0.0081 ms, 3612.3 GB/s, 45.2% peak
  B=8, S=256: 0.0150 ms, 3911.9 GB/s, 48.9% peak
  B=8, S=512: 0.0365 ms, 3214.5 GB/s, 40.2% peak
  B=8, S=1024: 0.0704 ms, 3334.3 GB/s, 41.7% peak
  B=8, S=2048: 0.1376 ms, 3413.3 GB/s, 42.7% peak
Saved ../results/rmsnorm.csv

[OK] rmsnorm completed successfully

======================================================================
Running: fused_add_rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: fused_add_rmsnorm (Kernel #2)
============================================================

=== Decode Phase ===
  B=1: 0.0023 ms, 24.9 GB/s, 0.3% peak
  B=2: 0.0023 ms, 49.9 GB/s, 0.6% peak
  B=4: 0.0023 ms, 99.7 GB/s, 1.2% peak
  B=8: 0.0023 ms, 197.1 GB/s, 2.5% peak
  B=16: 0.0024 ms, 379.5 GB/s, 4.7% peak
  B=32: 0.0024 ms, 758.4 GB/s, 9.5% peak
  B=64: 0.0024 ms, 1503.6 GB/s, 18.8% peak
  B=128: 0.0026 ms, 2875.5 GB/s, 35.9% peak

=== Prefill Phase ===
  B=1, S=128: 0.0026 ms, 2877.0 GB/s, 36.0% peak
  B=1, S=256: 0.0045 ms, 3267.9 GB/s, 40.8% peak
  B=1, S=512: 0.0081 ms, 3639.5 GB/s, 45.5% peak
  B=1, S=1024: 0.0143 ms, 4094.4 GB/s, 51.2% peak
  B=1, S=2048: 0.0272 ms, 4315.0 GB/s, 53.9% peak
  B=2, S=128: 0.0045 ms, 3272.1 GB/s, 40.9% peak
  B=2, S=256: 0.0081 ms, 3641.6 GB/s, 45.5% peak
  B=2, S=512: 0.0142 ms, 4132.7 GB/s, 51.7% peak
  B=2, S=1024: 0.0273 ms, 4298.0 GB/s, 53.7% peak
  B=2, S=2048: 0.0675 ms, 3480.2 GB/s, 43.5% peak
  B=4, S=128: 0.0081 ms, 3639.0 GB/s, 45.5% peak
  B=4, S=256: 0.0143 ms, 4102.8 GB/s, 51.3% peak
  B=4, S=512: 0.0273 ms, 4305.8 GB/s, 53.8% peak
  B=4, S=1024: 0.0676 ms, 3476.6 GB/s, 43.5% peak
  B=4, S=2048: 0.1311 ms, 3583.5 GB/s, 44.8% peak
  B=8, S=128: 0.0144 ms, 4088.5 GB/s, 51.1% peak
  B=8, S=256: 0.0273 ms, 4304.8 GB/s, 53.8% peak
  B=8, S=512: 0.0678 ms, 3462.0 GB/s, 43.3% peak
  B=8, S=1024: 0.1320 ms, 3558.8 GB/s, 44.5% peak
  B=8, S=2048: 0.2592 ms, 3624.2 GB/s, 45.3% peak
Saved ../results/fused_add_rmsnorm.csv

[OK] fused_add_rmsnorm completed successfully

======================================================================
Running: cutlass_scaled_fp4_mm (GEMM, Compute)
======================================================================
============================================================
Benchmark: cutlass_scaled_fp4_mm (Kernel #3)
============================================================

=== Decode Phase ===
  q_b_proj B=1: 0.0064 ms, 11884.2 GFLOPS, 0.13% peak
  kv_b_proj B=1: 0.0051 ms, 6617.4 GFLOPS, 0.07% peak
  o_proj B=1: 0.0233 ms, 10099.7 GFLOPS, 0.11% peak
  q_b_proj B=2: 0.0064 ms, 23695.5 GFLOPS, 0.26% peak
  kv_b_proj B=2: 0.0051 ms, 13193.1 GFLOPS, 0.15% peak
  o_proj B=2: 0.0232 ms, 20222.0 GFLOPS, 0.22% peak
  q_b_proj B=4: 0.0063 ms, 47999.2 GFLOPS, 0.53% peak
  kv_b_proj B=4: 0.0050 ms, 26581.8 GFLOPS, 0.30% peak
  o_proj B=4: 0.0233 ms, 40270.7 GFLOPS, 0.45% peak
  q_b_proj B=8: 0.0063 ms, 96148.4 GFLOPS, 1.07% peak
  kv_b_proj B=8: 0.0051 ms, 53066.8 GFLOPS, 0.59% peak
  o_proj B=8: 0.0234 ms, 80280.0 GFLOPS, 0.89% peak
  q_b_proj B=16: 0.0063 ms, 191746.9 GFLOPS, 2.13% peak
  kv_b_proj B=16: 0.0050 ms, 108070.0 GFLOPS, 1.20% peak
  o_proj B=16: 0.0234 ms, 160500.5 GFLOPS, 1.78% peak
  q_b_proj B=32: 0.0063 ms, 382912.5 GFLOPS, 4.25% peak
  kv_b_proj B=32: 0.0050 ms, 215404.1 GFLOPS, 2.39% peak
  o_proj B=32: 0.0233 ms, 322595.7 GFLOPS, 3.58% peak
  q_b_proj B=64: 0.0064 ms, 758349.0 GFLOPS, 8.43% peak
  kv_b_proj B=64: 0.0050 ms, 426457.3 GFLOPS, 4.74% peak
  o_proj B=64: 0.0233 ms, 644051.9 GFLOPS, 7.16% peak
  q_b_proj B=128: 0.0068 ms, 1421399.2 GFLOPS, 15.79% peak
  kv_b_proj B=128: 0.0054 ms, 797309.4 GFLOPS, 8.86% peak
  o_proj B=128: 0.0239 ms, 1257910.3 GFLOPS, 13.98% peak

=== Prefill Phase ===
  q_b_proj B=1, S=128: 0.0068 ms, 1423700.4 GFLOPS, 15.82% peak
  kv_b_proj B=1, S=128: 0.0054 ms, 796268.9 GFLOPS, 8.85% peak
  o_proj B=1, S=128: 0.0239 ms, 1257687.9 GFLOPS, 13.97% peak
  q_b_proj B=1, S=256: 0.0089 ms, 2170934.7 GFLOPS, 24.12% peak
  kv_b_proj B=1, S=256: 0.0070 ms, 1230912.5 GFLOPS, 13.68% peak
  o_proj B=1, S=256: 0.0219 ms, 2741729.4 GFLOPS, 30.46% peak
  q_b_proj B=1, S=512: 0.0122 ms, 3158336.3 GFLOPS, 35.09% peak
  kv_b_proj B=1, S=512: 0.0100 ms, 1716834.5 GFLOPS, 19.08% peak
  o_proj B=1, S=512: 0.0235 ms, 5106719.5 GFLOPS, 56.74% peak
  q_b_proj B=1, S=1024: 0.0200 ms, 3870211.2 GFLOPS, 43.00% peak
  kv_b_proj B=1, S=1024: 0.0150 ms, 2297692.6 GFLOPS, 25.53% peak
  o_proj B=1, S=1024: 0.0500 ms, 4814100.3 GFLOPS, 53.49% peak
  q_b_proj B=1, S=2048: 0.0401 ms, 3857547.7 GFLOPS, 42.86% peak
  kv_b_proj B=1, S=2048: 0.0286 ms, 2405530.9 GFLOPS, 26.73% peak
  o_proj B=1, S=2048: 0.0977 ms, 4921088.0 GFLOPS, 54.68% peak
  q_b_proj B=2, S=128: 0.0089 ms, 2164230.4 GFLOPS, 24.05% peak
  kv_b_proj B=2, S=128: 0.0070 ms, 1225655.3 GFLOPS, 13.62% peak
  o_proj B=2, S=128: 0.0226 ms, 2661758.9 GFLOPS, 29.58% peak
  q_b_proj B=2, S=256: 0.0122 ms, 3155771.7 GFLOPS, 35.06% peak
  kv_b_proj B=2, S=256: 0.0100 ms, 1715413.8 GFLOPS, 19.06% peak
  o_proj B=2, S=256: 0.0240 ms, 5017898.4 GFLOPS, 55.75% peak
  q_b_proj B=2, S=512: 0.0199 ms, 3875304.8 GFLOPS, 43.06% peak
  kv_b_proj B=2, S=512: 0.0148 ms, 2314762.3 GFLOPS, 25.72% peak
  o_proj B=2, S=512: 0.0499 ms, 4820396.6 GFLOPS, 53.56% peak
  q_b_proj B=2, S=1024: 0.0400 ms, 3865129.6 GFLOPS, 42.95% peak
  kv_b_proj B=2, S=1024: 0.0289 ms, 2376520.2 GFLOPS, 26.41% peak
  o_proj B=2, S=1024: 0.0961 ms, 5003732.2 GFLOPS, 55.60% peak
  q_b_proj B=2, S=2048: 0.0749 ms, 4126422.8 GFLOPS, 45.85% peak
  kv_b_proj B=2, S=2048: 0.0525 ms, 2616622.2 GFLOPS, 29.07% peak
  o_proj B=2, S=2048: 0.1835 ms, 5243886.0 GFLOPS, 58.27% peak
  q_b_proj B=4, S=128: 0.0123 ms, 3137622.6 GFLOPS, 34.86% peak
  kv_b_proj B=4, S=128: 0.0100 ms, 1713721.1 GFLOPS, 19.04% peak
  o_proj B=4, S=128: 0.0237 ms, 5074381.2 GFLOPS, 56.38% peak
  q_b_proj B=4, S=256: 0.0198 ms, 3894956.9 GFLOPS, 43.28% peak
  kv_b_proj B=4, S=256: 0.0152 ms, 2266703.1 GFLOPS, 25.19% peak
  o_proj B=4, S=256: 0.0499 ms, 4816638.9 GFLOPS, 53.52% peak
  q_b_proj B=4, S=512: 0.0397 ms, 3896465.5 GFLOPS, 43.29% peak
  kv_b_proj B=4, S=512: 0.0284 ms, 2416119.6 GFLOPS, 26.85% peak
  o_proj B=4, S=512: 0.0975 ms, 4935727.8 GFLOPS, 54.84% peak
  q_b_proj B=4, S=1024: 0.0748 ms, 4133284.7 GFLOPS, 45.93% peak
  kv_b_proj B=4, S=1024: 0.0532 ms, 2583622.0 GFLOPS, 28.71% peak
  o_proj B=4, S=1024: 0.1833 ms, 5249407.9 GFLOPS, 58.33% peak
  q_b_proj B=4, S=2048: 0.1459 ms, 4238434.2 GFLOPS, 47.09% peak
  kv_b_proj B=4, S=2048: 0.1020 ms, 2693892.0 GFLOPS, 29.93% peak
  o_proj B=4, S=2048: 0.3637 ms, 5289889.5 GFLOPS, 58.78% peak
  q_b_proj B=8, S=128: 0.0199 ms, 3881248.4 GFLOPS, 43.12% peak
  kv_b_proj B=8, S=128: 0.0148 ms, 2319941.9 GFLOPS, 25.78% peak
  o_proj B=8, S=128: 0.0498 ms, 4833383.7 GFLOPS, 53.70% peak
  q_b_proj B=8, S=256: 0.0403 ms, 3834667.8 GFLOPS, 42.61% peak
  kv_b_proj B=8, S=256: 0.0286 ms, 2401045.9 GFLOPS, 26.68% peak
  o_proj B=8, S=256: 0.0991 ms, 4853179.8 GFLOPS, 53.92% peak
  q_b_proj B=8, S=512: 0.0746 ms, 4144343.2 GFLOPS, 46.05% peak
  kv_b_proj B=8, S=512: 0.0525 ms, 2616847.0 GFLOPS, 29.08% peak
  o_proj B=8, S=512: 0.1860 ms, 5171707.0 GFLOPS, 57.46% peak
  q_b_proj B=8, S=1024: 0.1486 ms, 4161122.2 GFLOPS, 46.23% peak
  kv_b_proj B=8, S=1024: 0.1032 ms, 2663255.8 GFLOPS, 29.59% peak
  o_proj B=8, S=1024: 0.3586 ms, 5366215.5 GFLOPS, 59.62% peak
  q_b_proj B=8, S=2048: 0.2993 ms, 4132766.4 GFLOPS, 45.92% peak
  kv_b_proj B=8, S=2048: 0.2007 ms, 2739216.3 GFLOPS, 30.44% peak
  o_proj B=8, S=2048: 0.7260 ms, 5300544.8 GFLOPS, 58.89% peak
Saved ../results/cutlass_scaled_fp4_mm.csv

[OK] cutlass_scaled_fp4_mm completed successfully

======================================================================
Running: dsv3_fused_a_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_fused_a_gemm (Kernel #4)
============================================================

=== Decode Phase (B<=16, low-latency path) ===
  B=1: 0.0051 ms, 5926.6 GFLOPS, 0.26% peak
  B=2: 0.0051 ms, 11871.7 GFLOPS, 0.53% peak
  B=4: 0.0051 ms, 23652.7 GFLOPS, 1.05% peak
  B=8: 0.0052 ms, 46810.2 GFLOPS, 2.08% peak
  B=16: 0.0058 ms, 83894.9 GFLOPS, 3.73% peak
Saved ../results/dsv3_fused_a_gemm.csv

[OK] dsv3_fused_a_gemm completed successfully

======================================================================
Running: dsv3_router_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_router_gemm (Kernel #5)
============================================================

=== Decode Phase ===
  B=1: 0.0020 ms, 1835.8 GFLOPS, 0.08% peak
  B=2: 0.0022 ms, 3276.9 GFLOPS, 0.15% peak
  B=4: 0.0027 ms, 5476.0 GFLOPS, 0.24% peak
  B=8: 0.0036 ms, 8114.9 GFLOPS, 0.36% peak
  B=16: 0.0071 ms, 8236.5 GFLOPS, 0.37% peak
  Skipping B=32: kernel limited to num_tokens <= 16
  Skipping B=64: kernel limited to num_tokens <= 16
  Skipping B=128: kernel limited to num_tokens <= 16

=== Prefill Phase (skipped - kernel limited to 16 tokens) ===
Saved ../results/dsv3_router_gemm.csv

[OK] dsv3_router_gemm completed successfully

======================================================================
Running: bmm_fp8 (BMM, Compute)
======================================================================
============================================================
Benchmark: bmm_fp8 (Kernel #6)
============================================================

=== Decode Phase: q_nope * w_kc ===
  B=1: 0.0055 ms, 3035.3 GFLOPS, 0.07% peak
  B=2: 0.0055 ms, 6074.8 GFLOPS, 0.13% peak
  B=4: 0.0055 ms, 12147.5 GFLOPS, 0.27% peak
  B=8: 0.0055 ms, 24287.6 GFLOPS, 0.54% peak
  B=16: 0.0057 ms, 47507.4 GFLOPS, 1.06% peak
  B=32: 0.0058 ms, 93003.4 GFLOPS, 2.07% peak
  B=64: 0.0061 ms, 174997.3 GFLOPS, 3.89% peak
  B=128: 0.0070 ms, 307136.7 GFLOPS, 6.83% peak

=== Decode Phase: attn * w_vc ===
  B=1: 0.0028 ms, 6090.5 GFLOPS, 0.14% peak
  B=2: 0.0028 ms, 12160.0 GFLOPS, 0.27% peak
  B=4: 0.0028 ms, 24316.1 GFLOPS, 0.54% peak
  B=8: 0.0028 ms, 48321.8 GFLOPS, 1.07% peak
  B=16: 0.0031 ms, 85441.3 GFLOPS, 1.90% peak
  B=32: 0.0032 ms, 167231.4 GFLOPS, 3.72% peak
  B=64: 0.0034 ms, 318396.2 GFLOPS, 7.08% peak
  B=128: 0.0037 ms, 573424.2 GFLOPS, 12.74% peak
Saved ../results/bmm_fp8.csv

[OK] bmm_fp8 completed successfully

======================================================================
Running: cutlass_mla_decode (Attention, Mixed)
======================================================================
============================================================
Benchmark: cutlass_mla_decode (Kernel #7)
============================================================

=== Decode Phase (MLA Attention) ===
  B=1, seq_len=128: 0.0179 ms, 16.5 GB/s, memory
  B=1, seq_len=256: 0.0294 ms, 15.0 GB/s, memory
  B=1, seq_len=512: 0.0303 ms, 24.4 GB/s, memory
  B=1, seq_len=1024: 0.0301 ms, 44.2 GB/s, memory
  Skipping B=1, seq_len=2048: B*seq_len=2048 > 1024 (crash risk)
  B=2, seq_len=128: 0.0179 ms, 33.0 GB/s, memory
  B=2, seq_len=256: 0.0294 ms, 30.1 GB/s, memory
  B=2, seq_len=512: 0.0293 ms, 50.3 GB/s, memory
  Skipping B=2, seq_len=1024: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=2, seq_len=2048: B*seq_len=4096 > 1024 (crash risk)
  B=4, seq_len=128: 0.0179 ms, 65.9 GB/s, memory
  B=4, seq_len=256: 0.0295 ms, 60.0 GB/s, memory
  Skipping B=4, seq_len=512: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=4, seq_len=1024: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=4, seq_len=2048: B*seq_len=8192 > 1024 (crash risk)
  B=8, seq_len=128: 0.0179 ms, 131.5 GB/s, memory
  Skipping B=8, seq_len=256: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=8, seq_len=512: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=8, seq_len=1024: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=8, seq_len=2048: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=128: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=16, seq_len=256: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=16, seq_len=512: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=16, seq_len=1024: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=2048: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=128: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=32, seq_len=256: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=32, seq_len=512: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=32, seq_len=1024: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=2048: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=128: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=64, seq_len=256: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=64, seq_len=512: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=64, seq_len=1024: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=2048: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=128: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=128, seq_len=256: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=128, seq_len=512: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=128, seq_len=1024: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=2048: B*seq_len=262144 > 1024 (crash risk)
Saved ../results/cutlass_mla_decode.csv

[OK] cutlass_mla_decode completed successfully

======================================================================
Running: trtllm_batch_decode_with_kv_cache_mla (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_batch_decode_with_kv_cache_mla (Kernel #8)
============================================================

=== Decode Phase (TRT-LLM MLA Attention) ===

  Page size: 32
    B=1, seq_len=128: 0.0054 ms, 54.7 GB/s, memory
    B=1, seq_len=256: 0.0054 ms, 81.8 GB/s, memory
    B=1, seq_len=512: 0.0073 ms, 100.8 GB/s, memory
    B=1, seq_len=1024: 0.0097 ms, 137.4 GB/s, memory
    B=1, seq_len=2048: 0.0111 ms, 225.8 GB/s, memory
    B=2, seq_len=128: 0.0059 ms, 99.7 GB/s, memory
    B=2, seq_len=256: 0.0060 ms, 147.9 GB/s, memory
    B=2, seq_len=512: 0.0080 ms, 183.2 GB/s, memory
    B=2, seq_len=1024: 0.0101 ms, 263.0 GB/s, memory
    B=2, seq_len=2048: 0.0125 ms, 401.4 GB/s, memory
    B=4, seq_len=128: 0.0069 ms, 172.0 GB/s, memory
    B=4, seq_len=256: 0.0068 ms, 258.8 GB/s, memory
    B=4, seq_len=512: 0.0090 ms, 328.2 GB/s, memory
    B=4, seq_len=1024: 0.0114 ms, 465.1 GB/s, memory
    B=4, seq_len=2048: 0.0158 ms, 633.0 GB/s, memory
    B=8, seq_len=128: 0.0076 ms, 311.5 GB/s, memory
    B=8, seq_len=256: 0.0076 ms, 467.1 GB/s, memory
    B=8, seq_len=512: 0.0103 ms, 573.5 GB/s, memory
    B=8, seq_len=1024: 0.0154 ms, 690.0 GB/s, memory
    B=8, seq_len=2048: 0.0232 ms, 863.3 GB/s, memory
    B=16, seq_len=128: 0.0093 ms, 504.7 GB/s, memory
    B=16, seq_len=256: 0.0092 ms, 766.4 GB/s, memory
    B=16, seq_len=512: 0.0130 ms, 909.6 GB/s, memory
    B=16, seq_len=1024: 0.0200 ms, 1061.4 GB/s, memory
    B=16, seq_len=2048: 0.0153 ms, 2615.8 GB/s, memory
    B=32, seq_len=128: 0.0075 ms, 1264.1 GB/s, memory
    B=32, seq_len=256: 0.0088 ms, 1610.5 GB/s, memory
    B=32, seq_len=512: 0.0139 ms, 1697.8 GB/s, memory
    B=32, seq_len=1024: 0.0166 ms, 2563.8 GB/s, memory
    B=32, seq_len=2048: 0.0228 ms, 3517.4 GB/s, memory
    B=64, seq_len=128: 0.0081 ms, 2318.1 GB/s, memory
    B=64, seq_len=256: 0.0099 ms, 2866.8 GB/s, memory
    B=64, seq_len=512: 0.0125 ms, 3764.4 GB/s, memory
    B=64, seq_len=1024: 0.0189 ms, 4482.7 GB/s, memory
    B=64, seq_len=2048: 0.0432 ms, 3710.0 GB/s, memory
    B=128, seq_len=128: 0.0132 ms, 2869.8 GB/s, memory
    B=128, seq_len=256: 0.0166 ms, 3401.2 GB/s, memory
    B=128, seq_len=512: 0.0242 ms, 3897.1 GB/s, memory
    B=128, seq_len=1024: 0.0468 ms, 3633.0 GB/s, memory
    B=128, seq_len=2048: 0.0836 ms, 3837.3 GB/s, memory

  Page size: 64
    B=1, seq_len=128: 0.0055 ms, 53.5 GB/s, memory
    B=1, seq_len=256: 0.0055 ms, 81.1 GB/s, memory
    B=1, seq_len=512: 0.0074 ms, 99.0 GB/s, memory
    B=1, seq_len=1024: 0.0098 ms, 136.1 GB/s, memory
    B=1, seq_len=2048: 0.0108 ms, 232.7 GB/s, memory
    B=2, seq_len=128: 0.0056 ms, 104.6 GB/s, memory
    B=2, seq_len=256: 0.0058 ms, 151.9 GB/s, memory
    B=2, seq_len=512: 0.0076 ms, 194.9 GB/s, memory
    B=2, seq_len=1024: 0.0096 ms, 277.3 GB/s, memory
    B=2, seq_len=2048: 0.0111 ms, 450.4 GB/s, memory
    B=4, seq_len=128: 0.0064 ms, 185.0 GB/s, memory
    B=4, seq_len=256: 0.0065 ms, 270.6 GB/s, memory
    B=4, seq_len=512: 0.0083 ms, 357.2 GB/s, memory
    B=4, seq_len=1024: 0.0107 ms, 496.5 GB/s, memory
    B=4, seq_len=2048: 0.0141 ms, 710.1 GB/s, memory
    B=8, seq_len=128: 0.0071 ms, 333.1 GB/s, memory
    B=8, seq_len=256: 0.0069 ms, 515.6 GB/s, memory
    B=8, seq_len=512: 0.0093 ms, 633.2 GB/s, memory
    B=8, seq_len=1024: 0.0134 ms, 794.0 GB/s, memory
    B=8, seq_len=2048: 0.0202 ms, 992.7 GB/s, memory
    B=16, seq_len=128: 0.0081 ms, 584.0 GB/s, memory
    B=16, seq_len=256: 0.0083 ms, 856.7 GB/s, memory
    B=16, seq_len=512: 0.0115 ms, 1026.0 GB/s, memory
    B=16, seq_len=1024: 0.0184 ms, 1155.4 GB/s, memory
    B=16, seq_len=2048: 0.0149 ms, 2688.2 GB/s, memory
    B=32, seq_len=128: 0.0072 ms, 1306.8 GB/s, memory
    B=32, seq_len=256: 0.0085 ms, 1674.2 GB/s, memory
    B=32, seq_len=512: 0.0137 ms, 1716.7 GB/s, memory
    B=32, seq_len=1024: 0.0164 ms, 2591.2 GB/s, memory
    B=32, seq_len=2048: 0.0220 ms, 3641.1 GB/s, memory
    B=64, seq_len=128: 0.0081 ms, 2320.2 GB/s, memory
    B=64, seq_len=256: 0.0097 ms, 2909.4 GB/s, memory
    B=64, seq_len=512: 0.0123 ms, 3835.4 GB/s, memory
    B=64, seq_len=1024: 0.0180 ms, 4717.5 GB/s, memory
    B=64, seq_len=2048: 0.0420 ms, 3820.3 GB/s, memory
    B=128, seq_len=128: 0.0122 ms, 3087.8 GB/s, memory
    B=128, seq_len=256: 0.0163 ms, 3467.1 GB/s, memory
    B=128, seq_len=512: 0.0240 ms, 3929.9 GB/s, memory
    B=128, seq_len=1024: 0.0444 ms, 3821.6 GB/s, memory
    B=128, seq_len=2048: 0.0834 ms, 3847.1 GB/s, memory
Saved ../results/trtllm_batch_decode_with_kv_cache_mla.csv

[OK] trtllm_batch_decode_with_kv_cache_mla completed successfully

======================================================================
Running: trtllm_ragged_attention_deepseek (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_ragged_attention_deepseek (Kernel #9)
============================================================

=== Prefill Phase (TRT-LLM Ragged Attention) ===
  B=1, S=128: 0.0072 ms, 735.6 GFLOPS, memory
  B=1, S=256: 0.0103 ms, 3312.3 GFLOPS, memory
  B=1, S=512: 0.0181 ms, 4878.7 GFLOPS, memory
  B=1, S=1024: 0.0345 ms, 7886.8 GFLOPS, memory
  B=1, S=2048: 0.0817 ms, 11515.7 GFLOPS, memory
  B=2, S=128: 0.0115 ms, 1177.1 GFLOPS, memory
  B=2, S=256: 0.0174 ms, 4339.2 GFLOPS, memory
  B=2, S=512: 0.0359 ms, 5237.9 GFLOPS, memory
  B=2, S=1024: 0.0884 ms, 9364.2 GFLOPS, memory
  B=2, S=2048: 0.2521 ms, 13745.5 GFLOPS, memory
  B=4, S=128: 0.0192 ms, 1632.5 GFLOPS, memory
  B=4, S=256: 0.0340 ms, 3502.0 GFLOPS, memory
  B=4, S=512: 0.0735 ms, 6327.0 GFLOPS, memory
  B=4, S=1024: 0.1596 ms, 9677.4 GFLOPS, memory
  B=4, S=2048: 0.5044 ms, 13285.7 GFLOPS, memory
  B=8, S=128: 0.0350 ms, 1815.0 GFLOPS, memory
  B=8, S=256: 0.0598 ms, 3701.0 GFLOPS, memory
  B=8, S=512: 0.1367 ms, 6014.0 GFLOPS, memory
  B=8, S=1024: 0.3487 ms, 9077.1 GFLOPS, memory
  B=8, S=2048: 1.0037 ms, 13512.2 GFLOPS, memory
  B=16, S=128: 0.0665 ms, 1726.3 GFLOPS, memory
  B=16, S=256: 0.1177 ms, 3717.5 GFLOPS, memory
  B=16, S=512: 0.2829 ms, 6033.6 GFLOPS, memory
  B=16, S=1024: 0.7390 ms, 9520.9 GFLOPS, memory
  B=16, S=2048: 2.0206 ms, 14137.4 GFLOPS, memory
  B=32, S=128: 0.1295 ms, 1694.1 GFLOPS, memory
  B=32, S=256: 0.2319 ms, 3845.3 GFLOPS, memory
  B=32, S=512: 0.5808 ms, 6320.4 GFLOPS, memory
  B=32, S=1024: 1.4467 ms, 10084.4 GFLOPS, memory
  B=32, S=2048: 4.2007 ms, 14429.3 GFLOPS, memory
  B=64, S=128: 0.2588 ms, 1674.0 GFLOPS, memory
  B=64, S=256: 0.4635 ms, 3625.4 GFLOPS, memory
  B=64, S=512: 1.1515 ms, 6257.8 GFLOPS, memory
  B=64, S=1024: 2.9307 ms, 10070.3 GFLOPS, memory
  B=64, S=2048: 7.7886 ms, 14867.5 GFLOPS, memory
  B=128, S=128: 0.5130 ms, 1748.1 GFLOPS, memory
  B=128, S=256: 0.9267 ms, 3689.9 GFLOPS, memory
  B=128, S=512: 2.3034 ms, 6082.2 GFLOPS, memory
  B=128, S=1024: 5.7618 ms, 9738.5 GFLOPS, memory
Warning: Kernel failed for B=128, S=2048: Error in function 'aligned_alloc' at /usr/local/lib/python3.12/dist-packages/flashinfer/data/include/flashinfer/allocator.h:49: Buffer overflow when allocating memory for trtllm_gen_softmax_workspace with size 200737792 and alignment 16, but only 125829120 bytes available in AlignedAllocator. Increase the workspace buffer size.
Saved ../results/trtllm_ragged_attention_deepseek.csv

[OK] trtllm_ragged_attention_deepseek completed successfully

======================================================================
Running: mla_rope_quantize_fp8 (Attention, Memory)
======================================================================
============================================================
Benchmark: rope_quantize_fp8 (MLA config) (Kernel #10)
MLA: 128 Q heads, 1 K head, 64 rope_dim + 512 no_rope_dim
============================================================

=== MLA RoPE + FP8 Quantization ===
  tokens=128: 0.0064 ms, 4606.8 GB/s, 57.6% peak
  tokens=256: 0.0114 ms, 5101.8 GB/s, 63.8% peak
  tokens=512: 0.0237 ms, 4850.8 GB/s, 60.6% peak
  tokens=1024: 0.0466 ms, 4916.1 GB/s, 61.5% peak
  tokens=2048: 0.0918 ms, 4982.6 GB/s, 62.3% peak
  tokens=4096: 0.1833 ms, 4987.4 GB/s, 62.3% peak
  tokens=8192: 0.3678 ms, 4970.8 GB/s, 62.1% peak
  tokens=16384: 0.7470 ms, 4895.0 GB/s, 61.2% peak
  tokens=32768: 1.5417 ms, 4743.2 GB/s, 59.3% peak
  tokens=65536: 3.0740 ms, 4757.8 GB/s, 59.5% peak
  tokens=131072: 6.1745 ms, 4737.4 GB/s, 59.2% peak
  tokens=262144: 13.9702 ms, 4187.6 GB/s, 52.3% peak
Saved ../results/mla_rope_quantize_fp8.csv

[OK] mla_rope_quantize_fp8 completed successfully

======================================================================
Running: apply_rope_with_cos_sin_cache_inplace (RoPE, Memory)
======================================================================
============================================================
Benchmark: apply_rope_with_cos_sin_cache_inplace (Kernel #11)
============================================================

=== Decode Phase ===
  B=1: 0.0017 ms, 345.9 GB/s, 4.3% peak
  B=2: 0.0017 ms, 385.0 GB/s, 4.8% peak
  B=4: 0.0017 ms, 454.0 GB/s, 5.7% peak
  B=8: 0.0017 ms, 601.8 GB/s, 7.5% peak
  B=16: 0.0018 ms, 877.2 GB/s, 11.0% peak
  B=32: 0.0019 ms, 1411.3 GB/s, 17.6% peak
  B=64: 0.0022 ms, 2173.7 GB/s, 27.2% peak
  B=128: 0.0033 ms, 2718.8 GB/s, 34.0% peak

=== Prefill Phase ===
  B=1, S=128: 0.0032 ms, 2747.6 GB/s, 34.3% peak
  B=1, S=256: 0.0046 ms, 3747.5 GB/s, 46.8% peak
  B=1, S=512: 0.0073 ms, 4675.7 GB/s, 58.4% peak
  B=1, S=1024: 0.0127 ms, 5314.6 GB/s, 66.4% peak
  B=1, S=2048: 0.0242 ms, 5564.1 GB/s, 69.6% peak
  B=2, S=128: 0.0046 ms, 3732.5 GB/s, 46.7% peak
  B=2, S=256: 0.0073 ms, 4665.7 GB/s, 58.3% peak
  B=2, S=512: 0.0127 ms, 5309.0 GB/s, 66.4% peak
  B=2, S=1024: 0.0245 ms, 5497.5 GB/s, 68.7% peak
  B=2, S=2048: 0.0677 ms, 3974.7 GB/s, 49.7% peak
  B=4, S=128: 0.0073 ms, 4665.5 GB/s, 58.3% peak
  B=4, S=256: 0.0127 ms, 5332.5 GB/s, 66.7% peak
  B=4, S=512: 0.0243 ms, 5551.9 GB/s, 69.4% peak
  B=4, S=1024: 0.0676 ms, 3979.1 GB/s, 49.7% peak
  B=4, S=2048: 0.1385 ms, 3880.6 GB/s, 48.5% peak
  B=8, S=128: 0.0127 ms, 5344.4 GB/s, 66.8% peak
  B=8, S=256: 0.0239 ms, 5627.3 GB/s, 70.3% peak
  B=8, S=512: 0.0671 ms, 4008.6 GB/s, 50.1% peak
  B=8, S=1024: 0.1376 ms, 3904.7 GB/s, 48.8% peak
  B=8, S=2048: 0.2856 ms, 3761.6 GB/s, 47.0% peak
Saved ../results/apply_rope_with_cos_sin_cache_inplace.csv

[OK] apply_rope_with_cos_sin_cache_inplace completed successfully

======================================================================
Running: concat_mla_k (Concat, Memory)
======================================================================
============================================================
Benchmark: concat_mla_k (Kernel #12)
============================================================

=== Decode Phase ===
  B=1: 0.0021 ms, 39.8 GB/s, 0.5% peak
  B=2: 0.0030 ms, 55.3 GB/s, 0.7% peak
  B=4: 0.0048 ms, 69.0 GB/s, 0.9% peak
  B=8: 0.0048 ms, 137.0 GB/s, 1.7% peak
  B=16: 0.0048 ms, 273.8 GB/s, 3.4% peak
  B=32: 0.0048 ms, 548.0 GB/s, 6.8% peak
  B=64: 0.0049 ms, 1075.0 GB/s, 13.4% peak
  B=128: 0.0049 ms, 2134.5 GB/s, 26.7% peak

=== Prefill Phase ===
  B=1, S=128: 0.0049 ms, 2135.3 GB/s, 26.7% peak
  B=1, S=256: 0.0049 ms, 4254.0 GB/s, 53.2% peak
  B=1, S=512: 0.0054 ms, 7835.0 GB/s, 97.9% peak
  B=1, S=1024: 0.0107 ms, 7843.3 GB/s, 98.0% peak
  B=1, S=2048: 0.0274 ms, 6136.3 GB/s, 76.7% peak
  B=2, S=128: 0.0050 ms, 4225.1 GB/s, 52.8% peak
  B=2, S=256: 0.0051 ms, 8218.7 GB/s, 102.7% peak
  B=2, S=512: 0.0095 ms, 8811.5 GB/s, 110.1% peak
  B=2, S=1024: 0.0275 ms, 6119.6 GB/s, 76.5% peak
  B=2, S=2048: 0.0522 ms, 6443.9 GB/s, 80.5% peak
  B=4, S=128: 0.0051 ms, 8265.9 GB/s, 103.3% peak
  B=4, S=256: 0.0094 ms, 8937.1 GB/s, 111.7% peak
  B=4, S=512: 0.0273 ms, 6146.2 GB/s, 76.8% peak
  B=4, S=1024: 0.0522 ms, 6435.7 GB/s, 80.4% peak
  B=4, S=2048: 0.1010 ms, 6656.4 GB/s, 83.2% peak
  B=8, S=128: 0.0094 ms, 8929.2 GB/s, 111.6% peak
  B=8, S=256: 0.0274 ms, 6131.5 GB/s, 76.6% peak
  B=8, S=512: 0.0526 ms, 6392.9 GB/s, 79.9% peak
  B=8, S=1024: 0.1010 ms, 6651.7 GB/s, 83.1% peak
  B=8, S=2048: 0.1984 ms, 6775.5 GB/s, 84.7% peak
Saved ../results/concat_mla_k.csv

[OK] concat_mla_k completed successfully

======================================================================
Running: silu_and_mul (Activation, Memory)
======================================================================
============================================================
Benchmark: silu_and_mul (Kernel #13)
============================================================

=== Decode Phase ===
  B=1: 0.0018 ms, 6.9 GB/s, 0.1% peak
  B=2: 0.0018 ms, 13.8 GB/s, 0.2% peak
  B=4: 0.0018 ms, 27.6 GB/s, 0.3% peak
  B=8: 0.0018 ms, 55.3 GB/s, 0.7% peak
  B=16: 0.0019 ms, 104.7 GB/s, 1.3% peak
  B=32: 0.0019 ms, 210.5 GB/s, 2.6% peak
  B=64: 0.0019 ms, 414.9 GB/s, 5.2% peak
  B=128: 0.0019 ms, 813.1 GB/s, 10.2% peak

=== Prefill Phase ===
  B=1, S=128: 0.0019 ms, 812.2 GB/s, 10.2% peak
  B=1, S=256: 0.0021 ms, 1479.6 GB/s, 18.5% peak
  B=1, S=512: 0.0028 ms, 2247.5 GB/s, 28.1% peak
  B=1, S=1024: 0.0038 ms, 3293.1 GB/s, 41.2% peak
  B=1, S=2048: 0.0058 ms, 4369.2 GB/s, 54.6% peak
  B=2, S=128: 0.0021 ms, 1477.7 GB/s, 18.5% peak
  B=2, S=256: 0.0028 ms, 2249.0 GB/s, 28.1% peak
  B=2, S=512: 0.0038 ms, 3293.2 GB/s, 41.2% peak
  B=2, S=1024: 0.0058 ms, 4369.2 GB/s, 54.6% peak
  B=2, S=2048: 0.0098 ms, 5128.6 GB/s, 64.1% peak
  B=4, S=128: 0.0029 ms, 2158.4 GB/s, 27.0% peak
  B=4, S=256: 0.0038 ms, 3295.5 GB/s, 41.2% peak
  B=4, S=512: 0.0058 ms, 4368.1 GB/s, 54.6% peak
  B=4, S=1024: 0.0098 ms, 5127.5 GB/s, 64.1% peak
  B=4, S=2048: 0.0198 ms, 5076.9 GB/s, 63.5% peak
  B=8, S=128: 0.0039 ms, 3266.8 GB/s, 40.8% peak
  B=8, S=256: 0.0058 ms, 4362.2 GB/s, 54.5% peak
  B=8, S=512: 0.0098 ms, 5117.5 GB/s, 64.0% peak
  B=8, S=1024: 0.0199 ms, 5065.3 GB/s, 63.3% peak
  B=8, S=2048: 0.0399 ms, 5044.2 GB/s, 63.1% peak
Saved ../results/silu_and_mul.csv

[OK] silu_and_mul completed successfully

======================================================================
Running: topk_softmax (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_softmax (Kernel #14)
============================================================

=== Decode Phase ===
  B=1: 0.0034 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0034 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0034 ms, 1.3 GB/s, 0.0% peak
  B=8: 0.0034 ms, 2.6 GB/s, 0.0% peak
  B=16: 0.0034 ms, 5.1 GB/s, 0.1% peak
  B=32: 0.0034 ms, 10.2 GB/s, 0.1% peak
  B=64: 0.0035 ms, 19.9 GB/s, 0.2% peak
  B=128: 0.0035 ms, 39.7 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0035 ms, 39.7 GB/s, 0.5% peak
  B=1, S=256: 0.0035 ms, 78.7 GB/s, 1.0% peak
  B=1, S=512: 0.0036 ms, 156.0 GB/s, 2.0% peak
  B=1, S=1024: 0.0039 ms, 286.0 GB/s, 3.6% peak
  B=1, S=2048: 0.0053 ms, 422.7 GB/s, 5.3% peak
  B=2, S=128: 0.0035 ms, 78.7 GB/s, 1.0% peak
  B=2, S=256: 0.0036 ms, 156.0 GB/s, 2.0% peak
  B=2, S=512: 0.0039 ms, 286.0 GB/s, 3.6% peak
  B=2, S=1024: 0.0053 ms, 423.0 GB/s, 5.3% peak
  B=2, S=2048: 0.0078 ms, 572.1 GB/s, 7.2% peak
  B=4, S=128: 0.0036 ms, 156.0 GB/s, 1.9% peak
  B=4, S=256: 0.0039 ms, 285.9 GB/s, 3.6% peak
  B=4, S=512: 0.0053 ms, 422.9 GB/s, 5.3% peak
  B=4, S=1024: 0.0078 ms, 572.1 GB/s, 7.2% peak
  B=4, S=2048: 0.0132 ms, 672.7 GB/s, 8.4% peak
  B=8, S=128: 0.0039 ms, 286.0 GB/s, 3.6% peak
  B=8, S=256: 0.0053 ms, 422.9 GB/s, 5.3% peak
  B=8, S=512: 0.0078 ms, 572.1 GB/s, 7.2% peak
  B=8, S=1024: 0.0132 ms, 672.7 GB/s, 8.4% peak
  B=8, S=2048: 0.0237 ms, 752.9 GB/s, 9.4% peak
Saved ../results/topk_softmax.csv

[OK] topk_softmax completed successfully

======================================================================
Running: topk_sigmoid (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_sigmoid (Kernel #15)
============================================================

=== Decode Phase ===
  B=1: 0.0034 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0035 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0037 ms, 1.2 GB/s, 0.0% peak
  B=8: 0.0037 ms, 2.4 GB/s, 0.0% peak
  B=16: 0.0037 ms, 4.7 GB/s, 0.1% peak
  B=32: 0.0037 ms, 9.5 GB/s, 0.1% peak
  B=64: 0.0038 ms, 18.5 GB/s, 0.2% peak
  B=128: 0.0038 ms, 36.9 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0038 ms, 36.9 GB/s, 0.5% peak
  B=1, S=256: 0.0038 ms, 73.5 GB/s, 0.9% peak
  B=1, S=512: 0.0038 ms, 145.8 GB/s, 1.8% peak
  B=1, S=1024: 0.0041 ms, 272.4 GB/s, 3.4% peak
  B=1, S=2048: 0.0054 ms, 416.3 GB/s, 5.2% peak
  B=2, S=128: 0.0038 ms, 73.5 GB/s, 0.9% peak
  B=2, S=256: 0.0038 ms, 145.9 GB/s, 1.8% peak
  B=2, S=512: 0.0041 ms, 272.3 GB/s, 3.4% peak
  B=2, S=1024: 0.0054 ms, 416.4 GB/s, 5.2% peak
  B=2, S=2048: 0.0077 ms, 576.6 GB/s, 7.2% peak
  B=4, S=128: 0.0038 ms, 145.9 GB/s, 1.8% peak
  B=4, S=256: 0.0041 ms, 272.3 GB/s, 3.4% peak
  B=4, S=512: 0.0054 ms, 416.4 GB/s, 5.2% peak
  B=4, S=1024: 0.0077 ms, 576.6 GB/s, 7.2% peak
  B=4, S=2048: 0.0130 ms, 688.1 GB/s, 8.6% peak
  B=8, S=128: 0.0041 ms, 272.3 GB/s, 3.4% peak
  B=8, S=256: 0.0054 ms, 416.3 GB/s, 5.2% peak
  B=8, S=512: 0.0077 ms, 576.4 GB/s, 7.2% peak
  B=8, S=1024: 0.0129 ms, 688.3 GB/s, 8.6% peak
  B=8, S=2048: 0.0228 ms, 780.7 GB/s, 9.8% peak
Saved ../results/topk_sigmoid.csv

[OK] topk_sigmoid completed successfully

======================================================================
Running: moe_fused_gate (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: moe_fused_gate (Kernel #16)
============================================================

=== Decode Phase ===
  B=1: 0.0108 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0110 ms, 0.3 GB/s, 0.0% peak
  B=4: 0.0113 ms, 0.5 GB/s, 0.0% peak
  B=8: 0.0121 ms, 0.8 GB/s, 0.0% peak
  B=16: 0.0136 ms, 1.4 GB/s, 0.0% peak
  B=32: 0.0157 ms, 2.3 GB/s, 0.0% peak
  B=64: 0.0157 ms, 4.5 GB/s, 0.1% peak
  B=128: 0.0156 ms, 9.0 GB/s, 0.1% peak

=== Prefill Phase ===
  B=1, S=128: 0.0157 ms, 9.0 GB/s, 0.1% peak
  B=1, S=256: 0.0159 ms, 17.6 GB/s, 0.2% peak
  B=1, S=512: 0.0159 ms, 35.2 GB/s, 0.4% peak
  B=1, S=1024: 0.0159 ms, 70.1 GB/s, 0.9% peak
  B=1, S=2048: 0.0158 ms, 141.1 GB/s, 1.8% peak
  B=2, S=128: 0.0155 ms, 18.0 GB/s, 0.2% peak
  B=2, S=256: 0.0158 ms, 35.3 GB/s, 0.4% peak
  B=2, S=512: 0.0158 ms, 70.5 GB/s, 0.9% peak
  B=2, S=1024: 0.0158 ms, 140.7 GB/s, 1.8% peak
  B=2, S=2048: 0.0219 ms, 203.4 GB/s, 2.5% peak
  B=4, S=128: 0.0158 ms, 35.2 GB/s, 0.4% peak
  B=4, S=256: 0.0160 ms, 69.9 GB/s, 0.9% peak
  B=4, S=512: 0.0159 ms, 140.4 GB/s, 1.8% peak
  B=4, S=1024: 0.0217 ms, 205.3 GB/s, 2.6% peak
  B=4, S=2048: 0.0284 ms, 313.7 GB/s, 3.9% peak
  B=8, S=128: 0.0158 ms, 70.4 GB/s, 0.9% peak
  B=8, S=256: 0.0158 ms, 140.9 GB/s, 1.8% peak
  B=8, S=512: 0.0218 ms, 204.2 GB/s, 2.6% peak
  B=8, S=1024: 0.0285 ms, 312.5 GB/s, 3.9% peak
  B=8, S=2048: 0.0448 ms, 397.9 GB/s, 5.0% peak
Saved ../results/moe_fused_gate.csv

[OK] moe_fused_gate completed successfully

======================================================================
Running: prepare_moe_input (MoE, Memory)
======================================================================
============================================================
Benchmark: prepare_moe_input (Kernel #17)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=2, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=4, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=8, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=16, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=32, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=64, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=128, S=1: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=1, S=256: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=1, S=512: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=1, S=1024: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=1, S=2048: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=2, S=128: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=2, S=256: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=2, S=512: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=2, S=1024: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=2, S=2048: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=4, S=128: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=4, S=256: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=4, S=512: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=4, S=1024: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=4, S=2048: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=8, S=128: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=8, S=256: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=8, S=512: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=8, S=1024: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'
Warning: Kernel failed for B=8, S=2048: prepare_moe_input() missing 6 required positional arguments: 'problem_sizes2', 'input_permutation', 'output_permutation', 'num_experts', 'n', and 'k'

No results - kernel not available

[FAILED] prepare_moe_input: No CSV output (kernel not available or all runs failed)

======================================================================
Running: scaled_fp4_experts_quant (MoE, Memory)
======================================================================
============================================================
Benchmark: scaled_fp4_experts_quant (Kernel #18)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=2, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=4, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=8, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=16, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=32, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=64, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=128, S=1: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=1, S=256: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=1, S=512: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=1, S=1024: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=1, S=2048: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=2, S=128: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=2, S=256: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=2, S=512: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=2, S=1024: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=2, S=2048: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=4, S=128: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=4, S=256: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=4, S=512: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=4, S=1024: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=4, S=2048: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=8, S=128: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=8, S=256: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=8, S=512: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=8, S=1024: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'
Warning: Kernel failed for B=8, S=2048: scaled_fp4_experts_quant() missing 4 required positional arguments: 'input_global_scale', 'expert_offsets', 'blockscale_offsets', and 'topk'

No results - kernel not available

[FAILED] scaled_fp4_experts_quant: No CSV output (kernel not available or all runs failed)

======================================================================
Running: cutlass_fp4_group_mm (MoE, Compute)
======================================================================
============================================================
Benchmark: cutlass_fp4_group_mm (Kernel #19)
============================================================

=== Decode Phase: gate_up ===
Warning: Kernel failed for B=1, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=16, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=32, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=64, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=128, S=1, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'

=== Decode Phase: down ===
Warning: Kernel failed for B=1, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=16, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=32, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=64, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=128, S=1, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'

=== Prefill Phase: gate_up ===
Warning: Kernel failed for B=1, S=128, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=256, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=512, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=1024, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=2048, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=128, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=256, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=512, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=1024, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=2048, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=128, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=256, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=512, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=1024, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=2048, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=128, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=256, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=512, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=1024, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=2048, op=gate_up: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'

=== Prefill Phase: down ===
Warning: Kernel failed for B=1, S=128, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=256, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=512, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=1024, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=1, S=2048, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=128, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=256, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=512, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=1024, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=2, S=2048, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=128, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=256, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=512, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=1024, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=4, S=2048, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=128, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=256, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=512, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=1024, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'
Warning: Kernel failed for B=8, S=2048, op=down: cutlass_fp4_group_mm() missing 1 required positional argument: 'params'

No results - kernel not available

[FAILED] cutlass_fp4_group_mm: No CSV output (kernel not available or all runs failed)

======================================================================
Running: apply_shuffle_mul_sum (MoE, Memory)
======================================================================
============================================================
Benchmark: apply_shuffle_mul_sum (Kernel #20)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: Factors must match output dtype
Warning: Kernel failed for B=2, S=1: Factors must match output dtype
Warning: Kernel failed for B=4, S=1: Factors must match output dtype
Warning: Kernel failed for B=8, S=1: Factors must match output dtype
Warning: Kernel failed for B=16, S=1: Factors must match output dtype
Warning: Kernel failed for B=32, S=1: Factors must match output dtype
Warning: Kernel failed for B=64, S=1: Factors must match output dtype
Warning: Kernel failed for B=128, S=1: Factors must match output dtype

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: Factors must match output dtype
Warning: Kernel failed for B=1, S=256: Factors must match output dtype
Warning: Kernel failed for B=1, S=512: Factors must match output dtype
Warning: Kernel failed for B=1, S=1024: Factors must match output dtype
Warning: Kernel failed for B=1, S=2048: Factors must match output dtype
Warning: Kernel failed for B=2, S=128: Factors must match output dtype
Warning: Kernel failed for B=2, S=256: Factors must match output dtype
Warning: Kernel failed for B=2, S=512: Factors must match output dtype
Warning: Kernel failed for B=2, S=1024: Factors must match output dtype
Warning: Kernel failed for B=2, S=2048: Factors must match output dtype
Warning: Kernel failed for B=4, S=128: Factors must match output dtype
Warning: Kernel failed for B=4, S=256: Factors must match output dtype
Warning: Kernel failed for B=4, S=512: Factors must match output dtype
Warning: Kernel failed for B=4, S=1024: Factors must match output dtype
Warning: Kernel failed for B=4, S=2048: Factors must match output dtype
Warning: Kernel failed for B=8, S=128: Factors must match output dtype
Warning: Kernel failed for B=8, S=256: Factors must match output dtype
Warning: Kernel failed for B=8, S=512: Factors must match output dtype
Warning: Kernel failed for B=8, S=1024: Factors must match output dtype
Warning: Kernel failed for B=8, S=2048: Factors must match output dtype

No results - kernel not available

[FAILED] apply_shuffle_mul_sum: No CSV output (kernel not available or all runs failed)

======================================================================
Running: moe_align_block_size (MoE, Memory)
======================================================================
============================================================
Benchmark: moe_align_block_size (Kernel #21)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=2, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=4, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=8, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=16, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=32, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=64, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=128, S=1: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=1, S=256: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=1, S=512: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=1, S=1024: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=1, S=2048: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=2, S=128: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=2, S=256: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=2, S=512: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=2, S=1024: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=2, S=2048: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=4, S=128: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=4, S=256: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=4, S=512: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=4, S=1024: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=4, S=2048: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=8, S=128: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=8, S=256: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=8, S=512: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=8, S=1024: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'
Warning: Kernel failed for B=8, S=2048: moe_align_block_size() missing 4 required positional arguments: 'sorted_token_ids', 'experts_ids', 'num_tokens_post_pad', and 'cumsum_buffer'

No results - kernel not available

[FAILED] moe_align_block_size: No CSV output (kernel not available or all runs failed)

======================================================================
Running: trtllm_fp4_block_scale_moe (MoE, Mixed)
======================================================================
============================================================
Benchmark: trtllm_fp4_block_scale_moe (Kernel #22)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: Error in function 'run' at /usr/local/lib/python3.12/dist-packages/flashinfer/data/csrc/trtllm_batched_gemm_runner.cu:258: Error occurred when running GEMM! (numBatches:  256 , GemmMNK:  1   4096   7168 , Kernel:  bmm_E2m1_E2m1E2m1_Fp32_t128x8x512u2_s5_et128x8_m128x8x64_cga1x1x1_16dp256b_rM_TN_transOut_schedP2x1x2x3_bN_ldgsts_tmaOpt_clmp_swiGlu_dynBatch_sm100f )

[FAILED] trtllm_fp4_block_scale_moe: Exit code 1

======================================================================
Running: fused_moe_kernel (MoE, Mixed)
======================================================================
============================================================
Benchmark: fused_moe_kernel (Kernel #23)
============================================================

=== Decode Phase ===
Warning: Kernel failed for B=1, S=1: 'module' object is not callable
Warning: Kernel failed for B=2, S=1: 'module' object is not callable
Warning: Kernel failed for B=4, S=1: 'module' object is not callable
Warning: Kernel failed for B=8, S=1: 'module' object is not callable
Warning: Kernel failed for B=16, S=1: 'module' object is not callable
Warning: Kernel failed for B=32, S=1: 'module' object is not callable
Warning: Kernel failed for B=64, S=1: 'module' object is not callable
Warning: Kernel failed for B=128, S=1: 'module' object is not callable

=== Prefill Phase ===
Warning: Kernel failed for B=1, S=128: 'module' object is not callable
Warning: Kernel failed for B=1, S=256: 'module' object is not callable
Warning: Kernel failed for B=1, S=512: 'module' object is not callable
Warning: Kernel failed for B=1, S=1024: 'module' object is not callable
Warning: Kernel failed for B=1, S=2048: 'module' object is not callable
Warning: Kernel failed for B=2, S=128: 'module' object is not callable
Warning: Kernel failed for B=2, S=256: 'module' object is not callable
Warning: Kernel failed for B=2, S=512: 'module' object is not callable
Warning: Kernel failed for B=2, S=1024: 'module' object is not callable
Warning: Kernel failed for B=2, S=2048: 'module' object is not callable
Warning: Kernel failed for B=4, S=128: 'module' object is not callable
Warning: Kernel failed for B=4, S=256: 'module' object is not callable
Warning: Kernel failed for B=4, S=512: 'module' object is not callable
Warning: Kernel failed for B=4, S=1024: 'module' object is not callable
Warning: Kernel failed for B=4, S=2048: 'module' object is not callable
Warning: Kernel failed for B=8, S=128: 'module' object is not callable
Warning: Kernel failed for B=8, S=256: 'module' object is not callable
Warning: Kernel failed for B=8, S=512: 'module' object is not callable
Warning: Kernel failed for B=8, S=1024: 'module' object is not callable
Warning: Kernel failed for B=8, S=2048: 'module' object is not callable

No results - kernel not available

[FAILED] fused_moe_kernel: No CSV output (kernel not available or all runs failed)

Aggregated results saved to ../results/all_kernels.csv
Total benchmark results: 475

Summary saved to ../results/benchmark_summary.md

======================================================================
Benchmark Complete!
Successful: 16/23
Failed kernels:
  - prepare_moe_input: No CSV output (kernel not available or all runs failed)
  - scaled_fp4_experts_quant: No CSV output (kernel not available or all runs failed)
  - cutlass_fp4_group_mm: No CSV output (kernel not available or all runs failed)
  - apply_shuffle_mul_sum: No CSV output (kernel not available or all runs failed)
  - moe_align_block_size: No CSV output (kernel not available or all runs failed)
  - trtllm_fp4_block_scale_moe: Exit code 1
  - fused_moe_kernel: No CSV output (kernel not available or all runs failed)
======================================================================
