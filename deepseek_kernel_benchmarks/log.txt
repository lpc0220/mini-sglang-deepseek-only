======================================================================
DeepSeek-R1-NVFP4-v2 Kernel Benchmarks
======================================================================
Kernels to run: 23
Batch sizes: 1,2,4,8,16,32,64,128
Sequence lengths: 128,256,512,1024,2048
Output directory: ../results/

NOTE: Each kernel runs in a separate subprocess for isolation.
      CUDA crashes in one kernel will NOT affect other kernels.
======================================================================

======================================================================
Running: rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: rmsnorm (Kernel #1)
============================================================

=== Decode Phase ===
  B=1: 0.0020 ms, 14.5 GB/s, 0.2% peak
  B=2: 0.0020 ms, 28.7 GB/s, 0.4% peak
  B=4: 0.0020 ms, 57.1 GB/s, 0.7% peak
  B=8: 0.0020 ms, 113.8 GB/s, 1.4% peak
  B=16: 0.0020 ms, 229.0 GB/s, 2.9% peak
  B=32: 0.0020 ms, 455.8 GB/s, 5.7% peak
  B=64: 0.0020 ms, 897.6 GB/s, 11.2% peak
  B=128: 0.0021 ms, 1753.9 GB/s, 21.9% peak

=== Prefill Phase ===
  B=1, S=128: 0.0021 ms, 1752.6 GB/s, 21.9% peak
  B=1, S=256: 0.0027 ms, 2690.2 GB/s, 33.6% peak
  B=1, S=512: 0.0046 ms, 3205.5 GB/s, 40.1% peak
  B=1, S=1024: 0.0082 ms, 3564.3 GB/s, 44.6% peak
  B=1, S=2048: 0.0152 ms, 3864.9 GB/s, 48.3% peak
  B=2, S=128: 0.0027 ms, 2690.5 GB/s, 33.6% peak
  B=2, S=256: 0.0046 ms, 3195.4 GB/s, 39.9% peak
  B=2, S=512: 0.0082 ms, 3567.1 GB/s, 44.6% peak
  B=2, S=1024: 0.0152 ms, 3868.3 GB/s, 48.4% peak
  B=2, S=2048: 0.0356 ms, 3300.7 GB/s, 41.3% peak
  B=4, S=128: 0.0046 ms, 3194.3 GB/s, 39.9% peak
  B=4, S=256: 0.0082 ms, 3568.2 GB/s, 44.6% peak
  B=4, S=512: 0.0153 ms, 3840.4 GB/s, 48.0% peak
  B=4, S=1024: 0.0363 ms, 3235.3 GB/s, 40.4% peak
  B=4, S=2048: 0.0700 ms, 3357.5 GB/s, 42.0% peak
  B=8, S=128: 0.0081 ms, 3630.1 GB/s, 45.4% peak
  B=8, S=256: 0.0151 ms, 3898.0 GB/s, 48.7% peak
  B=8, S=512: 0.0365 ms, 3213.6 GB/s, 40.2% peak
  B=8, S=1024: 0.0698 ms, 3363.8 GB/s, 42.0% peak
  B=8, S=2048: 0.1377 ms, 3411.3 GB/s, 42.6% peak
Saved ../results/rmsnorm.csv

[OK] rmsnorm completed successfully

======================================================================
Running: fused_add_rmsnorm (Norm, Memory)
======================================================================
============================================================
Benchmark: fused_add_rmsnorm (Kernel #2)
============================================================

=== Decode Phase ===
  B=1: 0.0024 ms, 23.6 GB/s, 0.3% peak
  B=2: 0.0024 ms, 47.1 GB/s, 0.6% peak
  B=4: 0.0024 ms, 93.8 GB/s, 1.2% peak
  B=8: 0.0025 ms, 183.9 GB/s, 2.3% peak
  B=16: 0.0025 ms, 369.0 GB/s, 4.6% peak
  B=32: 0.0025 ms, 731.7 GB/s, 9.1% peak
  B=64: 0.0025 ms, 1480.2 GB/s, 18.5% peak
  B=128: 0.0026 ms, 2846.2 GB/s, 35.6% peak

=== Prefill Phase ===
  B=1, S=128: 0.0026 ms, 2846.4 GB/s, 35.6% peak
  B=1, S=256: 0.0045 ms, 3271.9 GB/s, 40.9% peak
  B=1, S=512: 0.0080 ms, 3657.9 GB/s, 45.7% peak
  B=1, S=1024: 0.0144 ms, 4085.4 GB/s, 51.1% peak
  B=1, S=2048: 0.0266 ms, 4410.6 GB/s, 55.1% peak
  B=2, S=128: 0.0045 ms, 3238.2 GB/s, 40.5% peak
  B=2, S=256: 0.0080 ms, 3657.7 GB/s, 45.7% peak
  B=2, S=512: 0.0143 ms, 4111.3 GB/s, 51.4% peak
  B=2, S=1024: 0.0266 ms, 4407.2 GB/s, 55.1% peak
  B=2, S=2048: 0.0677 ms, 3470.0 GB/s, 43.4% peak
  B=4, S=128: 0.0080 ms, 3658.8 GB/s, 45.7% peak
  B=4, S=256: 0.0144 ms, 4080.0 GB/s, 51.0% peak
  B=4, S=512: 0.0267 ms, 4405.7 GB/s, 55.1% peak
  B=4, S=1024: 0.0675 ms, 3478.7 GB/s, 43.5% peak
  B=4, S=2048: 0.1309 ms, 3589.3 GB/s, 44.9% peak
  B=8, S=128: 0.0143 ms, 4098.0 GB/s, 51.2% peak
  B=8, S=256: 0.0267 ms, 4392.7 GB/s, 54.9% peak
  B=8, S=512: 0.0685 ms, 3430.3 GB/s, 42.9% peak
  B=8, S=1024: 0.1316 ms, 3568.6 GB/s, 44.6% peak
  B=8, S=2048: 0.2589 ms, 3628.8 GB/s, 45.4% peak
Saved ../results/fused_add_rmsnorm.csv

[OK] fused_add_rmsnorm completed successfully

======================================================================
Running: cutlass_scaled_fp4_mm (GEMM, Compute)
======================================================================
============================================================
Benchmark: cutlass_scaled_fp4_mm (Kernel #3)
============================================================

=== Decode Phase ===
  q_b_proj B=1: 0.0064 ms, 11848.3 GFLOPS, 0.13% peak
  kv_b_proj B=1: 0.0050 ms, 6684.2 GFLOPS, 0.07% peak
  o_proj B=1: 0.0233 ms, 10091.7 GFLOPS, 0.11% peak
  q_b_proj B=2: 0.0064 ms, 23433.1 GFLOPS, 0.26% peak
  kv_b_proj B=2: 0.0050 ms, 13321.2 GFLOPS, 0.15% peak
  o_proj B=2: 0.0235 ms, 20030.9 GFLOPS, 0.22% peak
  q_b_proj B=4: 0.0064 ms, 47437.7 GFLOPS, 0.53% peak
  kv_b_proj B=4: 0.0050 ms, 26786.3 GFLOPS, 0.30% peak
  o_proj B=4: 0.0233 ms, 40277.1 GFLOPS, 0.45% peak
  q_b_proj B=8: 0.0063 ms, 95463.5 GFLOPS, 1.06% peak
  kv_b_proj B=8: 0.0050 ms, 53449.2 GFLOPS, 0.59% peak
  o_proj B=8: 0.0234 ms, 80297.7 GFLOPS, 0.89% peak
  q_b_proj B=16: 0.0063 ms, 190533.7 GFLOPS, 2.12% peak
  kv_b_proj B=16: 0.0050 ms, 107109.1 GFLOPS, 1.19% peak
  o_proj B=16: 0.0234 ms, 160758.0 GFLOPS, 1.79% peak
  q_b_proj B=32: 0.0064 ms, 378382.9 GFLOPS, 4.20% peak
  kv_b_proj B=32: 0.0050 ms, 213496.2 GFLOPS, 2.37% peak
  o_proj B=32: 0.0233 ms, 322400.2 GFLOPS, 3.58% peak
  q_b_proj B=64: 0.0064 ms, 754056.3 GFLOPS, 8.38% peak
  kv_b_proj B=64: 0.0051 ms, 423459.0 GFLOPS, 4.71% peak
  o_proj B=64: 0.0235 ms, 640267.2 GFLOPS, 7.11% peak
  q_b_proj B=128: 0.0068 ms, 1415782.8 GFLOPS, 15.73% peak
  kv_b_proj B=128: 0.0054 ms, 794183.5 GFLOPS, 8.82% peak
  o_proj B=128: 0.0240 ms, 1251584.3 GFLOPS, 13.91% peak

=== Prefill Phase ===
  q_b_proj B=1, S=128: 0.0068 ms, 1410797.3 GFLOPS, 15.68% peak
  kv_b_proj B=1, S=128: 0.0054 ms, 794651.2 GFLOPS, 8.83% peak
  o_proj B=1, S=128: 0.0240 ms, 1251663.8 GFLOPS, 13.91% peak
  q_b_proj B=1, S=256: 0.0089 ms, 2163569.2 GFLOPS, 24.04% peak
  kv_b_proj B=1, S=256: 0.0071 ms, 1215660.3 GFLOPS, 13.51% peak
  o_proj B=1, S=256: 0.0221 ms, 2715914.8 GFLOPS, 30.18% peak
  q_b_proj B=1, S=512: 0.0124 ms, 3127515.0 GFLOPS, 34.75% peak
  kv_b_proj B=1, S=512: 0.0102 ms, 1689402.1 GFLOPS, 18.77% peak
  o_proj B=1, S=512: 0.0236 ms, 5085142.3 GFLOPS, 56.50% peak
  q_b_proj B=1, S=1024: 0.0196 ms, 3935849.9 GFLOPS, 43.73% peak
  kv_b_proj B=1, S=1024: 0.0155 ms, 2212935.9 GFLOPS, 24.59% peak
  o_proj B=1, S=1024: 0.0495 ms, 4855045.9 GFLOPS, 53.94% peak
  q_b_proj B=1, S=2048: 0.0398 ms, 3881116.3 GFLOPS, 43.12% peak
  kv_b_proj B=1, S=2048: 0.0285 ms, 2409948.8 GFLOPS, 26.78% peak
  o_proj B=1, S=2048: 0.1014 ms, 4744996.5 GFLOPS, 52.72% peak
  q_b_proj B=2, S=128: 0.0090 ms, 2144696.1 GFLOPS, 23.83% peak
  kv_b_proj B=2, S=128: 0.0070 ms, 1219615.4 GFLOPS, 13.55% peak
  o_proj B=2, S=128: 0.0221 ms, 2717604.9 GFLOPS, 30.20% peak
  q_b_proj B=2, S=256: 0.0124 ms, 3125826.9 GFLOPS, 34.73% peak
  kv_b_proj B=2, S=256: 0.0102 ms, 1690753.7 GFLOPS, 18.79% peak
  o_proj B=2, S=256: 0.0236 ms, 5088010.1 GFLOPS, 56.53% peak
  q_b_proj B=2, S=512: 0.0192 ms, 4022560.5 GFLOPS, 44.70% peak
  kv_b_proj B=2, S=512: 0.0155 ms, 2211284.1 GFLOPS, 24.57% peak
  o_proj B=2, S=512: 0.0518 ms, 4644919.4 GFLOPS, 51.61% peak
  q_b_proj B=2, S=1024: 0.0397 ms, 3899487.6 GFLOPS, 43.33% peak
  kv_b_proj B=2, S=1024: 0.0282 ms, 2434413.4 GFLOPS, 27.05% peak
  o_proj B=2, S=1024: 0.1009 ms, 4769303.3 GFLOPS, 52.99% peak
  q_b_proj B=2, S=2048: 0.0709 ms, 4364461.8 GFLOPS, 48.49% peak
  kv_b_proj B=2, S=2048: 0.0509 ms, 2698610.4 GFLOPS, 29.98% peak
  o_proj B=2, S=2048: 0.1797 ms, 5352664.4 GFLOPS, 59.47% peak
  q_b_proj B=4, S=128: 0.0131 ms, 2958875.0 GFLOPS, 32.88% peak
  kv_b_proj B=4, S=128: 0.0102 ms, 1690798.8 GFLOPS, 18.79% peak
  o_proj B=4, S=128: 0.0238 ms, 5052348.9 GFLOPS, 56.14% peak
  q_b_proj B=4, S=256: 0.0193 ms, 4003448.5 GFLOPS, 44.48% peak
  kv_b_proj B=4, S=256: 0.0156 ms, 2208735.5 GFLOPS, 24.54% peak
  o_proj B=4, S=256: 0.0515 ms, 4666976.8 GFLOPS, 51.86% peak
  q_b_proj B=4, S=512: 0.0398 ms, 3887808.9 GFLOPS, 43.20% peak
  kv_b_proj B=4, S=512: 0.0283 ms, 2432411.4 GFLOPS, 27.03% peak
  o_proj B=4, S=512: 0.1004 ms, 4792019.1 GFLOPS, 53.24% peak
  q_b_proj B=4, S=1024: 0.0720 ms, 4293111.6 GFLOPS, 47.70% peak
  kv_b_proj B=4, S=1024: 0.0513 ms, 2681211.8 GFLOPS, 29.79% peak
  o_proj B=4, S=1024: 0.1792 ms, 5367260.7 GFLOPS, 59.64% peak
  q_b_proj B=4, S=2048: 0.1447 ms, 4273683.9 GFLOPS, 47.49% peak
  kv_b_proj B=4, S=2048: 0.0995 ms, 2761352.6 GFLOPS, 30.68% peak
  o_proj B=4, S=2048: 0.3513 ms, 5476487.5 GFLOPS, 60.85% peak
  q_b_proj B=8, S=128: 0.0203 ms, 3812853.2 GFLOPS, 42.37% peak
  kv_b_proj B=8, S=128: 0.0155 ms, 2219017.4 GFLOPS, 24.66% peak
  o_proj B=8, S=128: 0.0514 ms, 4679071.5 GFLOPS, 51.99% peak
  q_b_proj B=8, S=256: 0.0400 ms, 3865752.8 GFLOPS, 42.95% peak
  kv_b_proj B=8, S=256: 0.0283 ms, 2427192.7 GFLOPS, 26.97% peak
  o_proj B=8, S=256: 0.1014 ms, 4742403.1 GFLOPS, 52.69% peak
  q_b_proj B=8, S=512: 0.0718 ms, 4309339.1 GFLOPS, 47.88% peak
  kv_b_proj B=8, S=512: 0.0514 ms, 2671712.8 GFLOPS, 29.69% peak
  o_proj B=8, S=512: 0.1803 ms, 5337289.6 GFLOPS, 59.30% peak
  q_b_proj B=8, S=1024: 0.1435 ms, 4310871.3 GFLOPS, 47.90% peak
  kv_b_proj B=8, S=1024: 0.0981 ms, 2802570.3 GFLOPS, 31.14% peak
  o_proj B=8, S=1024: 0.3481 ms, 5527893.7 GFLOPS, 61.42% peak
  q_b_proj B=8, S=2048: 0.2889 ms, 4281306.9 GFLOPS, 47.57% peak
  kv_b_proj B=8, S=2048: 0.1972 ms, 2787956.6 GFLOPS, 30.98% peak
  o_proj B=8, S=2048: 0.7027 ms, 5476458.6 GFLOPS, 60.85% peak
Saved ../results/cutlass_scaled_fp4_mm.csv

[OK] cutlass_scaled_fp4_mm completed successfully

======================================================================
Running: dsv3_fused_a_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_fused_a_gemm (Kernel #4)
============================================================

=== Decode Phase (B<=16, low-latency path) ===
  B=1: 0.0051 ms, 5885.1 GFLOPS, 0.26% peak
  B=2: 0.0051 ms, 11791.9 GFLOPS, 0.52% peak
  B=4: 0.0052 ms, 23457.5 GFLOPS, 1.04% peak
  B=8: 0.0052 ms, 46372.6 GFLOPS, 2.06% peak
  B=16: 0.0058 ms, 82961.7 GFLOPS, 3.69% peak
Saved ../results/dsv3_fused_a_gemm.csv

[OK] dsv3_fused_a_gemm completed successfully

======================================================================
Running: dsv3_router_gemm (GEMM, Compute)
======================================================================
============================================================
Benchmark: dsv3_router_gemm (Kernel #5)
============================================================

=== Decode Phase ===
  B=1: 0.0020 ms, 1801.9 GFLOPS, 0.08% peak
  B=2: 0.0022 ms, 3284.1 GFLOPS, 0.15% peak
  B=4: 0.0027 ms, 5448.0 GFLOPS, 0.24% peak
  B=8: 0.0036 ms, 8214.3 GFLOPS, 0.37% peak
  B=16: 0.0072 ms, 8140.9 GFLOPS, 0.36% peak
  Skipping B=32: kernel limited to num_tokens <= 16
  Skipping B=64: kernel limited to num_tokens <= 16
  Skipping B=128: kernel limited to num_tokens <= 16

=== Prefill Phase (skipped - kernel limited to 16 tokens) ===
Saved ../results/dsv3_router_gemm.csv

[OK] dsv3_router_gemm completed successfully

======================================================================
Running: bmm_fp8 (BMM, Compute)
======================================================================
============================================================
Benchmark: bmm_fp8 (Kernel #6)
============================================================

=== Decode Phase: q_nope * w_kc ===
  B=1: 0.0055 ms, 3052.5 GFLOPS, 0.07% peak
  B=2: 0.0055 ms, 6113.4 GFLOPS, 0.14% peak
  B=4: 0.0055 ms, 12215.4 GFLOPS, 0.27% peak
  B=8: 0.0055 ms, 24415.3 GFLOPS, 0.54% peak
  B=16: 0.0056 ms, 47731.1 GFLOPS, 1.06% peak
  B=32: 0.0057 ms, 93437.9 GFLOPS, 2.08% peak
  B=64: 0.0061 ms, 176014.5 GFLOPS, 3.91% peak
  B=128: 0.0069 ms, 310350.9 GFLOPS, 6.90% peak

=== Decode Phase: attn * w_vc ===
  B=1: 0.0028 ms, 6084.0 GFLOPS, 0.14% peak
  B=2: 0.0027 ms, 12212.2 GFLOPS, 0.27% peak
  B=4: 0.0027 ms, 24433.6 GFLOPS, 0.54% peak
  B=8: 0.0028 ms, 48396.8 GFLOPS, 1.08% peak
  B=16: 0.0031 ms, 85735.6 GFLOPS, 1.91% peak
  B=32: 0.0032 ms, 168367.9 GFLOPS, 3.74% peak
  B=64: 0.0033 ms, 320911.7 GFLOPS, 7.13% peak
  B=128: 0.0038 ms, 571786.9 GFLOPS, 12.71% peak
Saved ../results/bmm_fp8.csv

[OK] bmm_fp8 completed successfully

======================================================================
Running: cutlass_mla_decode (Attention, Mixed)
======================================================================
============================================================
Benchmark: cutlass_mla_decode (Kernel #7)
============================================================

=== Decode Phase (MLA Attention) ===
  B=1, seq_len=128: 0.0181 ms, 16.3 GB/s, memory
  B=1, seq_len=256: 0.0295 ms, 15.0 GB/s, memory
  B=1, seq_len=512: 0.0307 ms, 24.0 GB/s, memory
  B=1, seq_len=1024: 0.0301 ms, 44.2 GB/s, memory
  Skipping B=1, seq_len=2048: B*seq_len=2048 > 1024 (crash risk)
  B=2, seq_len=128: 0.0181 ms, 32.6 GB/s, memory
  B=2, seq_len=256: 0.0296 ms, 29.9 GB/s, memory
  B=2, seq_len=512: 0.0293 ms, 50.4 GB/s, memory
  Skipping B=2, seq_len=1024: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=2, seq_len=2048: B*seq_len=4096 > 1024 (crash risk)
  B=4, seq_len=128: 0.0181 ms, 65.1 GB/s, memory
  B=4, seq_len=256: 0.0297 ms, 59.5 GB/s, memory
  Skipping B=4, seq_len=512: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=4, seq_len=1024: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=4, seq_len=2048: B*seq_len=8192 > 1024 (crash risk)
  B=8, seq_len=128: 0.0181 ms, 130.2 GB/s, memory
  Skipping B=8, seq_len=256: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=8, seq_len=512: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=8, seq_len=1024: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=8, seq_len=2048: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=128: B*seq_len=2048 > 1024 (crash risk)
  Skipping B=16, seq_len=256: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=16, seq_len=512: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=16, seq_len=1024: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=16, seq_len=2048: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=128: B*seq_len=4096 > 1024 (crash risk)
  Skipping B=32, seq_len=256: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=32, seq_len=512: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=32, seq_len=1024: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=32, seq_len=2048: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=128: B*seq_len=8192 > 1024 (crash risk)
  Skipping B=64, seq_len=256: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=64, seq_len=512: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=64, seq_len=1024: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=64, seq_len=2048: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=128: B*seq_len=16384 > 1024 (crash risk)
  Skipping B=128, seq_len=256: B*seq_len=32768 > 1024 (crash risk)
  Skipping B=128, seq_len=512: B*seq_len=65536 > 1024 (crash risk)
  Skipping B=128, seq_len=1024: B*seq_len=131072 > 1024 (crash risk)
  Skipping B=128, seq_len=2048: B*seq_len=262144 > 1024 (crash risk)
Saved ../results/cutlass_mla_decode.csv

[OK] cutlass_mla_decode completed successfully

======================================================================
Running: trtllm_batch_decode_with_kv_cache_mla (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_batch_decode_with_kv_cache_mla (Kernel #8)
============================================================

=== Decode Phase (TRT-LLM MLA Attention) ===

  Page size: 32
    B=1, seq_len=128: 0.0054 ms, 54.5 GB/s, memory
    B=1, seq_len=256: 0.0054 ms, 82.1 GB/s, memory
    B=1, seq_len=512: 0.0073 ms, 100.3 GB/s, memory
    B=1, seq_len=1024: 0.0098 ms, 134.8 GB/s, memory
    B=1, seq_len=2048: 0.0113 ms, 222.6 GB/s, memory
    B=2, seq_len=128: 0.0061 ms, 96.1 GB/s, memory
    B=2, seq_len=256: 0.0060 ms, 147.9 GB/s, memory
    B=2, seq_len=512: 0.0080 ms, 183.6 GB/s, memory
    B=2, seq_len=1024: 0.0102 ms, 259.1 GB/s, memory
    B=2, seq_len=2048: 0.0126 ms, 396.5 GB/s, memory
    B=4, seq_len=128: 0.0069 ms, 170.9 GB/s, memory
    B=4, seq_len=256: 0.0069 ms, 257.4 GB/s, memory
    B=4, seq_len=512: 0.0091 ms, 324.4 GB/s, memory
    B=4, seq_len=1024: 0.0116 ms, 458.6 GB/s, memory
    B=4, seq_len=2048: 0.0164 ms, 613.1 GB/s, memory
    B=8, seq_len=128: 0.0076 ms, 309.4 GB/s, memory
    B=8, seq_len=256: 0.0076 ms, 464.8 GB/s, memory
    B=8, seq_len=512: 0.0105 ms, 562.3 GB/s, memory
    B=8, seq_len=1024: 0.0154 ms, 687.3 GB/s, memory
    B=8, seq_len=2048: 0.0233 ms, 859.4 GB/s, memory
    B=16, seq_len=128: 0.0094 ms, 501.6 GB/s, memory
    B=16, seq_len=256: 0.0093 ms, 757.9 GB/s, memory
    B=16, seq_len=512: 0.0132 ms, 891.1 GB/s, memory
    B=16, seq_len=1024: 0.0204 ms, 1043.1 GB/s, memory
    B=16, seq_len=2048: 0.0160 ms, 2513.1 GB/s, memory
    B=32, seq_len=128: 0.0075 ms, 1261.7 GB/s, memory
    B=32, seq_len=256: 0.0088 ms, 1604.4 GB/s, memory
    B=32, seq_len=512: 0.0142 ms, 1663.2 GB/s, memory
    B=32, seq_len=1024: 0.0173 ms, 2461.0 GB/s, memory
    B=32, seq_len=2048: 0.0238 ms, 3377.0 GB/s, memory
    B=64, seq_len=128: 0.0081 ms, 2321.0 GB/s, memory
    B=64, seq_len=256: 0.0100 ms, 2835.5 GB/s, memory
    B=64, seq_len=512: 0.0128 ms, 3692.9 GB/s, memory
    B=64, seq_len=1024: 0.0186 ms, 4557.3 GB/s, memory
    B=64, seq_len=2048: 0.0436 ms, 3679.3 GB/s, memory
    B=128, seq_len=128: 0.0127 ms, 2978.2 GB/s, memory
    B=128, seq_len=256: 0.0172 ms, 3285.4 GB/s, memory
    B=128, seq_len=512: 0.0248 ms, 3808.4 GB/s, memory
    B=128, seq_len=1024: 0.0452 ms, 3754.8 GB/s, memory
    B=128, seq_len=2048: 0.0854 ms, 3758.4 GB/s, memory

  Page size: 64
    B=1, seq_len=128: 0.0068 ms, 43.2 GB/s, memory
    B=1, seq_len=256: 0.0055 ms, 81.1 GB/s, memory
    B=1, seq_len=512: 0.0075 ms, 98.6 GB/s, memory
    B=1, seq_len=1024: 0.0098 ms, 134.8 GB/s, memory
    B=1, seq_len=2048: 0.0111 ms, 225.4 GB/s, memory
    B=2, seq_len=128: 0.0057 ms, 104.1 GB/s, memory
    B=2, seq_len=256: 0.0056 ms, 156.6 GB/s, memory
    B=2, seq_len=512: 0.0076 ms, 193.5 GB/s, memory
    B=2, seq_len=1024: 0.0097 ms, 273.1 GB/s, memory
    B=2, seq_len=2048: 0.0114 ms, 440.8 GB/s, memory
    B=4, seq_len=128: 0.0065 ms, 181.4 GB/s, memory
    B=4, seq_len=256: 0.0063 ms, 278.9 GB/s, memory
    B=4, seq_len=512: 0.0083 ms, 353.2 GB/s, memory
    B=4, seq_len=1024: 0.0109 ms, 487.1 GB/s, memory
    B=4, seq_len=2048: 0.0143 ms, 699.3 GB/s, memory
    B=8, seq_len=128: 0.0070 ms, 337.6 GB/s, memory
    B=8, seq_len=256: 0.0069 ms, 512.1 GB/s, memory
    B=8, seq_len=512: 0.0095 ms, 623.3 GB/s, memory
    B=8, seq_len=1024: 0.0137 ms, 774.6 GB/s, memory
    B=8, seq_len=2048: 0.0205 ms, 978.9 GB/s, memory
    B=16, seq_len=128: 0.0081 ms, 580.1 GB/s, memory
    B=16, seq_len=256: 0.0081 ms, 868.7 GB/s, memory
    B=16, seq_len=512: 0.0116 ms, 1015.9 GB/s, memory
    B=16, seq_len=1024: 0.0184 ms, 1152.9 GB/s, memory
    B=16, seq_len=2048: 0.0156 ms, 2576.3 GB/s, memory
    B=32, seq_len=128: 0.0072 ms, 1305.7 GB/s, memory
    B=32, seq_len=256: 0.0085 ms, 1671.7 GB/s, memory
    B=32, seq_len=512: 0.0141 ms, 1676.0 GB/s, memory
    B=32, seq_len=1024: 0.0170 ms, 2497.5 GB/s, memory
    B=32, seq_len=2048: 0.0239 ms, 3350.3 GB/s, memory
    B=64, seq_len=128: 0.0081 ms, 2322.4 GB/s, memory
    B=64, seq_len=256: 0.0099 ms, 2865.8 GB/s, memory
    B=64, seq_len=512: 0.0127 ms, 3707.2 GB/s, memory
    B=64, seq_len=1024: 0.0185 ms, 4591.7 GB/s, memory
    B=64, seq_len=2048: 0.0441 ms, 3637.2 GB/s, memory
    B=128, seq_len=128: 0.0151 ms, 2495.6 GB/s, memory
    B=128, seq_len=256: 0.0171 ms, 3318.4 GB/s, memory
    B=128, seq_len=512: 0.0250 ms, 3777.3 GB/s, memory
    B=128, seq_len=1024: 0.0454 ms, 3744.7 GB/s, memory
    B=128, seq_len=2048: 0.0856 ms, 3747.2 GB/s, memory
Saved ../results/trtllm_batch_decode_with_kv_cache_mla.csv

[OK] trtllm_batch_decode_with_kv_cache_mla completed successfully

======================================================================
Running: trtllm_ragged_attention_deepseek (Attention, Mixed)
======================================================================
============================================================
Benchmark: trtllm_ragged_attention_deepseek (Kernel #9)
============================================================

=== Prefill Phase (TRT-LLM Ragged Attention) ===
  B=1, S=128: 0.0072 ms, 734.6 GFLOPS, memory
  B=1, S=256: 0.0105 ms, 3246.5 GFLOPS, memory
  B=1, S=512: 0.0185 ms, 4768.7 GFLOPS, memory
  B=1, S=1024: 0.0350 ms, 7763.5 GFLOPS, memory
  B=1, S=2048: 0.0836 ms, 11254.7 GFLOPS, memory
  B=2, S=128: 0.0117 ms, 1163.1 GFLOPS, memory
  B=2, S=256: 0.0177 ms, 4287.3 GFLOPS, memory
  B=2, S=512: 0.0359 ms, 5246.7 GFLOPS, memory
  B=2, S=1024: 0.0896 ms, 9234.8 GFLOPS, memory
  B=2, S=2048: 0.2502 ms, 13848.1 GFLOPS, memory
  B=4, S=128: 0.0195 ms, 1605.5 GFLOPS, memory
  B=4, S=256: 0.0346 ms, 3446.4 GFLOPS, memory
  B=4, S=512: 0.0741 ms, 6275.0 GFLOPS, memory
  B=4, S=1024: 0.1572 ms, 9825.0 GFLOPS, memory
  B=4, S=2048: 0.4850 ms, 13818.5 GFLOPS, memory
  B=8, S=128: 0.0350 ms, 1818.3 GFLOPS, memory
  B=8, S=256: 0.0592 ms, 3738.9 GFLOPS, memory
  B=8, S=512: 0.1350 ms, 6088.1 GFLOPS, memory
  B=8, S=1024: 0.3334 ms, 9494.3 GFLOPS, memory
  B=8, S=2048: 0.9761 ms, 13894.4 GFLOPS, memory
  B=16, S=128: 0.0648 ms, 1773.4 GFLOPS, memory
  B=16, S=256: 0.1135 ms, 3853.6 GFLOPS, memory
  B=16, S=512: 0.2755 ms, 6194.4 GFLOPS, memory
  B=16, S=1024: 0.7175 ms, 9806.6 GFLOPS, memory
  B=16, S=2048: 2.0006 ms, 14278.3 GFLOPS, memory
  B=32, S=128: 0.1247 ms, 1758.3 GFLOPS, memory
  B=32, S=256: 0.2244 ms, 3972.3 GFLOPS, memory
  B=32, S=512: 0.5594 ms, 6561.2 GFLOPS, memory
  B=32, S=1024: 1.4406 ms, 10127.1 GFLOPS, memory
  B=32, S=2048: 4.0675 ms, 14901.8 GFLOPS, memory
  B=64, S=128: 0.2457 ms, 1763.5 GFLOPS, memory
  B=64, S=256: 0.4463 ms, 3764.9 GFLOPS, memory
  B=64, S=512: 1.1184 ms, 6442.8 GFLOPS, memory
  B=64, S=1024: 2.8804 ms, 10246.4 GFLOPS, memory
  B=64, S=2048: 6.8967 ms, 16790.1 GFLOPS, memory
  B=128, S=128: 0.4940 ms, 1815.2 GFLOPS, memory
  B=128, S=256: 0.9059 ms, 3774.9 GFLOPS, memory
  B=128, S=512: 2.2006 ms, 6366.3 GFLOPS, memory
  B=128, S=1024: 5.6135 ms, 9995.7 GFLOPS, memory
Warning: Kernel failed for B=128, S=2048: Error in function 'aligned_alloc' at /usr/local/lib/python3.12/dist-packages/flashinfer/data/include/flashinfer/allocator.h:49: Buffer overflow when allocating memory for trtllm_gen_softmax_workspace with size 200737792 and alignment 16, but only 125829120 bytes available in AlignedAllocator. Increase the workspace buffer size.
Saved ../results/trtllm_ragged_attention_deepseek.csv

[OK] trtllm_ragged_attention_deepseek completed successfully

======================================================================
Running: mla_rope_quantize_fp8 (Attention, Memory)
======================================================================
============================================================
Benchmark: rope_quantize_fp8 (MLA config) (Kernel #10)
MLA: 128 Q heads, 1 K head, 64 rope_dim + 512 no_rope_dim
============================================================

=== MLA RoPE + FP8 Quantization ===
  tokens=128: 0.0064 ms, 4637.3 GB/s, 58.0% peak
  tokens=256: 0.0114 ms, 5100.7 GB/s, 63.8% peak
  tokens=512: 0.0240 ms, 4796.9 GB/s, 60.0% peak
  tokens=1024: 0.0466 ms, 4921.3 GB/s, 61.5% peak
  tokens=2048: 0.0915 ms, 5003.1 GB/s, 62.5% peak
  tokens=4096: 0.1829 ms, 4997.7 GB/s, 62.5% peak
  tokens=8192: 0.3676 ms, 4973.1 GB/s, 62.2% peak
  tokens=16384: 0.7463 ms, 4899.3 GB/s, 61.2% peak
  tokens=32768: 1.5316 ms, 4774.5 GB/s, 59.7% peak
  tokens=65536: 3.0664 ms, 4769.6 GB/s, 59.6% peak
  tokens=131072: 6.1680 ms, 4742.4 GB/s, 59.3% peak
  tokens=262144: 13.8909 ms, 4211.5 GB/s, 52.6% peak
Saved ../results/mla_rope_quantize_fp8.csv

[OK] mla_rope_quantize_fp8 completed successfully

======================================================================
Running: apply_rope_with_cos_sin_cache_inplace (RoPE, Memory)
======================================================================
============================================================
Benchmark: apply_rope_with_cos_sin_cache_inplace (Kernel #11)
============================================================

=== Decode Phase ===
  B=1: 0.0017 ms, 356.4 GB/s, 4.5% peak
  B=2: 0.0017 ms, 381.6 GB/s, 4.8% peak
  B=4: 0.0017 ms, 453.2 GB/s, 5.7% peak
  B=8: 0.0017 ms, 602.4 GB/s, 7.5% peak
  B=16: 0.0018 ms, 877.4 GB/s, 11.0% peak
  B=32: 0.0019 ms, 1397.1 GB/s, 17.5% peak
  B=64: 0.0022 ms, 2176.3 GB/s, 27.2% peak
  B=128: 0.0033 ms, 2721.0 GB/s, 34.0% peak

=== Prefill Phase ===
  B=1, S=128: 0.0033 ms, 2725.5 GB/s, 34.1% peak
  B=1, S=256: 0.0046 ms, 3753.8 GB/s, 46.9% peak
  B=1, S=512: 0.0073 ms, 4641.5 GB/s, 58.0% peak
  B=1, S=1024: 0.0128 ms, 5290.0 GB/s, 66.1% peak
  B=1, S=2048: 0.0242 ms, 5559.7 GB/s, 69.5% peak
  B=2, S=128: 0.0046 ms, 3734.1 GB/s, 46.7% peak
  B=2, S=256: 0.0073 ms, 4646.1 GB/s, 58.1% peak
  B=2, S=512: 0.0127 ms, 5318.5 GB/s, 66.5% peak
  B=2, S=1024: 0.0244 ms, 5522.6 GB/s, 69.0% peak
  B=2, S=2048: 0.0674 ms, 3992.2 GB/s, 49.9% peak
  B=4, S=128: 0.0073 ms, 4666.6 GB/s, 58.3% peak
  B=4, S=256: 0.0126 ms, 5353.6 GB/s, 66.9% peak
  B=4, S=512: 0.0239 ms, 5639.4 GB/s, 70.5% peak
  B=4, S=1024: 0.0674 ms, 3991.0 GB/s, 49.9% peak
  B=4, S=2048: 0.1391 ms, 3863.8 GB/s, 48.3% peak
  B=8, S=128: 0.0126 ms, 5360.6 GB/s, 67.0% peak
  B=8, S=256: 0.0239 ms, 5647.1 GB/s, 70.6% peak
  B=8, S=512: 0.0671 ms, 4006.1 GB/s, 50.1% peak
  B=8, S=1024: 0.1383 ms, 3887.6 GB/s, 48.6% peak
  B=8, S=2048: 0.2857 ms, 3760.2 GB/s, 47.0% peak
Saved ../results/apply_rope_with_cos_sin_cache_inplace.csv

[OK] apply_rope_with_cos_sin_cache_inplace completed successfully

======================================================================
Running: concat_mla_k (Concat, Memory)
======================================================================
============================================================
Benchmark: concat_mla_k (Kernel #12)
============================================================

=== Decode Phase ===
  B=1: 0.0022 ms, 38.0 GB/s, 0.5% peak
  B=2: 0.0031 ms, 53.6 GB/s, 0.7% peak
  B=4: 0.0049 ms, 67.0 GB/s, 0.8% peak
  B=8: 0.0049 ms, 133.3 GB/s, 1.7% peak
  B=16: 0.0049 ms, 266.5 GB/s, 3.3% peak
  B=32: 0.0049 ms, 533.8 GB/s, 6.7% peak
  B=64: 0.0049 ms, 1066.7 GB/s, 13.3% peak
  B=128: 0.0050 ms, 2120.9 GB/s, 26.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0050 ms, 2120.2 GB/s, 26.5% peak
  B=1, S=256: 0.0050 ms, 4212.5 GB/s, 52.7% peak
  B=1, S=512: 0.0053 ms, 7956.7 GB/s, 99.5% peak
  B=1, S=1024: 0.0106 ms, 7943.5 GB/s, 99.3% peak
  B=1, S=2048: 0.0272 ms, 6176.2 GB/s, 77.2% peak
  B=2, S=128: 0.0050 ms, 4162.5 GB/s, 52.0% peak
  B=2, S=256: 0.0052 ms, 8011.4 GB/s, 100.1% peak
  B=2, S=512: 0.0098 ms, 8593.0 GB/s, 107.4% peak
  B=2, S=1024: 0.0271 ms, 6205.5 GB/s, 77.6% peak
  B=2, S=2048: 0.0522 ms, 6438.4 GB/s, 80.5% peak
  B=4, S=128: 0.0051 ms, 8169.5 GB/s, 102.1% peak
  B=4, S=256: 0.0095 ms, 8812.3 GB/s, 110.2% peak
  B=4, S=512: 0.0270 ms, 6228.8 GB/s, 77.9% peak
  B=4, S=1024: 0.0524 ms, 6416.7 GB/s, 80.2% peak
  B=4, S=2048: 0.1009 ms, 6660.5 GB/s, 83.3% peak
  B=8, S=128: 0.0096 ms, 8743.9 GB/s, 109.3% peak
  B=8, S=256: 0.0270 ms, 6227.2 GB/s, 77.8% peak
  B=8, S=512: 0.0524 ms, 6414.7 GB/s, 80.2% peak
  B=8, S=1024: 0.1010 ms, 6656.9 GB/s, 83.2% peak
  B=8, S=2048: 0.1985 ms, 6770.6 GB/s, 84.6% peak
Saved ../results/concat_mla_k.csv

[OK] concat_mla_k completed successfully

======================================================================
Running: silu_and_mul (Activation, Memory)
======================================================================
============================================================
Benchmark: silu_and_mul (Kernel #13)
============================================================

=== Decode Phase ===
  B=1: 0.0019 ms, 6.6 GB/s, 0.1% peak
  B=2: 0.0019 ms, 13.0 GB/s, 0.2% peak
  B=4: 0.0019 ms, 26.1 GB/s, 0.3% peak
  B=8: 0.0019 ms, 52.3 GB/s, 0.7% peak
  B=16: 0.0019 ms, 104.6 GB/s, 1.3% peak
  B=32: 0.0019 ms, 208.7 GB/s, 2.6% peak
  B=64: 0.0019 ms, 411.1 GB/s, 5.1% peak
  B=128: 0.0019 ms, 810.5 GB/s, 10.1% peak

=== Prefill Phase ===
  B=1, S=128: 0.0019 ms, 811.4 GB/s, 10.1% peak
  B=1, S=256: 0.0021 ms, 1473.4 GB/s, 18.4% peak
  B=1, S=512: 0.0028 ms, 2229.4 GB/s, 27.9% peak
  B=1, S=1024: 0.0038 ms, 3318.8 GB/s, 41.5% peak
  B=1, S=2048: 0.0058 ms, 4358.4 GB/s, 54.5% peak
  B=2, S=128: 0.0021 ms, 1474.1 GB/s, 18.4% peak
  B=2, S=256: 0.0028 ms, 2228.5 GB/s, 27.9% peak
  B=2, S=512: 0.0038 ms, 3316.8 GB/s, 41.5% peak
  B=2, S=1024: 0.0058 ms, 4358.6 GB/s, 54.5% peak
  B=2, S=2048: 0.0099 ms, 5090.1 GB/s, 63.6% peak
  B=4, S=128: 0.0028 ms, 2222.5 GB/s, 27.8% peak
  B=4, S=256: 0.0038 ms, 3317.6 GB/s, 41.5% peak
  B=4, S=512: 0.0058 ms, 4357.7 GB/s, 54.5% peak
  B=4, S=1024: 0.0099 ms, 5083.5 GB/s, 63.5% peak
  B=4, S=2048: 0.0198 ms, 5074.2 GB/s, 63.4% peak
  B=8, S=128: 0.0038 ms, 3295.9 GB/s, 41.2% peak
  B=8, S=256: 0.0058 ms, 4351.5 GB/s, 54.4% peak
  B=8, S=512: 0.0099 ms, 5073.5 GB/s, 63.4% peak
  B=8, S=1024: 0.0198 ms, 5074.3 GB/s, 63.4% peak
  B=8, S=2048: 0.0399 ms, 5050.5 GB/s, 63.1% peak
Saved ../results/silu_and_mul.csv

[OK] silu_and_mul completed successfully

======================================================================
Running: topk_softmax (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_softmax (Kernel #14)
============================================================

=== Decode Phase ===
  B=1: 0.0035 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0035 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0035 ms, 1.2 GB/s, 0.0% peak
  B=8: 0.0035 ms, 2.5 GB/s, 0.0% peak
  B=16: 0.0035 ms, 4.9 GB/s, 0.1% peak
  B=32: 0.0035 ms, 9.8 GB/s, 0.1% peak
  B=64: 0.0035 ms, 19.7 GB/s, 0.2% peak
  B=128: 0.0035 ms, 39.3 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0035 ms, 39.3 GB/s, 0.5% peak
  B=1, S=256: 0.0036 ms, 78.2 GB/s, 1.0% peak
  B=1, S=512: 0.0036 ms, 154.9 GB/s, 1.9% peak
  B=1, S=1024: 0.0039 ms, 284.1 GB/s, 3.6% peak
  B=1, S=2048: 0.0053 ms, 418.5 GB/s, 5.2% peak
  B=2, S=128: 0.0036 ms, 78.2 GB/s, 1.0% peak
  B=2, S=256: 0.0036 ms, 154.9 GB/s, 1.9% peak
  B=2, S=512: 0.0039 ms, 284.2 GB/s, 3.6% peak
  B=2, S=1024: 0.0053 ms, 418.7 GB/s, 5.2% peak
  B=2, S=2048: 0.0079 ms, 567.1 GB/s, 7.1% peak
  B=4, S=128: 0.0036 ms, 154.9 GB/s, 1.9% peak
  B=4, S=256: 0.0039 ms, 284.1 GB/s, 3.6% peak
  B=4, S=512: 0.0053 ms, 418.6 GB/s, 5.2% peak
  B=4, S=1024: 0.0079 ms, 567.4 GB/s, 7.1% peak
  B=4, S=2048: 0.0134 ms, 663.8 GB/s, 8.3% peak
  B=8, S=128: 0.0039 ms, 284.1 GB/s, 3.6% peak
  B=8, S=256: 0.0053 ms, 418.8 GB/s, 5.2% peak
  B=8, S=512: 0.0078 ms, 567.7 GB/s, 7.1% peak
  B=8, S=1024: 0.0134 ms, 663.9 GB/s, 8.3% peak
  B=8, S=2048: 0.0240 ms, 743.8 GB/s, 9.3% peak
Saved ../results/topk_softmax.csv

[OK] topk_softmax completed successfully

======================================================================
Running: topk_sigmoid (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: topk_sigmoid (Kernel #15)
============================================================

=== Decode Phase ===
  B=1: 0.0037 ms, 0.3 GB/s, 0.0% peak
  B=2: 0.0037 ms, 0.6 GB/s, 0.0% peak
  B=4: 0.0038 ms, 1.1 GB/s, 0.0% peak
  B=8: 0.0038 ms, 2.3 GB/s, 0.0% peak
  B=16: 0.0038 ms, 4.6 GB/s, 0.1% peak
  B=32: 0.0038 ms, 9.2 GB/s, 0.1% peak
  B=64: 0.0038 ms, 18.3 GB/s, 0.2% peak
  B=128: 0.0038 ms, 36.6 GB/s, 0.5% peak

=== Prefill Phase ===
  B=1, S=128: 0.0038 ms, 36.6 GB/s, 0.5% peak
  B=1, S=256: 0.0038 ms, 72.8 GB/s, 0.9% peak
  B=1, S=512: 0.0039 ms, 144.6 GB/s, 1.8% peak
  B=1, S=1024: 0.0041 ms, 269.4 GB/s, 3.4% peak
  B=1, S=2048: 0.0054 ms, 412.3 GB/s, 5.2% peak
  B=2, S=128: 0.0038 ms, 72.8 GB/s, 0.9% peak
  B=2, S=256: 0.0039 ms, 144.6 GB/s, 1.8% peak
  B=2, S=512: 0.0041 ms, 269.3 GB/s, 3.4% peak
  B=2, S=1024: 0.0054 ms, 412.4 GB/s, 5.2% peak
  B=2, S=2048: 0.0078 ms, 571.5 GB/s, 7.1% peak
  B=4, S=128: 0.0039 ms, 144.6 GB/s, 1.8% peak
  B=4, S=256: 0.0041 ms, 269.4 GB/s, 3.4% peak
  B=4, S=512: 0.0054 ms, 412.3 GB/s, 5.2% peak
  B=4, S=1024: 0.0078 ms, 571.6 GB/s, 7.1% peak
  B=4, S=2048: 0.0131 ms, 679.6 GB/s, 8.5% peak
  B=8, S=128: 0.0041 ms, 269.4 GB/s, 3.4% peak
  B=8, S=256: 0.0054 ms, 412.3 GB/s, 5.2% peak
  B=8, S=512: 0.0078 ms, 571.5 GB/s, 7.1% peak
  B=8, S=1024: 0.0131 ms, 679.6 GB/s, 8.5% peak
  B=8, S=2048: 0.0231 ms, 771.3 GB/s, 9.6% peak
Saved ../results/topk_sigmoid.csv

[OK] topk_sigmoid completed successfully

======================================================================
Running: moe_fused_gate (MoE Routing, Memory)
======================================================================
============================================================
Benchmark: moe_fused_gate (Kernel #16)
============================================================

=== Decode Phase ===
  B=1: 0.0111 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0113 ms, 0.3 GB/s, 0.0% peak
  B=4: 0.0115 ms, 0.5 GB/s, 0.0% peak
  B=8: 0.0123 ms, 0.8 GB/s, 0.0% peak
  B=16: 0.0138 ms, 1.3 GB/s, 0.0% peak
  B=32: 0.0160 ms, 2.2 GB/s, 0.0% peak
  B=64: 0.0160 ms, 4.4 GB/s, 0.1% peak
  B=128: 0.0159 ms, 8.8 GB/s, 0.1% peak

=== Prefill Phase ===
  B=1, S=128: 0.0159 ms, 8.8 GB/s, 0.1% peak
  B=1, S=256: 0.0160 ms, 17.5 GB/s, 0.2% peak
  B=1, S=512: 0.0161 ms, 34.7 GB/s, 0.4% peak
  B=1, S=1024: 0.0161 ms, 69.4 GB/s, 0.9% peak
  B=1, S=2048: 0.0161 ms, 138.8 GB/s, 1.7% peak
  B=2, S=128: 0.0159 ms, 17.5 GB/s, 0.2% peak
  B=2, S=256: 0.0161 ms, 34.7 GB/s, 0.4% peak
  B=2, S=512: 0.0159 ms, 70.0 GB/s, 0.9% peak
  B=2, S=1024: 0.0161 ms, 138.5 GB/s, 1.7% peak
  B=2, S=2048: 0.0219 ms, 203.2 GB/s, 2.5% peak
  B=4, S=128: 0.0160 ms, 34.9 GB/s, 0.4% peak
  B=4, S=256: 0.0159 ms, 70.0 GB/s, 0.9% peak
  B=4, S=512: 0.0161 ms, 138.7 GB/s, 1.7% peak
  B=4, S=1024: 0.0221 ms, 202.0 GB/s, 2.5% peak
  B=4, S=2048: 0.0293 ms, 304.0 GB/s, 3.8% peak
  B=8, S=128: 0.0161 ms, 69.4 GB/s, 0.9% peak
  B=8, S=256: 0.0158 ms, 140.7 GB/s, 1.8% peak
  B=8, S=512: 0.0220 ms, 203.0 GB/s, 2.5% peak
  B=8, S=1024: 0.0290 ms, 307.7 GB/s, 3.8% peak
  B=8, S=2048: 0.0455 ms, 392.2 GB/s, 4.9% peak
Saved ../results/moe_fused_gate.csv

[OK] moe_fused_gate completed successfully

======================================================================
Running: prepare_moe_input (MoE, Memory)
======================================================================
============================================================
Benchmark: prepare_moe_input (Kernel #17)
============================================================

=== Decode Phase ===
  B=1: 0.0162 ms, 0.2 GB/s, 0.0% peak
  B=2: 0.0162 ms, 0.2 GB/s, 0.0% peak
  B=4: 0.0163 ms, 0.2 GB/s, 0.0% peak
  B=8: 0.0164 ms, 0.2 GB/s, 0.0% peak
  B=16: 0.0166 ms, 0.3 GB/s, 0.0% peak
  B=32: 0.0162 ms, 0.4 GB/s, 0.0% peak
  B=64: 0.0152 ms, 0.6 GB/s, 0.0% peak
  B=128: 0.0149 ms, 1.0 GB/s, 0.0% peak

=== Prefill Phase ===
  B=1, S=128: 0.0149 ms, 1.0 GB/s, 0.0% peak
  B=1, S=256: 0.0168 ms, 1.6 GB/s, 0.0% peak
  B=1, S=512: 0.0186 ms, 2.8 GB/s, 0.0% peak
  B=1, S=1024: 0.0231 ms, 4.4 GB/s, 0.1% peak
  B=1, S=2048: 0.0345 ms, 5.8 GB/s, 0.1% peak
  B=2, S=128: 0.0168 ms, 1.6 GB/s, 0.0% peak
  B=2, S=256: 0.0188 ms, 2.8 GB/s, 0.0% peak
  B=2, S=512: 0.0226 ms, 4.5 GB/s, 0.1% peak
  B=2, S=1024: 0.0340 ms, 5.9 GB/s, 0.1% peak
  B=2, S=2048: 0.0442 ms, 9.0 GB/s, 0.1% peak
  B=4, S=128: 0.0193 ms, 2.7 GB/s, 0.0% peak
  B=4, S=256: 0.0226 ms, 4.5 GB/s, 0.1% peak
  B=4, S=512: 0.0338 ms, 5.9 GB/s, 0.1% peak
  B=4, S=1024: 0.0447 ms, 8.9 GB/s, 0.1% peak
  B=4, S=2048: 0.0735 ms, 10.7 GB/s, 0.1% peak
  B=8, S=128: 0.0227 ms, 4.5 GB/s, 0.1% peak
  B=8, S=256: 0.0334 ms, 6.0 GB/s, 0.1% peak
  B=8, S=512: 0.0438 ms, 9.0 GB/s, 0.1% peak
  B=8, S=1024: 0.0728 ms, 10.9 GB/s, 0.1% peak
  B=8, S=2048: 0.1281 ms, 12.3 GB/s, 0.2% peak
Saved ../results/prepare_moe_input.csv

[OK] prepare_moe_input completed successfully

======================================================================
Running: scaled_fp4_experts_quant (MoE, Memory)
======================================================================
============================================================
Benchmark: scaled_fp4_experts_quant (Kernel #18)
============================================================

=== Decode Phase ===
  B=1: 0.0073 ms, 20.1 GB/s, 0.3% peak
  B=2: 0.0075 ms, 39.1 GB/s, 0.5% peak
  B=4: 0.0075 ms, 78.9 GB/s, 1.0% peak
  B=8: 0.0079 ms, 149.3 GB/s, 1.9% peak
  B=16: 0.0093 ms, 253.6 GB/s, 3.2% peak
  B=32: 0.0124 ms, 380.7 GB/s, 4.8% peak
  B=64: 0.0068 ms, 1385.0 GB/s, 17.3% peak
  B=128: 0.0110 ms, 1708.1 GB/s, 21.4% peak

=== Prefill Phase ===
  B=1, S=128: 0.0110 ms, 1707.5 GB/s, 21.3% peak
Warning: Kernel failed for B=1, S=256: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 169, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 165, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 139, in run_benchmarks
    result = bench_scaled_fp4_experts_quant(sgl_kernel, B, S, H, E, K, "prefill")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_scaled_fp4_experts_quant.py", line 48, in bench_scaled_fp4_experts_quant
    expert_inputs = torch.randn(total_expert_tokens, hidden_size, dtype=torch.bfloat16, device=device)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[FAILED] scaled_fp4_experts_quant: Exit code 1

======================================================================
Running: cutlass_fp4_group_mm (MoE, Compute)
======================================================================
============================================================
Benchmark: cutlass_fp4_group_mm (Kernel #19)
============================================================

=== Decode Phase: gate_up ===
  B=1: 0.0333 ms, 14122.8 GFLOPS, 0.16% peak
  B=2: 0.0382 ms, 24584.7 GFLOPS, 0.27% peak
  B=4: 0.0342 ms, 55023.0 GFLOPS, 0.61% peak
  B=8: 0.0351 ms, 106955.3 GFLOPS, 1.19% peak
  B=16: 0.0371 ms, 202732.6 GFLOPS, 2.25% peak
Warning: Kernel failed for B=32, S=1, op=gate_up: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 229, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 225, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 175, in run_benchmarks
    result = bench_cutlass_fp4_group_mm(sgl_kernel, B, 1, E, K, H, I, "gate_up", "decode")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_cutlass_fp4_group_mm.py", line 62, in bench_cutlass_fp4_group_mm
    a = torch.randn((M, K_dim), dtype=torch.bfloat16, device=device)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[FAILED] cutlass_fp4_group_mm: Exit code 1

======================================================================
Running: apply_shuffle_mul_sum (MoE, Memory)
======================================================================
============================================================
Benchmark: apply_shuffle_mul_sum (Kernel #20)
============================================================

=== Decode Phase ===
  B=1: 0.0030 ms, 43.0 GB/s, 0.5% peak
  B=2: 0.0031 ms, 84.6 GB/s, 1.1% peak
  B=4: 0.0030 ms, 170.5 GB/s, 2.1% peak
  B=8: 0.0030 ms, 340.7 GB/s, 4.3% peak
  B=16: 0.0030 ms, 683.2 GB/s, 8.5% peak
  B=32: 0.0030 ms, 1358.3 GB/s, 17.0% peak
  B=64: 0.0031 ms, 2680.1 GB/s, 33.5% peak
  B=128: 0.0031 ms, 5326.4 GB/s, 66.6% peak

=== Prefill Phase ===
  B=1, S=128: 0.0031 ms, 5328.5 GB/s, 66.6% peak
  B=1, S=256: 0.0042 ms, 7906.6 GB/s, 98.8% peak
  B=1, S=512: 0.0067 ms, 9833.3 GB/s, 122.9% peak
  B=1, S=1024: 0.0106 ms, 12477.6 GB/s, 156.0% peak
  B=1, S=2048: 0.0189 ms, 13990.1 GB/s, 174.9% peak
  B=2, S=128: 0.0042 ms, 7902.1 GB/s, 98.8% peak
  B=2, S=256: 0.0067 ms, 9846.1 GB/s, 123.1% peak
  B=2, S=512: 0.0106 ms, 12491.3 GB/s, 156.1% peak
  B=2, S=1024: 0.0189 ms, 13999.7 GB/s, 175.0% peak
  B=2, S=2048: 0.0381 ms, 13892.7 GB/s, 173.7% peak
  B=4, S=128: 0.0066 ms, 9946.6 GB/s, 124.3% peak
  B=4, S=256: 0.0106 ms, 12494.0 GB/s, 156.2% peak
  B=4, S=512: 0.0189 ms, 14024.3 GB/s, 175.3% peak
  B=4, S=1024: 0.0380 ms, 13929.6 GB/s, 174.1% peak
  B=4, S=2048: 0.0731 ms, 14461.0 GB/s, 180.8% peak
  B=8, S=128: 0.0105 ms, 12611.1 GB/s, 157.6% peak
  B=8, S=256: 0.0188 ms, 14025.5 GB/s, 175.3% peak
  B=8, S=512: 0.0381 ms, 13896.0 GB/s, 173.7% peak
  B=8, S=1024: 0.0731 ms, 14460.6 GB/s, 180.8% peak
  B=8, S=2048: 0.1426 ms, 14827.4 GB/s, 185.3% peak
Saved ../results/apply_shuffle_mul_sum.csv

[OK] apply_shuffle_mul_sum completed successfully

======================================================================
Running: moe_align_block_size (MoE, Memory)
======================================================================
============================================================
Benchmark: moe_align_block_size (Kernel #21)
============================================================

=== Decode Phase ===
  B=1: 0.0044 ms, 15.2 GB/s, 0.2% peak
  B=2: 0.0045 ms, 15.1 GB/s, 0.2% peak
  B=4: 0.0045 ms, 15.2 GB/s, 0.2% peak
  B=8: 0.0044 ms, 15.3 GB/s, 0.2% peak
  B=16: 0.0045 ms, 15.4 GB/s, 0.2% peak
  B=32: 0.0044 ms, 15.8 GB/s, 0.2% peak
  B=64: 0.0044 ms, 16.3 GB/s, 0.2% peak
  B=128: 0.0045 ms, 16.8 GB/s, 0.2% peak

=== Prefill Phase ===
  B=1, S=128: 0.0045 ms, 16.8 GB/s, 0.2% peak
  B=1, S=256: 0.0049 ms, 17.2 GB/s, 0.2% peak
  B=1, S=512: 0.0058 ms, 17.5 GB/s, 0.2% peak
  B=1, S=1024: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=1, S=2048: 0.0087 ms, 22.9 GB/s, 0.3% peak
  B=2, S=128: 0.0049 ms, 17.2 GB/s, 0.2% peak
  B=2, S=256: 0.0058 ms, 17.5 GB/s, 0.2% peak
  B=2, S=512: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=2, S=1024: 0.0087 ms, 22.9 GB/s, 0.3% peak
  B=2, S=2048: 0.0136 ms, 24.5 GB/s, 0.3% peak
  B=4, S=128: 0.0058 ms, 17.5 GB/s, 0.2% peak
  B=4, S=256: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=4, S=512: 0.0087 ms, 22.9 GB/s, 0.3% peak
  B=4, S=1024: 0.0135 ms, 24.5 GB/s, 0.3% peak
  B=4, S=2048: 0.0230 ms, 25.9 GB/s, 0.3% peak
  B=8, S=128: 0.0074 ms, 18.1 GB/s, 0.2% peak
  B=8, S=256: 0.0087 ms, 22.9 GB/s, 0.3% peak
  B=8, S=512: 0.0135 ms, 24.6 GB/s, 0.3% peak
  B=8, S=1024: 0.0231 ms, 25.8 GB/s, 0.3% peak
  B=8, S=2048: 0.0417 ms, 26.9 GB/s, 0.3% peak
Saved ../results/moe_align_block_size.csv

[OK] moe_align_block_size completed successfully

======================================================================
Running: trtllm_fp4_block_scale_moe (MoE, Mixed)
======================================================================
============================================================
Benchmark: trtllm_fp4_block_scale_moe (Kernel #22)
============================================================

=== Decode Phase ===
  B=1: Skipped (minimum batch size for FP4 MoE is 16)
  B=2: Skipped (minimum batch size for FP4 MoE is 16)
  B=4: Skipped (minimum batch size for FP4 MoE is 16)
  B=8: Skipped (minimum batch size for FP4 MoE is 16)
Warning: Kernel failed for B=16, S=1: Error in function 'run' at /usr/local/lib/python3.12/dist-packages/flashinfer/data/csrc/trtllm_batched_gemm_runner.cu:258: Error occurred when running GEMM! (numBatches:  256 , GemmMNK:  16   4096   7168 , Kernel:  bmm_E2m1_E2m1E2m1_Fp32_t128x8x512u2_s5_et128x8_m128x8x64_cga1x1x1_16dp256b_rM_TN_transOut_schedP2x1x2x3_bN_ldgsts_tmaOpt_clmp_swiGlu_dynBatch_sm100f )

Traceback (most recent call last):
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 318, in <module>
    main()
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 314, in main
    run_benchmarks(batch_sizes, seq_lens, args.output)
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 279, in run_benchmarks
    result = bench_trtllm_fp4_block_scale_moe(flashinfer, B, 1, H, E, K, I, "decode")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/deepseek_kernel_benchmarks/scripts/bench_trtllm_fp4_block_scale_moe.py", line 95, in bench_trtllm_fp4_block_scale_moe
    torch.manual_seed(42)
  File "/usr/local/lib/python3.12/dist-packages/torch/random.py", line 46, in manual_seed
    torch.cuda.manual_seed_all(seed)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 131, in manual_seed_all
    _lazy_call(cb, seed_all=True)
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 341, in _lazy_call
    callable()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 129, in cb
    default_generator.manual_seed(seed)
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[FAILED] trtllm_fp4_block_scale_moe: Exit code 1

======================================================================
Running: fused_moe_kernel (MoE, Mixed)
======================================================================
============================================================
Benchmark: fused_moe_kernel (Kernel #23)
============================================================

=== Decode Phase ===
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))

=== Prefill Phase ===
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))
Warning: fused_moe_kernel not available (requires flashinfer: cannot import name 'set_global_server_args' from 'sglang.srt.server_args' (/lustre/fsw/sw_aidot/pengchengl/sglang_deepseek_only/mini-sglang-deepseek-only/sglang/python/sglang/srt/server_args.py))

No results - kernel not available

[FAILED] fused_moe_kernel: No CSV output (kernel not available or all runs failed)

Aggregated results saved to ../results/all_kernels.csv
Total benchmark results: 559

Summary saved to ../results/benchmark_summary.md

======================================================================
Benchmark Complete!
Successful: 19/23
Failed kernels:
  - scaled_fp4_experts_quant: Exit code 1
  - cutlass_fp4_group_mm: Exit code 1
  - trtllm_fp4_block_scale_moe: Exit code 1
  - fused_moe_kernel: No CSV output (kernel not available or all runs failed)
======================================================================
